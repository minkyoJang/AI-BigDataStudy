{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"(ANS)Seq2Seq.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5zthtOlIjcO1","colab_type":"text"},"source":["**Copyright(C). Cheonbok Park. All rights reserved.**\n","\n","Email : cb_park@korea.ac.kr"]},{"cell_type":"markdown","metadata":{"id":"lWPhKRrqw8Vl","colab_type":"text"},"source":["### 필요 라이브러리 설치"]},{"cell_type":"code","metadata":{"id":"krquphUSw64W","colab_type":"code","colab":{}},"source":["# 필요한 라이브러리를 설치합니다. "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TF6swkROGoRk","colab_type":"code","colab":{}},"source":["import torch # torch library \n","import torch.nn as nn # Nueral Network에 대한 package\n","import numpy as np  # numpy \n","import editdistance # 평가 지표로서 사용될 edit distance \n","import matplotlib.pyplot as plt # plot 을 찍기 위한 라이브러리\n","import tqdm\n","import torch.nn.functional as F # pytorch function 들을 사용하기 위한 용도 \n","from torch.utils import data # dataset 관련된 utility 를 사용하려는 용도\n","from random import choice, randrange # random\n","from itertools import zip_longest \n","import librosa\n","import os   # directory 생성 및 디렉토리 생성과 관련된 package \n","import json \n","import random\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvgO0Z-3xKpr","colab_type":"text"},"source":["### Data Loader "]},{"cell_type":"markdown","metadata":{"id":"N5VY4V8ifgNm","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/word-encoding.png)"]},{"cell_type":"code","metadata":{"id":"JPt35iPSs0dO","colab_type":"code","colab":{}},"source":["def batch(iterable, n=1):\n","    args = [iter(iterable)] * n\n","    return zip_longest(*args)\n","\n","\n","def pad_tensor(vec, pad, value=0, dim=0):\n","    \"\"\"\n","    pad token으로 채우는 용도 \n","    args:\n","        vec - tensor to pad\n","        pad - the size to pad to\n","        dim - dimension to pad\n","    return:\n","        a new tensor padded to 'pad' in dimension 'dim'\n","    \"\"\"\n","    pad_size = pad - vec.shape[0]\n","\n","    if len(vec.shape) == 2:\n","        zeros = torch.ones((pad_size, vec.shape[-1])) * value\n","    elif len(vec.shape) == 1:\n","        zeros = torch.ones((pad_size,)) * value\n","    else:\n","        raise NotImplementedError\n","    return torch.cat([torch.Tensor(vec), zeros], dim=dim)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7t-W0gQps2rg","colab_type":"text"},"source":["![대체 텍스트](https://i.stack.imgur.com/Kuhh0.jpg)"]},{"cell_type":"code","metadata":{"id":"QAaKIfA7BdLX","colab_type":"code","colab":{}},"source":["def pad_collate(batch, values=(0, 0), dim=0):\n","    \"\"\"\n","    데이터 로더에 들어가기전에 batch화 할 때 거치는 함수 \n","    args:\n","        batch - list of (tensor, label)\n","    reutrn:\n","        xs - a tensor of all examples in 'batch' after padding\n","        ys - a LongTensor of all labels in batch\n","        ws - a tensor of sequence lengths\n","    \"\"\"\n","\n","    sequence_lengths = torch.Tensor([int(x[0].shape[dim]) for x in batch]) # 각 batch 마다 길이를 얻어내고 \n","    sequence_lengths, xids = sequence_lengths.sort(descending=True) # 감소하는 순서로 정렬\n","    target_lengths = torch.Tensor([int(x[1].shape[dim]) for x in batch])\n","    # find longest sequence (가장 긴 sequence의 길이를 구함 )\n","    src_max_len = max(map(lambda x: x[0].shape[dim], batch))\n","    tgt_max_len = max(map(lambda x: x[1].shape[dim], batch))\n","    # pad according to max_len (max length 만큼 padd를 추가 )\n","    batch = [(pad_tensor(x, pad=src_max_len, dim=dim), pad_tensor(y, pad=tgt_max_len, dim=dim)) for (x, y) in batch]\n","\n","    # stack all\n","    xs = torch.stack([x[0] for x in batch], dim=0)\n","    ys = torch.stack([x[1] for x in batch], dim=0)\n","    xs = xs[xids].contiguous() # decreasing order로 다시 나열 \n","    ys = ys[xids].contiguous() # xids 와 같은 순서로 \n","    target_lengths = target_lengths[xids] \n","    return xs.long(), ys.long(), sequence_lengths.int(), target_lengths.int()\n","\n","\n","class ToyDataset(data.Dataset):\n","    \"\"\"\n","    https://talbaumel.github.io/blog/attention/\n","    \"\"\"\n","    def __init__(self, min_length=5, max_length=20, type='train'):\n","        self.SOS = \"<s>\"  # all strings will end with the End Of String token )\n","        self.EOS = \"</s>\"  # all strings will end with the End Of String token\n","        self.characters = list(\"abcdefg\")\n","        self.int2char = list(self.characters)\n","        self.char2int = {c: i+3 for i, c in enumerate(self.characters)} # +3 을 왜하는 가?\n","        print(self.char2int)\n","        self.VOCAB_SIZE = len(self.characters)\n","        self.min_length = min_length\n","        self.max_length = max_length\n","        \n","        # train set or test set 을 생성 \n","        if type == 'train':\n","            self.set = [self._sample() for _ in range(4000)]\n","        else:\n","            self.set = [self._sample() for _ in range(300)]\n","\n","    def __len__(self):\n","        return len(self.set)\n","\n","    def __getitem__(self, item):\n","        return self.set[item]\n","\n","    def _sample(self):\n","        random_length = randrange(self.min_length, self.max_length)  # Pick a random length\n","        random_char_list = [choice(self.characters[:-1]) for _ in range(random_length)]  # Pick random chars\n","        random_string = ''.join(random_char_list)\n","        a = np.array([self.char2int.get(x) for x in random_string]+[2])\n","        b = np.array([self.char2int.get(x) for x in random_string[::-1]] + [2]) # Return the random string and its reverse + EOS \n","        \n","        return a, b\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7QcWCIsJzltc","colab_type":"text"},"source":["### utils misc.py\n","\n"]},{"cell_type":"code","metadata":{"id":"SciyvlCzBe-B","colab_type":"code","colab":{}},"source":["EOS_TOKEN = '</s>'\n","\n","\n","def check_size(tensor, *args):\n","    size = [a for a in args]\n","    assert tensor.size() == torch.Size(size), tensor.size()\n","\n","def to_mono(y):\n","    assert y.ndim == 2\n","    return np.mean(y, axis=1)\n","\n","\n","def edit_distance(guess, truth):\n","    guess = guess.split(EOS_TOKEN)[0]\n","    truth = truth[3:].split(EOS_TOKEN)[0]\n","    return editdistance.eval(guess, truth) / len(truth)\n","\n","\n","class AttrDict(dict):\n","  __getattr__ = dict.__getitem__\n","  __setattr__ = dict.__setitem__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a0Hv4JFBzM-4","colab_type":"text"},"source":["### Edit distance (편집거리 알고리즘) "]},{"cell_type":"markdown","metadata":{"id":"X4ct9e_OzuTT","colab_type":"text"},"source":["![대체 텍스트](https://raw.githubusercontent.com/sumitc91/data/master/askgif-blog/9e07d056-ccf7-4fc8-b6ee-000c8032b9ec_editDistance.gif)"]},{"cell_type":"code","metadata":{"id":"cwbk7k7h4PKB","colab_type":"code","outputId":"407843b1-4a47-4320-9650-6338e4f4a2fc","executionInfo":{"status":"ok","timestamp":1562221844301,"user_tz":-540,"elapsed":5297,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# edit distance 란 편집 거리 \n","\n","\n","ref = [1, 2, 3, 4]\n","hyp = [1, 2, 4, 5, 6]\n","editdistance.eval(ref,hyp)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"C1VtDggGzzs_","colab_type":"text"},"source":["### Attention Mask"]},{"cell_type":"code","metadata":{"id":"BOMNQN6Gj_-p","colab_type":"code","colab":{}},"source":["## 추후에 설명 Decoder section\n","def mask_3d(inputs, seq_len, mask_value=0.):\n","    batches = inputs.size()[0]\n","    assert batches == len(seq_len) # length 체크 \n","    max_idx = max(seq_len) # max length 체크 \n","    for n, idx in enumerate(seq_len): # length 에서 의미없는 hidden state attention 값은 0으로 두기 위한 mask값 설정 \n","        if idx < max_idx.item():\n","            if len(inputs.size()) == 3:\n","                inputs[n, idx.int():, :] = mask_value\n","            else:\n","                assert len(inputs.size()) == 2, \"The size of inputs must be 2 or 3, received {}\".format(inputs.size())\n","                inputs[n, idx.int():] = mask_value\n","    return inputs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kXtIVGUgHmws","colab_type":"text"},"source":["## Encoder RNN"]},{"cell_type":"markdown","metadata":{"id":"LdFDvktffm9k","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/encoder-network.png)"]},{"cell_type":"markdown","metadata":{"id":"Qf62OoGcwJP5","colab_type":"text"},"source":["#### Embedding Module "]},{"cell_type":"markdown","metadata":{"id":"c8mNg3ve8LmT","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/S0NJzq7/embedding.png)"]},{"cell_type":"markdown","metadata":{"id":"kH2OnZrXwOqk","colab_type":"text"},"source":["#### GRU Module"]},{"cell_type":"markdown","metadata":{"id":"goSiSeiq8bn-","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/881BygH/GRU.png)"]},{"cell_type":"markdown","metadata":{"id":"L_TIF6h58dZf","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/NsMqvcH/GRU-param.png)"]},{"cell_type":"markdown","metadata":{"id":"g-Z_vgd2wSAd","colab_type":"text"},"source":["#### ENCODER RNN Code"]},{"cell_type":"code","metadata":{"id":"8d__61m2HfFR","colab_type":"code","colab":{}},"source":["from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","class EncoderRNN(nn.Module):\n","    def __init__(self, config):\n","        super(EncoderRNN, self).__init__()\n","        self.input_size = config[\"n_channels\"]\n","        self.hidden_size = config[\"encoder_hidden\"]\n","        self.layers = config.get(\"encoder_layers\", 1)\n","        \n","        self.dropout = config.get(\"encoder_dropout\", 0.) \n","        self.bi = config.get(\"bidirectional_encoder\", False)\n","        embedding_dim = config.get(\"embedding_dim\", None)\n","        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n","        self.embedding = nn.Embedding(config.get(\"n_classes\", 32), self.embedding_dim, padding_idx=0)\n","        gru_input_dim = self.embedding_dim\n","        self.rnn = nn.GRU(\n","            gru_input_dim,\n","            self.hidden_size,\n","            self.layers,\n","            dropout=self.dropout,\n","            bidirectional=self.bi,\n","            batch_first=True)# model 선언 \n","        self.gpu = config.get(\"gpu\", False) \n","\n","\n","\n","    def forward(self, inputs, hidden, input_lengths):\n","        \n","        # pack padded 를 통하여 input을 감싸기 \n","        inputs = self.embedding(inputs)\n","        \n","        x = pack_padded_sequence(inputs, input_lengths, batch_first=True)\n","        output, state = self.rnn(x, hidden)\n","        output, _ = pad_packed_sequence(output, batch_first=True, padding_value=0.) # sequence 를 위의 그림과 같이 pack함 \n","        \n","        if self.bi: # bidirectional 의 경우 forward와 backward를 sum하여 사용한다. or concat \n","            output = output[:, :, :self.hidden_size] + output[:, :, self.hidden_size:]\n","            state = state[:1] + state[1:]\n","        return output, state\n","\n","    def init_hidden(self, batch_size):\n","        # hidden state가 없는 초기 상태일때 \n","        h0 = torch.zeros(2 if self.bi else 1, batch_size, self.hidden_size)\n","        if self.gpu:\n","            h0 = h0.cuda()\n","        return h0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l8yDzSXKHnyB","colab_type":"text"},"source":["### Decoder "]},{"cell_type":"code","metadata":{"id":"X83Lj_GBHojW","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, config):\n","        super(Decoder, self).__init__()\n","        self.batch_size = config[\"batch_size\"]\n","        self.hidden_size = config[\"decoder_hidden\"]\n","        embedding_dim = config.get(\"embedding_dim\", None)\n","        self.embedding_dim = embedding_dim if embedding_dim is not None else self.hidden_size\n","        self.embedding = nn.Embedding(config.get(\"n_classes\", 32), self.embedding_dim, padding_idx=0)\n","        self.rnn = nn.GRU(\n","            input_size=self.embedding_dim+self.hidden_size if config['decoder'].lower() == 'bahdanau' else self.embedding_dim,\n","            hidden_size=self.hidden_size,\n","            num_layers=config.get(\"decoder_layers\", 1),\n","            dropout=config.get(\"decoder_dropout\", 0),\n","            bidirectional=False,\n","            batch_first=True)\n","        if config['decoder'] != \"RNN\":\n","            self.attention = Attention(\n","                self.batch_size,\n","                self.hidden_size,\n","                method=config.get(\"attention_score\", \"dot\"))\n","\n","        self.gpu = config.get(\"gpu\", False)\n","        self.decoder_output_fn = F.log_softmax if config.get('loss', 'NLL') == 'NLL' else None\n","\n","    def forward(self, **kwargs):\n","        \"\"\" Must be overrided \"\"\"\n","        raise NotImplementedError"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcUzMxqV9Lr2","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/gvpn1RT/bmm.png)"]},{"cell_type":"markdown","metadata":{"id":"CBkw-82hE3MU","colab_type":"text"},"source":["![대체 텍스트](http://cnyah.com/2017/08/01/attention-variants/attention-mechanisms.png)"]},{"cell_type":"code","metadata":{"id":"IYbzCRP6HuLD","colab_type":"code","colab":{}},"source":["class BahdanauDecoder(Decoder):\n","    \"\"\"\n","        Corresponds to BahdanauAttnDecoderRNN in Pytorch tutorial\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(BahdanauDecoder, self).__init__(config)\n","        self.output_size = config.get(\"n_classes\", 32)\n","        self.character_distribution = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, **kwargs):\n","        \"\"\"\n","        :param input: [B]\n","        :param prev_context: [B, H]\n","        :param prev_hidden: [B, H]\n","        :param encoder_outputs: [B, T, H]\n","        :return: output (B), context (B, H), prev_hidden (B, H), weights (B, T)\n","        \"\"\"\n"," \n","        input = kwargs[\"input\"] # decoder input \n","        prev_hidden = kwargs[\"prev_hidden\"] # decoder rnn 에서 들어갈 previous hidden state \n","        encoder_outputs = kwargs[\"encoder_outputs\"] # encoder RNN에서 Encoding이 끝난 (B,L,hidden_size)  \n","        seq_len = kwargs.get(\"seq_len\", None) # sequence length \n","\n","        # check inputs\n","        \n","       \n","\n","        # Attention weights\n","        weights = self.attention.forward(prev_hidden, encoder_outputs, seq_len)  # B x T\n","        context = weights.unsqueeze(1).bmm(encoder_outputs).squeeze(1)  # [B x H]\n","\n","        # embed characters\n","        embedded = self.embedding(input).unsqueeze(0)\n","        \n","        #attention 을 통해 얻어낸 context를 추가하여 모델에 input으로 제공\n","        rnn_input = torch.cat((embedded, context.unsqueeze(0)), 2)\n","\n","        outputs, hidden = self.rnn(rnn_input.transpose(1, 0), prev_hidden.unsqueeze(0)) # 1 x B x N, B x N\n","\n","        \n","        output = self.character_distribution(outputs.squeeze(0)) # logit 값 각 chracter 별로\n","\n","        if self.decoder_output_fn:\n","            # NLL loss 인 경우 \n","            output = self.decoder_output_fn(output, -1)\n","\n","        if len(output.size()) == 3:\n","            output = output.squeeze(1)\n","\n","        return output, hidden.squeeze(0), weights\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHhtZXhUEQ64","colab_type":"text"},"source":["![대체 텍스트](https://i.stack.imgur.com/tiQkz.png)"]},{"cell_type":"code","metadata":{"id":"kYfGqtu0eqZy","colab_type":"code","colab":{}},"source":["class Attention(nn.Module):\n","    \"\"\"\n","    Inputs:\n","        last_hidden: (batch_size, hidden_size)\n","        encoder_outputs: (batch_size, max_time, hidden_size)\n","    Returns:\n","        attention_weights: (batch_size, max_time)\n","    \"\"\"\n","    def __init__(self, batch_size, hidden_size, method=\"dot\"):\n","        super(Attention, self).__init__()\n","        self.method = method\n","        self.hidden_size = hidden_size\n","        if method == 'dot':\n","            pass\n","        elif method == 'general':\n","            # Wa (hidden,hidden)\n","            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n","        elif method == \"concat\":\n","            # Wa : (2*hidden,hidden)\n","            # Va : (hidden,1)\n","            self.Wa = nn.Linear(2*hidden_size, hidden_size, bias=False)\n","            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n","        elif method == 'bahdanau':\n","            # Wa : (hidden_size,hidden_size) \n","            # Ua : (hidden_size,hidden_size)\n","            # Va : (hidden_size,1)\n","            self.Wa = nn.Linear(hidden_size, hidden_size, bias=False)\n","            self.Ua = nn.Linear(hidden_size, hidden_size, bias=False)\n","            self.va = nn.Parameter(torch.FloatTensor(hidden_size, 1))\n","        else:\n","            raise NotImplementedError\n","\n","        \n","    def forward(self, last_hidden, encoder_outputs, seq_len=None):\n","        \"\"\"\n","        Inputs :\n","          last_hidden : (B,T,hidden_size)\n","          encoder_outputs : \n","          seq_len:  \n","        Returns:\n","          attention matrix : \n","        \"\"\"\n","        batch_size, seq_lens, _ = encoder_outputs.size()\n","        # attention energies 를 구하기 \n","        attention_energies = self._score(last_hidden, encoder_outputs, self.method)\n","        \n","        if seq_len is not None:\n","            attention_energies = mask_3d(attention_energies, seq_len, -float('inf'))\n","\n","        return F.softmax(attention_energies, -1)\n","\n","    def _score(self, last_hidden, encoder_outputs, method):\n","        \"\"\"\n","        Computes an attention score\n","        :param last_hidden: (batch_size, hidden_dim)\n","        :param encoder_outputs: (batch_size, max_time, hidden_dim)\n","        :param method: str (`dot`, `general`, `concat`)\n","        :return:\n","        \"\"\"\n","\n","        # assert last_hidden.size() == torch.Size([batch_size, self.hidden_size]), last_hidden.size()\n","        \n","        if method == 'dot':\n","            last_hidden = last_hidden.unsqueeze(-1) # (batch_size, hidden_dim,1)\n","            \n","            # attention : (batch_size,max_time, hidden_dim) , (batch_size,hidden_dim,1) - > (batch_size,max_time ,1)\n","            \n","            return encoder_outputs.bmm(last_hidden).squeeze(-1)  \n","\n","        elif method == 'general':\n","            # dot 이랑 비슷 다만 last hidden을 한번 projection\n","            x = self.Wa(last_hidden) # (batch_size, hidden_dim) ->  (batch_size, hidden_dim)\n","            x = x.unsqueeze(-1) # (batch_size, hidden_dim) ->  (batch_size, hidden_dim,1)\n","            # encoded 된 hidden states 와 dot proudct를 수행하기 \n","            # attention: (batch_size,max_time, hidden_dim) , (batch_size,hidden_dim,1) - > (batch_size,max_time ,1)\n","            return encoder_outputs.bmm(x).squeeze(-1)\n","\n","        elif method == \"concat\":\n","            x = last_hidden.unsqueeze(1).expand_as(encoder_outputs) # (batch_size, hidden_dim) ->  (batch_size,1, hidden_dim)\n","            # concat 후 -> linear 거치기 -> 후 tanh\n","            x = F.tanh(self.Wa(torch.cat((x, encoder_outputs), -1))) # (batch_size, max_timestep, hidden_dim) ->  (batch_size,  max_timestep, hidden_dim*2)\n","            # (batch_size, max_timestep, hidden_dim*2) ->  (batch_size,  max_timestep, )\n","            return x.matmul(self.va).squeeze(-1)\n","\n","        elif method == \"bahdanau\":\n","            # mlp 기반의 attention model\n","            \n","            x = last_hidden.unsqueeze(1) # (batch_size, hidden_dim) ->  (batch_size,1, hidden_dim)\n","            # 각각을 projection 후 더하기 -> tanh \n","            out = F.tanh(self.Wa(x) + self.Ua(encoder_outputs)) # \n","            return out.matmul(self.va).squeeze(-1)# (batch_size,max_timestep,hidden_dim) ->  (batch_size, max_timestep)\n","\n","        else:\n","            raise NotImplementedError"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqeFcsDJ7Dz2","colab_type":"text"},"source":["### Seq2Seq Model "]},{"cell_type":"markdown","metadata":{"id":"jS2cmY548vtB","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/CK5wTz5/crossentropy.png)"]},{"cell_type":"markdown","metadata":{"id":"z_rIN2DY80pD","colab_type":"text"},"source":["![대체 텍스트](https://i.ibb.co/ssXZ28q/crossentropy-2.png)"]},{"cell_type":"code","metadata":{"id":"V-axgHRo7C5V","colab_type":"code","colab":{}},"source":["class Seq2Seq(nn.Module):\n","    \"\"\"\n","        Sequence to sequence module\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super(Seq2Seq, self).__init__()\n","        self.SOS = config.get(\"start_index\", 1) # Start index를 가져옵니다. \n","        self.vocab_size = config.get(\"n_classes\", 32) # embedding 에 필요한 vocabulary size \n","        self.batch_size = config.get(\"batch_size\", 1) # batch_size 정보를 가져옵니다.\n","        self.gpu = config.get(\"gpu\", False) # cuda 로 돌아가는지 아닌지에 대한 정보 \n","\n","        # Encoder 선언\n","        \n","        self.encoder = EncoderRNN(config)\n","\n","        # Decoder 선언 \n","        \n","        self.decoder = BahdanauDecoder(config)\n","        \n","        # loss fucntion \n","        # ignore_index =0 왜???\n","        self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=0)\n","        \n","        \n","\n","    def encode(self, x, x_len):\n","        # encoder를 통해 주어진 source 정보를 Encodeing 하는 용도 \n","        \n","        batch_size = x.size()[0]\n","        # 초기 inital hidden state 만들기\n","        init_state = self.encoder.init_hidden(batch_size)\n","        # encoder Forward 수행 \n","        encoder_outputs, encoder_state = self.encoder.forward(x, init_state, x_len)\n","        \n","        \n","       \n","        return encoder_outputs, encoder_state.squeeze(0)\n","\n","    def decode(self, encoder_outputs, encoder_hidden, targets, targets_lengths, input_lengths):\n","        \"\"\"\n","        Args:\n","            encoder_outputs: (B, T, H)\n","            encoder_hidden: (B, H)\n","            targets: (B, L)\n","            targets_lengths: (B)\n","            input_lengths: (B)\n","        Vars:\n","            decoder_input: (B)\n","            decoder_context: (B, H)\n","            hidden_state: (B, H)\n","            attention_weights: (B, T)\n","        Outputs:\n","            alignments: (L, T, B)\n","            logits: (B*L, V)\n","            labels: (B*L)\n","        \"\"\"\n","\n","        batch_size = encoder_outputs.size()[0]\n","        max_length = targets.size()[1]\n","        # decoder의 처음 y0 는 무엇이 되어야 할까? *주의해야할 포인트 \n","        if batch_size ==1:\n","          decoder_input = torch.LongTensor([self.SOS] * batch_size)\n","        else:\n","          decoder_input = torch.LongTensor([self.SOS] * batch_size).squeeze(-1)\n","        decoder_context = encoder_outputs.transpose(1, 0)[-1] #(Batch,1)\n","        decoder_hidden = encoder_hidden\n","        \n","        #alignments :  attention align을 저장하기 위한 용도  \n","        alignments = torch.zeros(max_length, encoder_outputs.size(1), batch_size) # attention align을 저장하기 위한 용도 \n","        logits = torch.zeros(max_length, batch_size, self.decoder.output_size) # logits 값을 저장하기 위한 용도의 tensor \n","\n","        if self.gpu:\n","            decoder_input = decoder_input.cuda()\n","            decoder_context = decoder_context.cuda()\n","            logits = logits.cuda()\n","        inference = []\n","        for t in range(max_length):\n","\n","            # The decoder accepts, at each time step t :\n","            # - an input, [B]\n","            # - a context, [B, H]\n","            # - an hidden state, [B, H]\n","            # - encoder outputs, [B, T, H]\n","            \n","            # The decoder outputs, at each time step t :\n","            # - an output, [B]\n","            # - a context, [B, H]\n","            # - an hidden state, [B, H]\n","            # - weights, [B, T]\n","\n","            outputs, decoder_hidden, attention_weights = self.decoder.forward(\n","                    input=decoder_input.long(),\n","                    prev_hidden=decoder_hidden,\n","                    encoder_outputs=encoder_outputs,\n","                    seq_len=input_lengths)\n","            \n","            alignments[t] = attention_weights.transpose(1, 0)\n","            \n","            \n","            logits[t] = outputs\n","\n","            \n","\n","            if  self.training:\n","                decoder_input = targets[:, t]\n","            else:\n","                topv, topi = outputs.data.topk(1) # 가장 높은 예측만 사용.\n","                decoder_input = topi.squeeze(-1).detach()\n","                inference.append(decoder_input.cpu())\n","\n","        \n","        labels = targets.contiguous().view(-1)\n","\n","        \n","        mask_value = 0\n","        #what is this mask_3d? # (warning check)\n","        logits = mask_3d(logits.transpose(1, 0), targets_lengths, mask_value)\n","        logits = logits.contiguous().view(-1, self.vocab_size) # loss를 구하기 위해 쫙 펴주기 \n","\n","        return logits, labels.long(), alignments,inference\n","\n","    \n","    def step(self, batch):\n","        x, y, x_len, y_len = batch\n","        if self.gpu:\n","            x = x.cuda()\n","            y = y.cuda()\n","            x_len = x_len.cuda()\n","            y_len = y_len.cuda()\n","\n","        encoder_out, encoder_state = self.encode(x, x_len) # encoder \n","        logits, labels, alignments,inference = self.decode(encoder_out, encoder_state, y, y_len, x_len) # decoder 를 통해 alignment와 logit 값 얻기 \n","        return logits, labels, alignments,inference\n","\n","    def loss(self, batch):\n","        logits, labels, alignments,inference = self.step(batch)\n","        loss = self.loss_fn(logits, labels) # loss 구하기 우리는 cross entropy 사용 \n","        return loss, logits, labels, alignments,inference"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xbOfjOmU6262","colab_type":"text"},"source":["### Train the model"]},{"cell_type":"markdown","metadata":{"id":"weB4hLTwfV3S","colab_type":"text"},"source":["![대체 텍스트](https://pytorch.org/tutorials/_images/seq2seq.png)"]},{"cell_type":"code","metadata":{"id":"NKYVKohKBmpS","colab_type":"code","colab":{}},"source":["def train(model, optimizer, train_loader, epoch,n_epochs):\n","    \n","\n","    losses = []\n","    cers = []\n","\n","    \n","    model.train() # train mode \n","    count = 0\n","    for batch in train_loader:\n","        loss, _, _, _,_ = model.loss(batch)\n","        losses.append(loss.item())\n","        # Reset gradients\n","        optimizer.zero_grad()\n","        # Compute gradients\n","        loss.backward()\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2)\n","        optimizer.step()\n","  \n","    print ('\\n [{}/{}] avg_loss= {:05.3f}'.format(epoch,n_epochs,np.mean(losses)))\n","    \n","    return model, optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0q5dl-qGtXB","colab_type":"code","colab":{}},"source":["def evaluate(model, eval_loader):\n","\n","    losses = []\n","    accs = []\n","    edits = []\n","    \n","    model.eval() # why?? \n","\n","    with torch.no_grad():\n","        for batch in eval_loader:\n","            #t.set_description(\" Evaluating... (train={})\".format(model.training))\n","            loss, logits, labels, alignments,_ = model.loss(batch)\n","            preds = logits.detach().cpu().numpy()\n","            \n","            acc = 100 *np.sum(np.argmax(preds, -1) == labels.detach().cpu().numpy()) / len(preds)\n","            edit = editdistance.eval(np.argmax(preds, -1), labels.detach().cpu().numpy()) / len(preds)\n","            \n","            losses.append(loss.item())\n","            \n","            accs.append(acc)\n","            edits.append(edit)\n","        \n","        align = alignments.detach().cpu().numpy()[:, :, 0]\n","\n","   \n","    print(\"  End of evaluation : loss {:05.3f} , acc {:03.1f} , edits {:03.3f}\".format(np.mean(losses), np.mean(accs), np.mean(edits)))\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWWvvbf68__6","colab_type":"text"},"source":["## 학습을 진행해보도록 하겠습니다"]},{"cell_type":"code","metadata":{"id":"N6zoFKQj8_MU","colab_type":"code","outputId":"777a8ad9-076d-4ee4-8c3b-2fd88ff008e5","executionInfo":{"status":"ok","timestamp":1562222904536,"user_tz":-540,"elapsed":1324,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["USE_CUDA = torch.cuda.is_available()\n","batch_size = 32\n","epochs = 6\n","dataset = ToyDataset(5, 15)\n","eval_dataset = ToyDataset(5, 15, type='eval')"],"execution_count":102,"outputs":[{"output_type":"stream","text":["{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9}\n","{'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PKechkHv9EXQ","colab_type":"code","colab":{}},"source":["train_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate, drop_last=True)\n","eval_loader = data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate,drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JapBBgq6KNp2","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"xh2HQkg59sND","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": True,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"bahdanau\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_h_LOmU-AEz","colab_type":"code","outputId":"5f8ad1a2-8fe6-4f5b-82f3-dd835dbc6706","executionInfo":{"status":"ok","timestamp":1562222904907,"user_tz":-540,"elapsed":775,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":105,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"_jXTGn9V-CuD","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ktMBioF-EAN","colab_type":"code","outputId":"54bb311d-9ccf-44d3-aaeb-b80afeea46a5","executionInfo":{"status":"error","timestamp":1562222977705,"user_tz":-540,"elapsed":73043,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":550}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":107,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["\n"," [0/6] avg_loss= 1.599\n","  End of evaluation : loss 1.469 , acc 58.6 , edits 0.330\n","\n"," [1/6] avg_loss= 1.003\n","  End of evaluation : loss 1.278 , acc 65.4 , edits 0.271\n","\n"," [2/6] avg_loss= 0.752\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-107-35dec0004425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-101-578b0403d5aa>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, eval_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m#t.set_description(\" Evaluating... (train={})\".format(model.training))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malignments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-9d481b0e742e>\u001b[0m in \u001b[0;36mpad_collate\u001b[0;34m(batch, values, dim)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtgt_max_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# pad according to max_len (max length 만큼 padd를 추가 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# stack all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-9d481b0e742e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtgt_max_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# pad according to max_len (max length 만큼 padd를 추가 )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# stack all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-47c58731b38b>\u001b[0m in \u001b[0;36mpad_tensor\u001b[0;34m(vec, pad, value, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"5RNRT6acajT5","colab_type":"text"},"source":["### 시각화"]},{"cell_type":"code","metadata":{"id":"cQ77ZlPKal2j","colab_type":"code","colab":{}},"source":["import seaborn\n","\n","def draw(data, x, y):\n","    seaborn.heatmap(data, \n","                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0, \n","                    cbar=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3fVzxjganHg","colab_type":"code","colab":{}},"source":["def visualize_plot(model,custom_input= 'cgdafa'):\n","    c_xs = np.array([dataset.char2int.get(x) for x in custom_input]+[2])\n","    c_xs = torch.from_numpy(c_xs).unsqueeze(0).long()\n","\n","    c_xl = torch.tensor(c_xs[0].size()[-1]).unsqueeze(0)\n","\n","    c_ys = np.array([dataset.char2int.get(x) for x in custom_input[::-1]] + [2]) # Return the random string and its reverse + EOS \n","    c_ys = torch.from_numpy(c_ys).unsqueeze(0).long()\n","\n","    c_yl = torch.tensor(c_ys[0].size()[-1]).unsqueeze(0)\n","    c_data = (c_xs,c_ys,c_xl,c_yl)\n","    loss, logits, labels, alignments,predict=model.loss(c_data)\n","    heat_map_value = alignments.detach().cpu().numpy()[:, :, 0]\n","    preds = logits.detach().cpu().numpy()\n","    preds = np.argmax(preds, -1)\n","    source_tokens = [ dataset.int2char[item-3] for item in c_xs[0] if item!=0 if item !=2 ] +['</s>']\n","    target_tokens = [ dataset.int2char[item-3] if item !=2 else '</s>' for item in preds.tolist() if item!=0 ]\n","    draw(heat_map_value,source_tokens,target_tokens)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IkbDmwaY4BG","colab_type":"code","outputId":"61bbefc6-f251-4e27-b9db-50dc836a08a0","executionInfo":{"status":"ok","timestamp":1561647573965,"user_tz":-540,"elapsed":67242,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":324}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng5caMXipkf8Bw5yzphbon6EAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"ZZdAsEpjcC0V","colab_type":"text"},"source":["### Dot Mode "]},{"cell_type":"code","metadata":{"id":"T8X3wWrrewkY","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xHTy6m9k7XU","colab_type":"code","outputId":"a0b6a5ce-ba72-4c5b-9d72-cb70cecab7f9","executionInfo":{"status":"ok","timestamp":1561647573967,"user_tz":-540,"elapsed":67217,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LuAGn6wOcMAU","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6NNv1KexcOQh","colab_type":"code","outputId":"925e66f2-eced-4f41-94a2-0abe39db14ae","executionInfo":{"status":"ok","timestamp":1561647639812,"user_tz":-540,"elapsed":133059,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["\n"," [0/6] avg_loss= 1.748\n","  End of evaluation : loss 1.569 , acc 55.1 , edits 0.361\n","\n"," [1/6] avg_loss= 0.945\n","  End of evaluation : loss 1.084 , acc 75.6 , edits 0.177\n","\n"," [2/6] avg_loss= 0.526\n","  End of evaluation : loss 0.623 , acc 89.1 , edits 0.074\n","\n"," [3/6] avg_loss= 0.307\n","  End of evaluation : loss 0.563 , acc 89.8 , edits 0.070\n","\n"," [4/6] avg_loss= 0.355\n","  End of evaluation : loss 1.199 , acc 79.4 , edits 0.133\n","\n"," [5/6] avg_loss= 0.321\n","  End of evaluation : loss 0.353 , acc 95.0 , edits 0.029\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"48ACZ__zcgz3","colab_type":"code","colab":{}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZio7ZpScXWf","colab_type":"text"},"source":["### Concat Mode "]},{"cell_type":"code","metadata":{"id":"rlEMn4CDcVdv","colab_type":"code","colab":{}},"source":["config = {\n","  \"decoder\": \"Bahdanau\",\n","  \"encoder\": \"RNN\",\n","  \"n_channels\": 4,\n","  \"encoder_hidden\": 64,\n","  \"encoder_layers\": 1,\n","  \"encoder_dropout\": 0.2,\n","  \"bidirectional_encoder\": False,\n","  \"decoder_hidden\": 64,\n","  \"decoder_layers\": 1,\n","  \"decoder_dropout\": 0.2,\n","  \"n_classes\":dataset.VOCAB_SIZE+3 ,\n","  \"batch_size\": 32,\n","  \"embedding_dim\": 64,\n","  \"attention_score\": \"concat\",\n","  \"learning_rate\": 0.001,\n","  \"gpu\": True,\n","  \"loss\": \"cross_entropy\"\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvMOke61cbvf","colab_type":"code","outputId":"147fd31e-e2b9-40d8-dcea-68930ee082a4","executionInfo":{"status":"ok","timestamp":1561647639815,"user_tz":-540,"elapsed":133060,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["model = Seq2Seq(config)\n","model = model.cuda()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xCRpTxKVcc__","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=config.get(\"learning_rate\", .001))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjbdwe3jcfFD","colab_type":"code","outputId":"cb04ef03-d5de-42dc-8969-a38da098a1d1","executionInfo":{"status":"ok","timestamp":1561647810800,"user_tz":-540,"elapsed":66738,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["for epoch in range(epochs):\n","  model,optimizer  = train(model,optimizer, train_loader,epoch,epochs)\n","  evaluate(model,eval_loader)\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["\n"," [0/6] avg_loss= 1.759\n","  End of evaluation : loss 1.575 , acc 55.8 , edits 0.359\n","\n"," [1/6] avg_loss= 1.008\n","  End of evaluation : loss 1.170 , acc 71.6 , edits 0.215\n","\n"," [2/6] avg_loss= 0.525\n","  End of evaluation : loss 0.780 , acc 84.9 , edits 0.111\n","\n"," [3/6] avg_loss= 0.333\n","  End of evaluation : loss 0.682 , acc 88.3 , edits 0.082\n","\n"," [4/6] avg_loss= 0.177\n","  End of evaluation : loss 0.831 , acc 86.4 , edits 0.084\n","\n"," [5/6] avg_loss= 0.184\n","  End of evaluation : loss 0.261 , acc 96.8 , edits 0.020\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uhnkBB82chid","colab_type":"code","outputId":"23c3b0d8-8ffc-4ded-b851-9b6e79146e1c","executionInfo":{"status":"ok","timestamp":1561647810801,"user_tz":-540,"elapsed":62529,"user":{"displayName":"Cheonbok Park","photoUrl":"https://lh3.googleusercontent.com/-IBOYs9WOjak/AAAAAAAAAAI/AAAAAAAABAk/gDfiXuRJUhA/s64/photo.jpg","userId":"16050539117346266781"}},"colab":{"base_uri":"https://localhost:8080/","height":324}},"source":["visualize_plot(model,'cbada')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlxoxeKkRg5caMXipEYOXGjF4qZH/BZa9zCnpGkzXAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"uMzGeSiUdZRo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}