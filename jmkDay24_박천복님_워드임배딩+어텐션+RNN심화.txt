jmkDay24
<워드임배딩+RNN+어탠션>
1# oh
1.간단0,1로만 구현
2. 유사도 구분 못함

2#워드임베딩?
= 디스트리부트 레프리테이션
예) 포유류를 구하고자 할때, 포유류라는 벡터가 있고 이게 여러 곳에 픝뿌려져있음.  

3)정보가 한곳에 있는게 아니라 여러곳에 뿌려져있다(=디스트리부트 레프리제이션)
*벡터로 표현될떄 장점) 크기+방향 있음.
-아까의 단점. 비슷한것들이 가깝게 표시가 되고, 좀 차이가 있으면 떨어져서 표현됨
- 메모리 수도 줄어들게 됨. (디맨젼 줄어들 수 있기때문)


4)# 워드 임베딩 학습 방법?
- 주변 컨택스트 기반으로 맞추게 함. 

5#)비쥬얼화 하게 되면 이렇게 나타나게 되어요. 
가치있는 이유: 주변 단어들이 비슷하기 때문.
	- 예) is, was, were이 있으면 비슷한 단어들이 주변에 있기 때문

6) 워드투백은 의미론적 매칭 잘되니?
- 응 남자-여자=킹-퀸

7)수많은 데이터(코퍼스)따라 워드투벡 달라질 수 있음.
- 전제) 많은 데이터가 있는 곳 긁어옴
	> 위키 
8) 워드 투백의 알고리즘
- 주변단어들을 인풋으로 주고, 아웃풋으로는 그 중심 단어를 예측합니다. 

9)주변단어들을 인풋으로 주고, 아웃풋으로는 그 중심 단어를 예측합니다. 
우리가 할 수 있는 예제) w1,w2,w3,w4,w5
	1) w3기준으로 w1,w2 각각 예측하기 
	2) w3 제외한 것들 토대로 w3예측

##주변단어들을 인풋으로 주고, 아웃풋으로는 그 중심 단어를 예측합니다. 
우리가 할 수 있는 예제) w1,w2,w3,w4,w5
	1) w3기준으로 w1,w2 각각 예측하기 
	2) w3 제외한 것들 토대로 w3예측. 

1) w3은 어쩔 수 없이 원핫인코딩 [0 0 0 0 01 0]해야하고, 이건  매트릭스,
	벡터(임베딩 디맨션)이 있음.           7*4의 대맨션

예측할 것과 예측될 거(7*4)가있을거에요 . 7은 우리의 워드가 들어갈 부분.
이 4개의 디맨션과 우리것들 각각 곱해요. 원하는 것은 쭉 나오는 확률값들이
각각 1,2,3,4,5의 위치가 높아야 하는거. 나머지 확률은 낮아야하고.

예) 1의 소프트맥스1, 2의 소프트맥스 1....이어야 해. 
질문) 근데 왜 다 1이 되나? 1이 쉽게 되는가?
- 주변으로부터 중심 학습이 되게 하는게 쉬운편. 
- ,HIDDEN으로 곱해직, 이게 아웃풋으로 나오게 하는 로짓을 예측하는게 주변단어 예측
== 오코인코더

#False of dimension(차원의 저주)
- 각 사분면마다 데이터가 존재해야 학습이 될겁니다. 
- 데이터 공간이 커지면 특성을 분리할 수 없어요. 예) 공간 작으면 더 가까이 앉고, 넓으면 멀리
			>> 여기서 패턴을 찾을 수가 없어. 그래도 친한 사람끼리 가까이있으
			그래서 차원을 줄이는게 의미론적으로 괜찮아보여. 
			>> PCA가 의미론적관점에서 의미잇는이유.
-> 이렇게 하기위해 '오토인코더'로 줄임. 

#오토인코더
예)2천 데이터를 200개의 디맨션으로 줄이고,
다시 2천 디맨션으로 펴주고자 해. 그러면 이 모델의 목적 함수는 x에 대해서 wx가 에이치 프라임 되어 넌리니어 될 수 있어요. 그래서 원래 벡터인 x를 복원시키는거에요
== 전체 큰 디맨션 있는거 줄여서 프록션 시키고 이걸 다시 원래대로 복구 가능== 이는 찌부를 시켯을 때도 '정보의 손실'이 없음. 근데 이걸 적당히 쪼갠다면 정보 잃을 수 밖에 없어.
오토인코더== 인풋이 자기자신이고 아웃풋으로도 자기가 나오게 하는 학습법. |x-x^|=0

# [워드투벡 오버뷰]
1. 전체 데이터로 다 할 수 없으니, window 사이즈를 지정해줍니다
2 윈도우 사이즈에 대한 데이터에 대해서만. into가 있을떄 turning 나올 확률, banking이 나올 확률등을 각각을 높여주는 방식으로 학습합니다.

# [주의] 시퀀스X.?

# * Likelihood
- 머신러닝 모델은 라이클리후드 높이는거로 학습
- 닮음. 이런거 생각나죠?
- 주어진 데이터에 대해 초대한 닮도록 학습하게 하는ML
- 예) 핸드폰을 보고 사람은 스마트폰이라고 대답하는
데이터(인풋)에 대해서 정확히 모방을 했다고 한다면
모든 정보를 학습한것. 
핸드폰을 회전시켜서 본 모습에도 잘 맞출 확률.
- 이를 로스값으로전환이  되기도 합니다.
- 주어진 인풋 (티에 인풋을 줄때) 그에 대해 Yt로 나올
확률인데 이걸 모든 데이터에 대해 확률로 곱해
- 이게 1일떄 머신러닝 성능이 좋은 것.

#  왜 우리가 이렇게 학습 안하고 로그 씌운거 보나?
- 지금 머신이 확률값일때문제가 0.01,0.9의 숫자가
너무 많이 곱해지면 언더플로가 생겨서 사라짐.
		> 따라서 로그를 씌워줘야함
		> 로그를씌우는건 확률값이고 계산편리!


# 우리의 목적: 세타찾기(라이클리후드 최적화)
# 단점) 트레이닝 데이터에 대해 최적화를 하다보니
	이 데이터가 잘못된거라면 모방도 잘못된거.
	그러면 오버피팅이 생길 수있음 .
	따라서 라이클리후드 기반은 오버피팅이 생길수
>> 맥시멈 라이클리후드 에스테이메이션 (MLE)해야해



# 오브젝티브 펑션
- 라이클리후드를 최적화해야하니까  (목적) 데이터를 모방하기 쉽게


# 워드 임베딩(오버뷰)
- 사용하고자 하는 것 
	- : 센터워드 쪽에 임베딩 추출(인풋>히든레이어), 컨택스 쪽에 임베딩 추출(히든>아웃풋레이어)
- 센터워드 관점인지 알고 싶은
	- 인풋>히든래이어: 워드의 갯수* 임배딩 갯수
- 컨택스드 워드가 am인지 are인지 알고 싶죠. 컨택스드 워드(내가 주변과 얼마나 관련잇는지)
	- 주어진 데이터가 i와 m이 나와서 예측을 하고 시펑.

# 내적
- 백터의 연산중에서 내적이라는게 있어요. 이공계는 기하벡터에서 배웠을거에요
- 에이벡터와 비벡터가 있으며 프로..시켜주는거야. 그래서 가장 클때는 이 각도가 가장 작은 0도 일떄
같은 위치에 있을때 가장 클거에요. 
- 그러면 닷프로적트는 벡터의 유사도를 측정하는거에요. 
- 에이벡터가 1,2이고 비벡터가 3,4이면 각 엘리먼트를 곱해주면 되는거에요
- 그러면 그 곱해준거 스칼라 값이 (여기서는 11)이 유사도에요

#각 임베딩에서 닷프로덕트
- i가 나올때 m이 나오는 유사도.
- 그러면 이 두개의 유사도가 같아지는거에요

# 투벡터 쓰는 이유?
- 같은 벡터를 쓴다고 하면? 같은 방향인데 커요. 우리 스케일 프로덕트는 같은 ㄴ방향이면 커요. 컨택스드워드는 자기 자신이 같죠. 무조건. 그건 말이 안돼. 
주변 단어에 자기가나오지  않으니 옵티마이즈 힘들어져. 그래서 컨택스와 콘일때 두가지로 해서 보게 하는거에요. 그래서 2백터 사용하는거에요.
						==내가 자신인데 나보다 최적화가 높아야하는데 그건 말이 안되서 학습이 안되니 방지하고자 2벡터로 쪼개 사용

투벡터 쓰는 이유?
- 같은 벡터를 쓴다고 하면? 같은 방향인데 커요. 우리 스케일 프로덕트는 같은 ㄴ방향이면 커요. 컨택스드워드는 자기 자신이 같죠. 무조건. 그건 말이 안돼. 
주변 단어에 자기가나오지  않으니 옵티마이즈 힘들어져. 그래서 컨택스와 콘일때 두가지로 해서 보게 하는거에요. 그래서 2백터 사용하는거에요.
						==내가 자신인데 나보다 최적화가 높아야하는데 그건 말이 안되서 학습이 안되니 방지하고자 2벡터로 쪼개 사용


# 
1. 메모리 코스트가 커서 학습할 수 없었음(그래디언트 써도)
해결
- 네거티브 샘플링 시도
	- 모두 소프트 맥스에 계산말고 추출해서 하자
	- 내가 센터워드일때 콘택스드..
	- 간단한 아이디어) I일떄 am을 예측하고자 해요 I가 센터로
	있고 am 이 콘텍스에 있을때 얘네 올라가면, 나머지 애들
	are/were/you 등은 곱했을때 유사도 낮추면 반대로 i/am은 올라가.

: 콘텍스드 워드 뽑고 얘네 유사도 증가하고, 나머지는 유사도 감소
: 해당되지 않는 애들 샘플링하여 얘네 유사도 낮추기

I go to the school
대해 임베션 하고, to에 해당하는 닷프로덕트가
높아지게 학습하는게 씨보오

to 하나만 가지고i/go/the/school 예측하는게 skip gram

#이 두개의 차이 (워드투백) 알아두는게 중요
I go to the school
대해 임베션 하고, to에 해당하는 닷프로덕트가
높아지게 학습하는게 씨보오

to 하나만 가지고i/go/the/school 예측하는게 skip gram

# 두 단어가 얼마나 같은 문서에 많이 등자했는지로 워드간 유사도 구할 수도 있어요

#같은 문서 내에서 ice 나올때 solid가 나올 확률은 높아. 근데 
steam과 solid 나올 확률은 적은거에요. 그래서 gas일떄는 스팀이 나올게 크겠죠
워터일때는 둘다많이  나오고 랜덤일때는 다 작아. 즉 코어커런스(두개가 같이
일어날 빈도수) 통해서 의미를 알 수 있어요.  

#이거 보케뷸러리 만큼 뽑고 아이/라이크 등등이 몇 번 나오는지 보고, 자기 자신은 제외해서 카운트를 만듭니다.
이게 브이 곱하기 브이가 나와야해요. 그걸 싱글러 별로 디컴포지션 SVD(어려워서 설명 불가 선형대수)

사용할 수 있어요. pca 친구. 이거 통해서 얘로 차원을 줄일 수 있어요. 매트릭스를 백..하는거에요.
10*10=(10*4)(4*4)(4*10) 이렇게 임베딩 할 수 있죠. 10*4로 이렇게 줄일 수 있죠. 매트릭스 팩토라이즈 하는데
얘네는 그래디언트로 예측해서 오브젝트 펑션하는거 안하고 바로 싱글러 디컴포지션 하면 딱 나와요. 

# 이 방법의 단점: 카운트로 했기에 카운트가 높을수록 결과가 높을 수 있으나, 단어가 많이 나온게 그리 좋은것 만은 아니야. 그래서 이런 단어 a the 에대해서  
맥스 카운트를 100으로 하고 너무 작게 나오면 이그노어해. 전체포커스하면 노이즈 크니까 여기도 윈도우 사이즈 정해주는거야.카운트 대신 코릴레이션을 피어스로 구해


# 글로브 임베딩) 주어져있는 가각 워드에 대한 닷프로덕트 값이 솔리드/아이스 있으면 그 닷프러덕트 스칼라 값이 두 워드가 같이 나타날 확률 빈도와같아야해
장점) 브이곱하기 브이를 sv-로계산 안해도 되서 편해. 프리퀀시가 높으면 상대적으로 강할 수 있으니 일정 크기 이상이면 ㄴ가중치 낮추는 식으로 ㄴ
			너무 높은 빈도수 애들 낮출 수 있고 그래서 글로브 임베딩 쓰면 코이너로 학습한 새로운 임베딩. 이런 벡터로 만들어지는게 글로브 임베딩
			츠렉티컬하게는 글로브를 맣ㄴ이 써요 엔엘피는. 그리고 씨보어나 스킵..을 쓰기도 합니다.


# 워드 임베드 주는게 좋으ㅏ
- 트레이닝 데이터는 적어요
- 센티만탈 하게 되면 10만개가 넘을
확률이 적고 기껏해야 1만개. 
- 우리가 학습하는 워드 임배딩은
20만개를 또 따로해서 학습해야해
익언 학습 데이터 더많이 해서 나오니
성능이 좋을수 밖에 없고 그래서
제너럴라이즈하기 좋아

# 임베딩 없다며9ㄴ?
- 랜덤하게 주고 더블유 파라미터처럼
엔드투엔드로 해요. 
- 임베딩 있으면 이렇게 쓸 수가 있음
- 근데 실제 트렌드는 임베딩 쓰기고 하나
안쓰는게 추세
- 워드 기반의 임베딩이 의미 잇다는게문제

여담) # 임베딩 없다며9ㄴ?
- 랜덤하게 주고 더블유 파라미터처럼
엔드투엔드로 해요. 
- 임베딩 있으면 이렇게 쓸 수가 있음
- 근데 실제 트렌드는 임베딩 쓰기고 하나
안쓰는게 추세
- 워드 기반의 임베딩이 의미 잇다는게문제

여담) 한국어. 간다/갑니다/가요/갈거야
라고 할 수 있는데 이건 '간-' '-다'가
서브워드 방식. subword로 쓰는거죠.
토큰을 썼을때 i / am/ playing /tennis 라고할때 워드토큰으로하면 각각하나 서브워드로 하면 playing이 play+ing가 됩니다. 이건 워드 자체가 너무 커지는문제를  방지가능
* replay는 따로 토큰을 만들 필요없이 re+play만 사용하면 되어 보케블러리 줄고, 단어가없어서  생기는 문제도 방지가능. out of vocabulary. 

#워드투백에서 히든통해 디맨션줄였다 키워요?
- 보캡 크기만큼 쓰게 되면 패턴이나 시간이 안 모여 있어서 피쳐 학습이 어렵고 의미론적으로 매핑이 되지 않을거에요. 디맨션을 줄이게 되면 훨씬 모델이나 데이터 자체로서 잘 학습이 되어 잘 돌아갈거에요
- 예측은 보캡을 해야하는거니까 그 크기대로 다시 키우는겁니다

# 딥러닝
- cs231n 스탠포드. 강의를 들으세요. 
- 다만 장벽은 모두 영어. 느리진 않고. 토익의 듣기 속도의 1.5배 
- 책은 굳이 보지마세ㅐ용

#윈도우
- 컨택스드 워드를 고려하는거에요
- 윈도우사이즈2는 왼쪽과 오른쪽 각각 2씩 보겠다는 것

#RNN==============================================
리컬시브
CNN은 사실 연결 단계가 없는거. 이미지 하나만 내고, 다음엔 영향 받는게 없음
RNN은 이전의 이미지가 다음의 인풋으로 나오기에 이전의 것이 반영됨. 메모리 셀이 전달이 됩니다. 


##각각 구조를 알아야해요
- 백본을 알아야 프로젝트시 수여
- 원투원: 씨앤앤. 클래시피케이션하여 아웃풋 하나 나오는거
- 원투 매니: 이미지 캡셔닝. 이미지 주고 디스크립션 하게 되는것. 타자가 공을 친다. 피쳐가 공을 던지다.
- 매니투원 : 여러가지가 하나로 가는 것으로, 시퀀스. nlp에서 시퀀스오면 분류하는 문제. 센티맨탈클래시피케이션. 시퀀스오브 월드로 
- 매니투매니: 보통은 머신 트랜스래이션. 한국어 문장에 대해서 영어로 번역하는 식. 대표적인 매니투매니


#RNN
- 펑션은 시퀀스마다 동일하게 공유되고 중요한건 '올드스테이트'
- 이전 스테이트와 현재를 고려하여 현재의 뉴 스태이트를 만드는것. 리컬시브한 연산
- 컴퓨터입장에서 이 느낌은 튜링 머신과 유사함.
- 튜링 컴플릿하다고 해요. 알엔에은 모든 계싼 문제 풀고 컴퓨터 모델링 가능

# 시퀀스가 있는건 진행ㄴ을 하고

# 캐릭터 레벨 랭귀지 모델
- 아마 의아할텐데
- 인풋이 원핫으로 보이죠. 1과0만있는듯
- 근데 실제로는 원핫을 임배딩으로 두는걸 하나 추가적으로 두고 그 임배딩에
- 더블류 엑스 에이치를 곱하는 식으로 사용하곤합니다. 
- 그리고 이전의 히든 시테이트 고려해서 웨이트 에이치에이치를 탄에이치 펑션 이용해 나타남

# 에ㅐ이치 원
 - 초반에 영으로 이니셜라이즈 하곤해

# 시퀀스투시퀀스 주의
-트레이닝과 테스트 인풋이 달라요
- 실제로 테스트 한다 생각을 하면 h넣어 e 나온다 하면, 이 넣어서 아이 나오고. 
- 이렇게 하면 트레이닝은 애매. 알엔엔이 처음에 랜덤하니까 아무거나 넣겠죠
- 예를 들어서 에이치> 오>엘>아이>에스가 나오는 식이면 총체적 난관.
- 로스 펑션이라고 하면 에이치 오가 나왔을때, 엘이 오랑 에이치가 인풋이면 엘이 나오는건데
- 이거 가정이 잘못되었죠
- 만약에 테스트 할때는 결과를 다음 인풋으로 넣는단건데, 트레이닝에서는 그러면 아 ㄴ돼
 - 트레이닝은 뭐가 나오든 그라운드 (정답)을 넣어줘요. 올바르게 행동했을떄의 정답.***
- 트레이닝할때 옵티말을 배우면 얘네는 생성하게 하는 것은 무조건 원래 우리가 원하는 정답이 목표일테니
- 문제) 하지만 이런 차이가 되는게 문제
	- 알엔엔에서는 항상 인풋이 좋은 값이라는 문제가 생김.
	- 모델이 잘못 배워서 순간적으로 실수를 하게 되었어. 
	- 갑자기 h e l l 하고 e 가 나와서 깨지면 계속 e  e e 나오며 모델이 이상해 질 수 있음.  
- 해결 테스트)많이 있음
	-  일단 처음 학습할때는 그랑누드 넣고 하나씩 정답이라 생각하고 교정하는게 일반적
	- 실수말것) 생성된거 할때는 정답 말고 그대로 인풋 넣어줘야해


# BPTT
- Backpropagation through time
- 우리가 문장이 존재하잖아요. 이 랭기지 모델을 한다 했을떄
- i go to the school , when i go to the lah.
- 이렇게 문장이 이어지면 쭉 되면 rnn의 시퀀스 길이가 무한정 길어지게 됨
- 백 프로파하기위해서 너무 커져서 메모리 문제
- 그래서 이걸 잘라서 학습을 시키는 거에요.
- 시퀀스가 있다면 일에서 다섯번째를 하나의 데이터 시퀀스로 생각해서 학습시키고
- 여기서의 히든을 다음번째의 인풋으로 넣고 또 이거 결과를 다음번 히든으로 보내
- 백프로파는 메모리가 무한정 많고 알엔엔에게 학습시키면 좋으나 로스 흐를 가능성도 높고
- 그래서 잘라주는거에요. 시퀀스가 30이면 10씩 자르고 대신에 초기 이니셜은 0 말고
- 이전의 시퀀스에서 나온 히든 스테이트를 이니셜라이즈
- 그러면 적어도 멀리 있는 정보가 잃어지진 않겠죠


#
- ㅇ생각해보세요
- 알엔엔은 렐루 말고 탄에이치를 선택했을까
- 컨벌레이어는 렐루쓰는데 왜 여기서느 ㄴ굳이 탄에이치를 쓸까
- 선생님 생각에서는 언어가 긍정 부정이 나뉘어있죠. 그래서 그런거 모델하려면 
렐루는 음수가 없어서 정도가 나타나지 않아
- 근데 탄에이치는 마이너스 플러스가 있어서 가능
- 그래서 부정은 마이너스, 긍정은 플러스에 가까워서 언어 모델에 적합하다 생각 가능

# 누군가가 한 테스트 
- 인용마크일떄 긍정
- 인용 끝나면 빨갛고해
- 그럼 자기와 이전 스테이ㅋ트 봐서 바뀌는게 없으면 그대로 부정으로 하고, 인용이 나오면 긍정이 나오게 하는식
- 그래서 인용마크가 나오면 변경하는 식으로 동작하게 할 수도 있음

# RNN 큰 문제 2가지
- 이거로 lstm 나왔어
- 그래디언트 배니싱
- 익스플로
- 그래서 엘이스티엠이나 지알유 사용
- 왜 생기는지는 하이레벨적으로 아는게 좋아요.

# 체인룰 생각- 배니싱 예시
- 탄에이치에서 웨이트 부분이고 머신러닝 및 딥러닝에서 더블유가 평균이 영에 가깝고 일보다 크진 않아
- 그러면 기본적으로 곱해질수록 저 값은 계속 작아지게 되어요.
- 그래서 알엔엔에서 계속 곱해져서 시퀀스 길어지고 참여율이 없어지게 돼 초기값.
- 그런데 이게 중요해요 예를 들어서 영어에서 수일치 문제 풀면
- 처음에 매니 피플 오브 뭐뭐하고 주격관계대명사 나오고 그러다 주어가 나오면
- 매니였으니까 이제 나올게 정해져있는데 잘못 생성했어. 그건 앞에것 잘 보면 알았을 문제인데
- 이거 수식어 읽다가 초기에 값을 까먹는 식이야.
- 그럼 앞에것 수정하고 싶어도 영향력이 미치지 않으니 바꿀 수가 없는 문제가 생기지

# 익스플로딩 예시
- 만약에 더블ㅇ 엥치ㅣ가 작지만 오히려 계속 곱하면 운이 좋게 값이 증가하게 되는거야
- 일보다 크면 오히려 값이 커지겠죠. ㄱ
- 그런 경우에는 그래디언트가 증폭이 되니까 익스플로딩이 될 수밖에 없음


#  그래디언트 크면 안돼
- 너무 깊게 믿으면 발등 찍혀
- 그래서 익스플로딩으로써 업데이트가 안될 수도 있음
- 워스트하면 익스플로가 인피니티 및 넌값으로 학습이 안되면 익스플로딩 고려

# 그래디언트 익스플로딩 푸릭
- 그래디언트르 클래핑
- 첫번째의 디맨션이 10과 20대의 값이나오면 이 최대를 1로 픽싱하여 클리핑
- 그러면 갑자기 확 뛰어버리는 문제를 해결할 수 있음.




# 알엔엔 어떻게 수정?
- 하나의 스테이트에 다 쓰고 지우는게 문제
- 암기 문제를 푼다고 할떄 다 보고 머리속에 기억하고 내뱉지 않죠
- 수업도 듣고 메모리같은데 써두듯이
- 우리가 전체적인 정보를 담을 수 있는 그런 메모지를 만들게 하는식
- 메모리 셀 추가한게 lstm.
- 인간으로 치면 메모지. 그래서 이걸 바탕으로 모델이 예측 잘하게 하고
- 과거에 어떤거 인코딩했는지 셀을 담아서
-모델로 하여금 과거의 정보를 빠르게 가져올하이웨이 갖고오게해
- 이게 바로 엘에스티엠

# 엘에스티엠
- 세개의 게이트(인풋, 포겟, 게이트 게이트)와 탄에이치 하나로 구성이 되어있어요
- 하이레벨로 말하면 이전에 바날라 알엔엔은 모든 부분의 레지스터를 다 읽고 한번에 업뎃하는 식
- 그런데 이거를 그대로 유지해야할때는 어떻게 해야하나.더블류 따로 했어야해
- 모든걸 다 읽고 모든걸 다해(메모를 한번보고 다른 정보 들어오면 다 지우고 다시 쓰는 식)
- 그러면 이걸 잘하려면 원래거에 수정할 부분만 수정하면 되겠지요. 그게 쥐알유와 알에스티엠
- 히든에서 원하는 특정 디맨션만 뽑아와서 수정할 양이나 위치를 정합니다.-
- 그 중에서 덧붙일 부분에 추가적으로 써서 업데이트 하는식
- 그러면 아무것도 안바꾸거나 조금만 수정을 하고자 할때 이전 정보를 잘 유지할 수 있어요
- 메모지를 생각하면 좋아요. 메모지를 다 찢어서 다 적는거 아니면 추가된 정보 일부만 덧붙이는거
- 어떤게 정보 안 잃고 이어나갈 수 있는지. 일정만 수정하는게 더 좋아요
	- 인풋게이트:어디 읽을지
	- 포겟 : 어디 지울지
	-라이트 게이트: 어디를 쓸지
	- 그래서 모델로 하여금 정보를 기억해서 전달하게끔. 이게 엘이스티엠 및 쥐알유 하이레벨적


# 쥐알유
- 특징: 게이트가 상대적으로 3개뿐.
- 업데이트/리셋/ 히든을 업데이트 하는 게이트라기보다 탄에이치
- 엘에스티엠보다 하나가 적어. 
- 즉 엘에스티엠은 복잡한거에 좋고, 쥐알유는 메모리 적게 빠르게 하고 싶을떄 좋은 선택.
- 왜냐하면 쥐알유가 파라미터가 적어서. 그래서 학습도 빠름ㄴ

# 프로젝트
- 첫번째로 쥐알유 도입
- 그다으메 엘에스티엠 도입하는게 좋은 선택

# 탄에이치로 인해서 그래디언트 배니시가 될 수 있고 그거 해결위해 '' 넣어주는게 일반적
	- 처음에 아웃을 인풋으로 더하는 식
	- 그럼 그래디언트가 옆으로 흘러서 엘에스티엠 더 많이 쌓아도 덜해
	- 쥐알유도 포드포어드 등에서 딥한거 학습 잘하려고 스티커 ~~ 넣는ㄱ 서처럼
	- 쥐알유나 엘이스도 ~~넣어서 잘 할수 있께해

# 요약
- 알엔엔ㅇ느 플랙서블
- 타임 시퀀스한 모델
- 그러나 바닐라 알엔엔은 학습 어려움(그래디언트 크리핑, 배니싱)
	- 배니싱 해결위해 쥐알유와 알에스 티엠
	- 물론 스틱 커낵션 및 다른 아키텍쳐로 안 되는 부분 보완가능하긴함
	- 엘에스티엠과 지알유는 쓰기 잊어버리기 개념등으로 rnn 성능 향상 시킴.
	- 그러나 익스플로딩 자체는 지알유와 엘에스티엠도 갖고 있기 때문에 그래딩너트 클래핑은 어쩔수업슴
	- rnn 조언: 학습이 잘 안되면 러닝ㄹ ㅔ이트나 옵티마이저 잘 바꿔야해. 그래딩너트 익스플로딩이상할수
		- 알엔엔 학습이 어려울 수 있따.	
		= 클리핑으로 익스플로딩
- 긴거면 빅피티티. 잘라서 시퀀스 줄수있고 잘랐으면 인풋이 이전것의 아웃풋을 넣어서 하나로 학습하듯
- 트레이닝과 인퍼런스 달라. 트레이닝은 그대로, 그러나 예측한거 넣어 그러나 트레이닝으 초반에 아웃풋넣으면 이상할 수 있어. 그래서 처음엔 그라운투스 줘서 안정 주고 어느정도 되면 트레이닝과 인퍼런스 주는. 스케쥴드 샘플링 방식이 있음.

- 이보다 더 좋은 아키텍쳐가 연구방향 되는데 유명한게 컨벌류선 기반. 피드 포워드(언탠션 기반) 기반 모델들
- 좀더 좋은 언더스탠딩 위해서 왜 안 되는지 수학적 알고리즘 아는게 중요합니다.


# 바이디렉셔널 ㅇ알엔엔
- 센티맨트 클래시픽하면 알엔엔 단점은 하나의 방향 정보만 있단거
- 테러블에 대한건 익사이팅을 보지 못해. 만약에 더 무비 워스 테러블리 익사이팅에서 테러블리는 더 무비 워서 까지만 봐. 그래서 얘는 부정 네거티브로 읽을 수 있으나, 사실은 익사이팅이라 긍정일 수있어
- 이 정보가 테러블리에게 영향 못줘
- 그래서 알엔엔은 한쪽만 봐서 다른 방향을 못보는 단점이 생겨
- 그리고 익사이팅이라는게 무비한테 영향 못줘
- 그래서 양방향으로 늘리는거야. 
- 이런 상호보완을 위해 정방/역방향을 concat해요
- 생성테스크가 아니면 무조건 바이디렉션이 조아요***


#바이디렉셔널 짱
- 인풋 한번에 다 접근가능하면 바이디렉셔널짱


#멀티레이어
- 2개에서 4개 안에서 쌓아줍니다.
- 4개가 베스트한 퍼포먼스
- 그러나스키커낵션이나 댄스 커낵션할수있는데 댄스는 잊어도 괜ㅊ낳


# 알엔엔 정리
-1. 알에스티엠은 바워풀하고 지알유는 빨라
- 엘이스티엠은 좀더 피쳐적 파워풀. 
- 지알유는 좀더 빨라요 파라미터 작아
-2. 이런 애들은 우리가 아는 그래디언트 배니싱을 해결 가능
- 그래서 바닐라 알엔엔ㅇ안써
-2. 우리는 피할수ㅇㅄ는 그래디언트 배니싱. 잘라도 생길수밖에
그래서 클리핑 주곤해요. 그럼 학습이 좀 더 안정화
-3. 바이디렉션이 가능하면 무조건 쓰게 해요. 못 쓰면 안쓰지만 
쓰면 
-4. 멀티레이어 좋은 선택지
- 그러나 학습이 더 안 되면 몇가지 트릭 선택해야하고
- 컨벌류션이나 (레즈넷) 등을 넣어줄 수 있음
- 그러면 모델 학습이 안정화되고 깊은 레이어 성공가능

# ATTENTION48page-------------------------------------
- 어탠션은 파워풀하고 좋아요
- 이거 잘 알아두면 최근에 발전된 아키택쳐 이해하기에 수월해요

# 머신트랜스레이션
- 매니투매니
- 시퀀스에 대해 타겟이 존재해요
- 그러다보니까 우리가 인코더와 디코더가 존재하는데 인코더는 우리가 주어진 워드의 시퀀스 고려해어 적당한 단어 매핑
- i go school이면 내가 학교를 간다는거 벡터 만들고
- 각 정보를 하이로 인코딩해주는 벡터인코딩하는게 인코더.

#인코더 알엔엔과 디코더 알엔엔이 존재합니다
- 인코더 알엔엔은 주어진 문제 잘 이해해서 벡터로 표시
- 디코더: 주어진 문장에 주어진 벡터 기반으로 생성또는 번역수행

# 우리가 어떤 정보 인코딩하고 이해할 수 있께 바꾸는게 디코더
- 한국어를 영어로 번역하면 의미론적으로 스페이스로 매핑하고
- 디코더는 매핑된 애를 다시 한국어 정보 및 영어로 보내는 역할
- 자연어 세계에서 영어를 임베딩 스페이스 벡터로 보내는게 인코더
- 디코더는 이걸 사람이 이해할 수 있는 한글로 바꿔주는 것. 

 # 시퀀스투 시퀀스
- 인코더와 디코더의 구조 가진 것을 하나의 용어인 시퀀스투 시퀀스
- 주어진 인풋을 아웃풋으로 바꿔서 그리 부름
- 이 모델 특징은 인코더와 디코더로 구성
- 그래서 가각ㄱ 알엔엔 및 네트워크고, 그 파라미터는 공유 안됨

# 특이한 토큰
- 엔엘피엔 스페셜 토큰 존재: 스타트 토큰, 앤드 토큰. 
- sos, eos, pad
- 스타트 토큰: 스타트 오브 센텐스: 문자으이 시작
-이오에스: 엔드 오브 센텐스: 문장의 끝
- 피에이디: 패딩
	> 아무것도 없는 정보. 
	> 컴퓨터 비전에서 씨앤앤 돌릴떄 한쪽 0으로 돌린 역할과 같음
- 디코더는 스타트와 앤드 토큰 중요
	- 예측을 할떄 초창기엔 생성한게 없으니 
	디코더에게 생성하라고 알려주는 스타트 토큰
	- 다 마치고 나면 앤드토큰으로 번역 마침을 알려 문장의 끝 고지.

#MT
- NMT는 컨디셔널 랭귀지라 할 수 있음
- 이건 주어진 인풋 시퀀스로부터 타겟의 랭귀지에 적잘한 워드 미 문장 단어를 만들어 생성하는 것. 
- 우리가 주어진 엑스로 부터 와이를 예측하면
	- 와이는 와이 엔부터 영까지  주어진 센텐스
	- 소스인 엑스는 한국어이고, 와이원은 첫번쨰 단어. 그 리고 와이원아는 채로 와이투 예측
	마지막은 긴 길이까지 예측하는게 엔엘티 목적
- 기존 랭귀지는 초창기에 아무것도 없을떄 엑스원구하고, 엑스 투랑 엑스 원알때 엑스쓰리 구하는식
	- 비슷한데 기븐으로서 항상 엑스가 주어진 조건부 랭귀지 모델. 

- 기존 딥러닝이 모든 경우에 대해서 좋냐는건 아니에요.
	- 큰 챌린지: 적은 데이터에 대해서도 피팅을 잘해야함
	- 많은 데이터가 있으면 통계 기반의 모델들을 가뿐히 뛰어넘어요
	- 데이터가 적으면 딥러닝 결과가 안좋곤함
	- 일단 엔엠티등에는 빅 포커스 필요. 

#시퀀스투 시퀀스 단점 
- 길어져서 그레디언트. 배니싱이 존재 가능
- 그러면 임베딩 정보에 다 담겨서 뒤에까지 전달하는게 쉽지 않아요

# 고민
- 우리가 정보를 하나로 얻어서 의지하지말고 상황마다 필요한 정보 가져오면 어떨까 생각
- 예) 데이터 베이스에서 필요한거 가져오듯이. 그럼 훨씬 학습이 용이 할것이라 생각
- 아니면 조그만한 임베딩에 모든 단어 넣으면 문장이 길이 다 넣어야 하는데 그게 안 쉬워
- 따라서 다이렉트하게 모델이 바로 접근할 수 있또록 어텐션을 해보게 됨 
- 필요한 정보를 바로 접근하면 좋겠다.

#어텐션
- 일종의 태깅
- 인코더의 어디를 포커스 할지 선택
- 디코딩시 인코딩의 어디 부분을 다이렉트하게 포커싱 할까
- 엔드투엔드로 학습한다 생각해봐요
-문제) 롱 시퀀스에 대해서는 빅 알엔엔으로 가능하나 문장이 길면 프로블럼 가질 수 밖에

# 내가 이 시퀀스 시퀀스 
- 지가 나오고 그다음 나오는게 아이라고 하면 
- 나는 동사 부분이 필요해
- 가지고 올때 중요도를 곱해줘서(0.6),(0.2)가져온대
- 이걸 하이레벨적으로 생각하면 데이터 베이스 생각하면 편해
-인코더 쪽에서 데이터 베이스 테이블인데 키/밸류가 있겠지
-쿼리문이 있어. 이 쿼리 기반으로 키랑 비교해요. 
- 그 다음에 키 페어중에서 맞는 거 힛해서 가져오죠
- 이건 정도를 따져요 이 쿼리가 이거면 키의 이게 필요한게 60프로 필요하다
- 두번쨰 부분은 20프로, 세번째는 10프로 필요한거 쿼리와 키 비교하는데
- 쿼리 백터가 3개 있고 키 백터가 마찬가지로 3개 있따 치면
- 들어가고 이게 유사도인거에요
- 전체 섬이 1이 되게 소프트 맥스하고 **
- 각 데이터 베이스에 대해서 0.6/0.2/0.1/0.1로 가져옵니다.
- 그게 바로 내가 번역시 필요한 정보
- 이걸 바탕으로 다음 단어를 예측합니다.
- 지금 매커니즘이 어탠션 어렵게 생각 안하고 데이터베이스 기준으로
인코더가 데이터 베이스에 올라가는 정보 매핑
- 그럼 벡터로 표시되고 키와 벨류는 사실 동일해요 (디비랑 다르지만)
- 그 중에서 번역을 할때마다 쿼리를 만들어요.
- 그래서 필요한거 가져오는데 쿼리랑 키를 비교해서 가져오고
- 쿼리의 유사도 정보가 있을거에요. 이거 필요하다는 유사도
- 이 정도가 필요한 정도가 될거니까 
- 이런 정도를 유사도로가져오고, 소프트맥스하면 확률값이 나와요
- 소프트하게 그 값을 가져와서 그게 데이터베이스로부터 가져온 값
- 이렇게 하면 롱시퀀스.메모리가 커져도 혹은 아무리 긴 단어를 번역해도
- 이전까지는 하나의 데이터 베이스 하나의 블록의존이, 이제는
- 필요할떄마다 다이렉트하게 정보를 빼올 수 있어 펺지죠
- 기존의 시퀀스는 디비 없고 하나의 테이블만 있어서 그거 전달해 번역했는데
- 그거보다는 더 빠르게 접근할 수 있어서 속도도 빠르고 좋을 수 있단그죠
- 정보를 다이나믹하게 빼오는 알고리즘이다!


#어텐션 적용
- 인코딩 벡터를 만들고
- 중요한 파트가 각각 유사도 어찌 계산할지

# 유사도 계산
- 쿼리벡터 키 벡터들을 어떻게 계산 잘할건지따ㅏ 매커니즘 다라져
- 누구는 닷프라덕트(각각 곱해주고), 어떤 애들은 키랑 쿼리 펑켓한거 mlp해서 나오는 로지션을 원디맨션으로 해서 볼 수도 있고
- 또 하나로써는 바이에니어 함수일수도
- 그래서 이거 어떻게 계산할지가 포인트 달라질 수 있음. 

# 유사도 구하는 방법
- 유사도를 구해서 어탠션 값을 일단은 구해야하죠
- 각각에 대한 로짓값을 구해야하고 이 로짓에 대해서 소프트 맥스로 쿼리값을 바꿔요
- 구한 소프트 맥스로  컨택스트 백터로 만들고 
- 컨택스트 백터와 히든 시테이트를 concat을 하는(컨태스트와 rnn 딧) 
- 리니어 레이어하여 보캡을 구해요
- 코드로 짤거에요
- 인코더로 히든스테이트만들고 디코더 도는데 마짐가 타임스텝에서 히든스테이트 뽑은거에서 키랑 쿼리 백터 곱해주죠 닷으로. 그래서 구한거 소프트 맥스로 구해서 나온걸 컨택스트 벡터만들고 히든 스테이트을 컨킷해서 리니어 래이어로 다음 단어 예측하는거 코딩짤게요

# 헷갈릴 수있음
- 변종이 많음
- Loung과 Bahand
- 초창기는 바한드고  많이 쓰는건 루옹

#다시
- 히든 스테이트 올리려고 알엔ㅇ네에서 인코더로 백터를 시켜줍니다.(바이디렉션 가능)
- 가각 벡터 생기고
- 주어진 히든 스테이트들을 그대로 디코더에 전달을 해주어 처음에 시퀀스를 만듭니다.
- 어떤 rnn에서 나오는 히든 스테이트가 나올거에요 디코더에서 나온
- 이건 앞으로 우리의 쿼리가 될거에요. 질문지
- 이 쿼리 바탕으로 인코더에서 나온 벡터와 비료를 합ㄴ다.
- 비교해주는 알고리즘이 바로 유사도 알고리즘
	- 우리는 닷 프로덕트라 말할게요
	- 그러면 이제 이 바탕으로 값을 구하고 0.1 0;1 벡터 구해서 이 값을 소프트 맥스로 노말라이즈
- 이제 콘택스 벡터 곱해서 나온게 context vector
- '이 콘택스와 이거 곱해서 ...리니어하고.. 워드별로 

#다시2
- 인코더에서 e1[0.6,0.2] e2[-0.1 -0.7] e3[0.3, 0.4] 하다가
-  히든에서 e1[0.1 -1]이 나오면 히든 시트에트이자 쿼리 벡터 
- 닷 프롵덕트는 일이랑 s1= 0.6-0.2=0.4, s2=0.6, s3=-0.1
- 이렇게 구한 에스값. 이거 아직 노말라이즈 안되었으니 편의상 소프트멕스해요
- 그러면 s1이 0.4, s2가 0,5, ㄴ3가 0.1 되어 이게 어텐션의 확률값
- 이거 바탕으로 각 값을 e들과 곱해서 더해주면 0.4 [0.6 0.2 ]+ 0.5[-0.1 0.7 ]+ [0.3 0.4]하고 
디코더랑 concat을 해서 이제 보캐불러리 만큼 확률이 나오죠. [i go school...l][0.01 0.1xx]

# 어탠션 굳
- 필요한 정보 잘못된거 애드훅처럼 찌를수 있어 좋아
- 인터프리터플해(근데 아니기도 해요)
	- 아이를 생성하는데 none 생성하는데 아이보고 했다면 믿을만해
	- 근데 머신러닝은 뭐보고 클래시픽했는지 이해하기 힘든데 어탠션으로는 이해하기 쉬워
	- 이걸 통해서 잘 행동했는지를 알 수 있어. 디버깅 및 이해할때 도움이 됩니다.
	- 어텐션이 인터프리터블해서 논문 쓰기도 좋아요. 
- 어탠션이나 nmt는 아이고우투더 스쿨 매핑



# 어탠션 버라이언트
- 베이직 닷 프로덕트 어태션
- 멀티피케이티브 어탠션더블유를 헤이치 아이 넣고 이거 기반으로 닷프로덕트.
	- 유사할 필요는 없지만 조합해서 학습해서 좀 더 제네럴 할 수 있어요
- 어딕티브 어탠션

# 간단히
- 콘캣: 정확히 덧셈이에요. 딥러닝에서 
	- 정보를 그냥 덧셈해준거다. 나중 레이어에 가서.

# 셀렉티브 섬
- 쿼리 기반으로 현재 서머리 구할 수 있음
- 이제 픽스 사이즈: 인코더로 사이즈가 고정되어있다.
	- 
#이미지 캡셔닝
- 씨앤앤으로 이미지 뽑아줘. 컨벌루션

--------실습-----------
### Data Loader 
- 문제점 있어요. NLP에서 가질 수 밖에 없음
- 원핫인코딩말고 I go to the school이라고 하면 i 가 토큰이 1번 인덱스다라해봐요
- 그럼 0 1 0 0 넣지 않고, i를 그냥 1이라고 하고 go는 7번, to는 21, the 는 3, school50번째 토큰으로 하나의 인덱스 할 수 있음 (토큰 5개)
- 한 문장만 트레이닝하지 않고 하나의 배치에 여러 문장 들어갈 것
- 그럼  i have to rend the book 이라는 문장에 대해서도 토큰이 6개들어가.
- 지금 이 두 문장은 하나는 5토큰, 하나는 6토큰. 이거 매트릭스 불가
- 즉 이 문제를 해결해주려면 패딩을 해줄 수 밖에 없음.  패딩 중요**

#### 길이?
- 샌탠스에 배치 안에서 최대 길이에 맞춰줘야합니다.
- 만들어주지 않으면 매트릭스 자체가 안되어 연산 깨짐


#### padded sequence
- 하나의 시퀀스로 패딩하는 거
- RNN 넣을때 이렇게 넣으면 빠르게 딥러닝 돌아가서 파이토치 지원
- RNN을 만들었어요 아래처럼
- 맨 아래부터 2,3,4,5,..개의 토큰이 있어요
- 이거 하나/둘/셋/넨/다/여섯. 이렇게 할때 패드토큰까지 주면 좋을까요?
    - 얘네 히든도 있고 시퀀스도 넣어주고 하면.?
    - 지금 메모리 낭비하고 있음. 
    - 해당되는 애들을 길이나 시퀀스 고려해서 뱇 사이즈를 다이나믹하게 늘렸다줄일수 있음
    - 배치 사이즈를 처음엔 6개로 하고, 두번쨰는 전체 배칠아 같은 6개 넣고, 세번쨰 시퀀스부터는 하나 빼줘. 이제 업데이트 안해. 그리고 네번째 시퀀스 부터도 하나씩 빼. 그럼 속도 빨라질 수 있겠지. 낭비하는 메모리가 없으니까. 이게 다이나믹하게 하기 위한 시작 **
    - 파이토치는 이런거 귀찮아 rnn은.
    - cnn 플젝트하면 쉬운데 rnn은 장벽 있어. 프리프로세싱 고려해서 모델을 만들어야


# class ToyDataset(data.Dataset): 
- 1.데이터 셋 상속해야 여러 장점 있어요. 2가지 아이템 필요
- (랜, 겟 아이템)
>> 렌은 데이터 셋의 전체 랭쓰 3만개라면 이 정보, 
>> 겟 아이템은 데이터셋의 첫번쨰 인덱스 두번째 데이터 등
	- 해당되는 위치에서 센텐스 등 나와. 

# 데이터 로더는
- 전체가 1만개이면 이거 쭉 인덱스하고 셔플링
- 배치가 30이면 0부터 30씩 꺼내고, 다음은 60까지 꺼내고
- 이런 방식으로 데이터 가져와야함. 그래서 
- getitem이 인덱스로 참조해서 가져와(toyDataset_ getitem)

# 예제
- 알파벳. 인풋이 aacd라고하면 dcaa가 나오게 하는게 모델의 목적
- 어탠션 잘해야해. a는 맨 뒤엥 ㅣㅆ을때 앞을 봐야 어탠션 잘 잡을수있어서
- 리스트 캐릭터스가 abcdefg 6rkwldlrh wnfduTdma 

class ToyDataset(data.Dataset): #1.데이터 셋 상속해야 여러 장점 있어요. 2가지 아이템 필요(랜, 겟 아이템)렌은 데이터 셋의 전체 랭쓰 3만개라면 이 정보, 겟 아이템은 데이터셋의 첫번쨰 인덱스 두번째 데이터 등
    """
    https://talbaumel.github.io/blog/attention/
    """
    def __init__(self, min_length=5, max_length=20, type='train'):
        self.SOS = "<s>"  # all strings will end with the End Of String token )
        self.EOS = "</s>"  # all strings will end with the End Of String token
        self.characters = list("abcde")
        self.int2char = list(self.characters)
        self.char2int = {c: i+3 for i, c in enumerate(self.characters)} # +3 을 왜하는 가?
        print(self.char2int)
        self.VOCAB_SIZE = len(self.characters)
        self.min_length = min_length
        self.max_length = max_length
        

	>> 보통 nlp는 이게 딕셔너리 방식이라고 해
	>> 인덱스화 해서 추적하려고 그래서 in2char, char2int todtjd
	>> 보카 사이즈: 갯수가 나오게 됩니다. 


#데이터 로더
- 파이토치점 데이터로더 적용은 일단은 1~10까지 데이터가 있다 생각
- 랜덤하게 셔플링하여 순서 잘 바꿔서 2, 7, 6이 나왔어요. 그럼 2,7,6번째 인덱스 것만 가져올거에요.
- [data]-len->[dataloader0~9]--2,7,6  뽑아요-- 미니배치 사이즈
>> [data]에서 getitem해서 (2,7,6)으로 하나씩 뽑아와서 sentesce1, s2,s3 을 가져옵니다. (얘네 아직 매트릭스 합치기 전)
	>> 데이터 로더는 뽑기만 하거 어찌 합치는 지몰라ㅣ
	>> 그래서 s1,s2,s3 합치는 함수가 nlp에서 필요해요 
		>> s1,s2,s3를 하나의 매트릭스로 만드는 함수. 
** nlp_pad_collate***
		->이미지는 사실 필요없어요. 디맨젼이 같으면 자동으로 concat되니까
		>> 그러나 nlp는 길이가 달라서 merge할 함수 ㅠㅣㄹ요하고 이게 pad-collate
			>> 최대 길이 뽑고 그 중에서 부족한건 패드
			>> 소스가 가장 큰 길이가 맨위에, 작을 수록 아래에 두는 역할 합니다.


#
#워드 임배딩으로 인식되려면 롱으로 해야해. 그래서 토큰을 롱으로 자형 선언 필요
--------------------------------------------------
#### ENCODER RNN Code
- 엔엔점 모듈 먼저 행해. 그래야 뉴럴네트워크인거알지
- 인잇은 무조건 레고 선언. 여기서는 2개 필요해요. 임베딩과 알엔엔. 그럼 이거에 대해 무조건 선언해줘야한다고 생각하면돼

- 1. 우선 임베딩 선언해요 nn.embedding 그리고
- n classes는 아까 말했던 넘버오브 클래스 갯수. 캐릭터의 갯수 가져오는게 config.get
- self.embedding_dim 넣어서 (?????) 몇개 임베딩 하는지 얘기
- 패드 토큰 0을 넣어서 앞으로 얘는 패드 토큰을 영 쓴다 말해요. 

-2. 지알유의 인풋
- 지알유인풋디맨션은 임베딩의 디맨션이 되어요. ** (self.embedding_dim)
- 알엔엔 선언해야하고, 그 중에서 지알유 선언해요. 그리고 엘에스티엠하고 싶음 대문자로 쓰고 (GRU)

-3. 지피유 트루하고 각종 지알유 선언한 것들 해봐요


-4 포워드로 레고 순서 나열
- 인풋은 처음에 어디 지나냐면 임베딩 지나야 해요. 그러면 (self.embedding)
- RNN에 얘를 넣어야 하죠 이떄 패딩 시퀀스를 먼저 해줘요 ** 다이나믹하게 시퀀스 만들려면 팩 패딩 시퀀스로 해(인풋, 걔네 각각 실제 길이 담고, 배치퍼스트는 비,티 순서라서 트루로줍니다.)

-5. 이렇게 배킹이 된 애를 엑스에 넣고, 히든은 프리비어스 히든 스테이트인데 여기선 이니셜

-6. 일단 아웃풋과 스테이터스 나오고, 아웃풋은 마찬가지로 의미있는 시퀀스만 저장해둬서 현재 패킹된 상태임. 그래서 이 output을 pad_packed_squence로 풀어줘야합니다.

//얼굴보니 모르겟는거 같아 설명
배치 사이즈 RNN 돌리게 되면 아웃풋은 이걸 줘요. 각각 타임 스탭에 대한 정보를 주는게 결과를 주는게 아웃풋이에요. 그러니까 마지막 레이어에 각 토큰 마다의 히든 스테이트 주는게 아웃풋 **. 그 다음에 스테이트는 마지막 시퀀스의 각 레이어별 히든 스테이터스 주는 것. 이걸 줘야 나중에 디코더 초기로 넣어야하니까. 그래서 가지고 있어야하죠.
- 일단 아웃풋이 있고 아웃풋은 4개의 토큰이 있다고 하면 아웃풋은 4곱하기 히든 사이즈만큼 있을 거에요
- 이제 배치가 예를 들어서 3개가 있다면 삼곱하기 사곱하기 히든 사이즈.
- 이렇지 않은게 배치를 다 하지 않죠. 그래서 우리가 첫번쨰 시퀀스에서 이런게 배치가 6개마다 있고, 둡너째도 6개 있지만, 세번째는 5개 있죠. 
- 그럼 이빨이빠진 부분이 있어서 텐서가아니게 되는데 이때 는 전체 3이고 4해서 히든사이즈 곱해주는거에요. 이 애들이 음. (현재 무지개 색있는 시퀀스가지고도 설명)
- 지금 우리가 패킹을 안 풀어주면 전체 데이터는 9개가 있을거엥 시퀀스. 이거 패킹 푸면 3개를 빵빵 의미없는 매트릭스로 채워줘요. 그래서 총 삼곱하기 사의 히든사이즈가 있죠. 거기서 ㅇ이콤마 삼, 이콤마 이 의 위치는 다 빵이겠죠. 
- 원래 매트릭스 사이즈 복구를 위해서 보는 pad packed. 
    - 패킹을 할때 팩 패크드이고, 언패킹 할떄는 바꺼서 이야기하면 돼. 
- 7. 바이 디렉션의경우에는 콘켓도 되지만 일단 섬을 할 수 있어서 섬을 할게요(콘켓이 맞긴함)(self.hiddensize)

-8. 반반 쪼개서 해줘요. 바이디렉션은 앞에서 부터, 뒤에서 부터하니까. 

-9. 인잇 히든 스테이터스
- 아무것도 없으면 영으로 넣으니 (.zeros) 넣어줍니다.

-----------------------------------------
### Data Loader 
- 문제점 있어요. NLP에서 가질 수 밖에 없음
- 원핫인코딩말고 I go to the school이라고 하면 i 가 토큰이 1번 인덱스다라해봐요
- 그럼 0 1 0 0 넣지 않고, i를 그냥 1이라고 하고 go는 7번, to는 21, the 는 3, school50번째 토큰으로 하나의 인덱스 할 수 있음 (토큰 5개)
- 한 문장만 트레이닝하지 않고 하나의 배치에 여러 문장 들어갈 것
- 그럼  i have to rend the book 이라는 문장에 대해서도 토큰이 6개들어가.
- 지금 이 두 문장은 하나는 5토큰, 하나는 6토큰. 이거 매트릭스 불가
- 즉 이 문제를 해결해주려면 패딩을 해줄 수 밖에 없음.  패딩 중요**

#### 길이?
- 샌탠스에 배치 안에서 최대 길이에 맞춰줘야합니다.
- 만들어주지 않으면 매트릭스 자체가 안되어 연산 깨짐

___________________
#### 아래 그림 설명 padded sequence

- RNN을 만들었어요 아래처럼
- - RNN 넣을때 이렇게 넣으면 빠르게 딥러닝 돌아가서 파이토치 지원
- 맨 아래부터 2,3,4,5,..개의 토큰이 있어요
- 이거 하나/둘/셋/넨/다/여섯. 이렇게 할때 패드토큰까지 주면 좋을까요?
    - 얘네 히든도 있고 시퀀스도 넣어주고 하면.?
    - 지금 메모리 낭비하고 있음. 
    - 해당되는 애들을 길이나 시퀀스 고려해서 뱇 사이즈를 다이나믹하게 늘렸다줄일수 있음
    - 배치 사이즈를 처음엔 6개로 하고, 두번쨰는 전체 배칠아 같은 6개 넣고, 세번쨰 시퀀스부터는 하나 빼줘. 이제 업데이트 안해. 그리고 네번째 시퀀스 부터도 하나씩 빼. 그럼 속도 빨라질 수 있겠지. 낭비하는 메모리가 없으니까. 이게 다이나믹하게 하기 위한 시작 **
    - 파이토치는 이런거 귀찮아 rnn은.
    - cnn 플젝트하면 쉬운데 rnn은 장벽 있어. 프리프로세싱 고려해서 모델을 만들어야
- 즉 시퀀스 나눠줘야함
    - 저렇게 해서 rnn hidden statte

------

# 텐서플로
- 컴퓨테이션 그래프
- 딥러닝들은 연산하는 플로우가 있고 이거 블록으로 조립하는 식
- 파이토치나 텐서플로는 그런 그래프 그리고 백프로파게이션 연산하는 식.
- 코딩할때 먼저 컴퓨테이션 그래프 그리는게 첫 시작이에요
- 그게 ㅇ위에 있는 것


### 저런 그래프 어떻게 만드나요?
- 모델을 그려보면서 하면 됩니다. 아래 그림을 볼까요

---------------
#### Embedding Module 
- 보캐블러리 넘버
- 임대빙 딤
- 패딩 인덱스: 영번 은 패드 토크니라고 해서 의미가 없다고 했죠. 얘네 임베딩은 다 0으로 채움. 넘버 주면 알아서 학습 안하고 0 뱉음


#### gru함수
- 3가지 학스ㅏㅂ하게 할거야
- 인풋 정하면 나오고 바이디랙션도 하게해
- 많은 파라미텅 ㅣㅆ음
    - 인풋 사이즈
    - 히든 사이즈: 그거 안에 있는 히든 스테이터스 수
    - 넘버 오브 레이어: 멀티 레이어 얼마나 쌓을 건지에 대한 제약조건
    - 배치 퍼스트: 기본적으로 트루를 주곤 합니다.
    - 인풋을 어떻게 줄 수 있냐면 일반적으로 (batch, 3 , w, h)였을거에요 rgb는
    - 그리고 지금은 (B,T)하고 아니면 (T,B) 모델은 타임스컨스로 보기에 T를 먼저 생각
        >> b,t 순서면 배치 퍼스트 트루로 줘야해 *********@@*******
        >> 드랍아웃 확률값 주려면 확률값 주려고
    - 바이디렉션: 각 디맨션 마다 추가적인 하나의 백워드 방향의 gru 생성
-------
#### ENCODER RNN Code
- 엔엔점 모듈 먼저 행해. 그래야 뉴럴네트워크인거알지
- 인잇은 무조건 레고 선언. 여기서는 2개 필요해요. 임베딩과 알엔엔. 그럼 이거에 대해 무조건 선언해줘야한다고 생각하면돼

- 1. 우선 임베딩 선언해요 nn.embedding 그리고
- n classes는 아까 말했던 넘버오브 클래스 갯수. 캐릭터의 갯수 가져오는게 config.get
- self.embedding_dim 넣어서 (?????) 몇개 임베딩 하는지 얘기
- 패드 토큰 0을 넣어서 앞으로 얘는 패드 토큰을 영 쓴다 말해요. 

-2. 지알유의 인풋
- 지알유인풋디맨션은 임베딩의 디맨션이 되어요. ** (self.embedding_dim)
- 알엔엔 선언해야하고, 그 중에서 지알유 선언해요. 그리고 엘에스티엠하고 싶음 대문자로 쓰고 (GRU)

-3. 지피유 트루하고 각종 지알유 선언한 것들 해봐요


-4 포워드로 레고 순서 나열
- 인풋은 처음에 어디 지나냐면 임베딩 지나야 해요. 그러면 (self.embedding)
- RNN에 얘를 넣어야 하죠 이떄 패딩 시퀀스를 먼저 해줘요 ** 다이나믹하게 시퀀스 만들려면 팩 패딩 시퀀스로 해(인풋, 걔네 각각 실제 길이 담고, 배치퍼스트는 비,티 순서라서 트루로줍니다.)

-5. 이렇게 배킹이 된 애를 엑스에 넣고, 히든은 프리비어스 히든 스테이트인데 여기선 이니셜

-6. 일단 아웃풋과 스테이터스 나오고, 아웃풋은 마찬가지로 의미있는 시퀀스만 저장해둬서 현재 패킹된 상태임. 그래서 이 output을 pad_packed_squence로 풀어줘야합니다.

//얼굴보니 모르겟는거 같아 설명
배치 사이즈 RNN 돌리게 되면 아웃풋은 이걸 줘요. 각각 타임 스탭에 대한 정보를 주는게 결과를 주는게 아웃풋이에요. 그러니까 마지막 레이어에 각 토큰 마다의 히든 스테이트 주는게 아웃풋 **. 그 다음에 스테이트는 마지막 시퀀스의 각 레이어별 히든 스테이터스 주는 것. 이걸 줘야 나중에 디코더 초기로 넣어야하니까. 그래서 가지고 있어야하죠.
- 일단 아웃풋이 있고 아웃풋은 4개의 토큰이 있다고 하면 아웃풋은 4곱하기 히든 사이즈만큼 있을 거에요
- 이제 배치가 예를 들어서 3개가 있다면 삼곱하기 사곱하기 히든 사이즈.
- 이렇지 않은게 배치를 다 하지 않죠. 그래서 우리가 첫번쨰 시퀀스에서 이런게 배치가 6개마다 있고, 둡너째도 6개 있지만, 세번째는 5개 있죠. 
- 그럼 이빨이빠진 부분이 있어서 텐서가아니게 되는데 이때 는 전체 3이고 4해서 히든사이즈 곱해주는거에요. 이 애들이 음. (현재 무지개 색있는 시퀀스가지고도 설명)
- 지금 우리가 패킹을 안 풀어주면 전체 데이터는 9개가 있을거엥 시퀀스. 이거 패킹 푸면 3개를 빵빵 의미없는 매트릭스로 채워줘요. 그래서 총 삼곱하기 사의 히든사이즈가 있죠. 거기서 ㅇ이콤마 삼, 이콤마 이 의 위치는 다 빵이겠죠. 
- 원래 매트릭스 사이즈 복구를 위해서 보는 pad packed. 
    - 패킹을 할때 팩 패크드이고, 언패킹 할떄는 바꺼서 이야기하면 돼. 
- 7. 바이 디렉션의경우에는 콘켓도 되지만 일단 섬을 할 수 있어서 섬을 할게요(콘켓이 맞긴함)(self.hiddensize)

-8. 반반 쪼개서 해줘요. 바이디렉션은 앞에서 부터, 뒤에서 부터하니까. 

-9. 인잇 히든 스테이터스
- 아무것도 없으면 영으로 넣으니 (.zeros) 넣어줍니다.
-------------------------
# 디코드

- 빨간색은 디코드 알엔엔이 있어요(빨강)
- 이거 바탕으로 어텐션을 해야하죠. 어탠션을 해주게 되는 어탠션 모듈이 필요해요. (핑크)
- 디코드코드 아래에 있어야 하는건 [임배딩][알엔엔 층]
- 디코드이 토큰이 들어가야하고
- 인코드에서 마지막에 생긴 히든 스테이터스가 디코드에서 들어가는 용이겠죠
- 인코드의 라스트 히든 스테이터스 가 저장이 되고 
- 핑크가 만들어넨 ct와 rnn의 쿼리 스테이터스를 concoat하고 리니어 레이어 거쳐야겠죠
- 리니어 레이어 거치면 각각 보캡에 대한 확률 구할 수 있죠. ㄱ래서 각 보캡 수만큼 확률 값이나올거에요(=로짓값)

#### 어탠션 모듈 필요한 거
- 히든 스테이터스 필요
-참조 메몰 ㅣ필요(인코더 히든스테이터스들)
- ht랑 비교해줘야해
- dot 프로덕트ㅡㄹ 이제 할건데 우리의 소스가 바로 인코더쪽의 히든 스테이터스와 타겟인 디코드 쪽의 히든 스테이트를 dot 프로덕트할거에요. 그럼 어떤 스칼라 값이 나올거에요
- 그게 바로 어텐션의 로짓이고 소프트맥스 거쳐서 웨이티드 에브리지하면 결과 나와요
-------------------------------------------------

1. 디코드에 필요한거 우선 지알유
2. (디코드에 바이디랙션해도 될까요? 안돼. 왜냐하면 우리가 바이디렉션 하면 치팅을 하는거죠. sos이고 nan이 들어가면 바이디렉션 하는 순간 난의 정보가 위에 올라가니 sos가 치팅할 수 있어. 그래서 바이디랙션은하면 안돼******그래서 어느 경우에도 false)
3. 아..루옹은 어텐션 거쳐서 하는데, 반하은은 어탠션자체가 어.....
- 그림 잘못 가져오셨대
-  히든 스테이터스> 어탠션> c> 리니어레이어에서 예측하는 루옹. 
    - 현재 필요한 정보를 꺼내
- 바안) 내가 필요한 다음거 가져온다
- 즉 rnn돌려서 내가 필요한 컨탠츠를 가져와서 concat해서 쓰는 루옹과, 일단은 rnn돌리고 힏느 스테이터스 어탠션해서 그 결과를 얘의 인풋으로 넣어. 
- 즉 루옹은 지금 필요한거 가져오는 식이고, 반항은 다음번에 필요한걸 가져오는 식. 그래서 어탠션을 만든 context 벡터가 rnn 인풋으로서 concat해서 들어가는게 오른쪽 반흥 내용.
- 루옹과 반흥. 코드보면 어탠션 모델이 제ㅐ각각이긴해. 어떤건 이렇고 어떤건 저래. 이미지 캡셔닝은 bahdanau같아. 초기에서 어탠션 가져와서 인풋과 concat하고 그 히든 을 가지고 다음 콘태스트 뭐 넣을지는 인풋으로 넣었지. 그래서 이미지는 무엇을 볼지 알려주는거고
- 루옹은 지금 필요한 정볼르 가져오는 모델들 

- 실습 코드는 반흥거 가져왔네요ㅜㅜ

### 디코드
- 1. 지알유에 false
    - 일단은 프리비어스 히든 스테이터스 기반으로 어탠션을 구하고 그 어탠션 깁나으로 소프ㅡ 맥스한걸 인코더의 아웃풋과 계싼해서 가져오고 그걸 기반으로 gru에 콘캣으로 준다는거
    
-2. 디코더 선언3가지(어탠션 모델, rnn, 임배딩)
- nn.embedding(패딩 인댁스도 넣어줌)
- nn.GRU
- attention

그래서 이건 따로 만ㄷ르어줘야하고 그럼 디코더에 대한 추상 클래스 완성

------------------
####
- 루옹 
     - 파란색 : 인코드. 우선적으로 만들어요. 
          - 인코드 들어가기전에 인풋을 임베딩으로 바꿔줘야해요(벡터화해야 연산 가능)
            - 그래서 파란색 하단에는 embedding 레이어가 존재해야해요
           - 현재 RNN 레이어 2개 쌓아야 하니 임베딩 위에 [RNN]을 두개 올려요
            - 바이디렉션 항상 고민해야해요. 여기서는 오케이
            - 이제 인코더로 나온게 '히든 스테이트'
        - 인코더의 인풋?
               - 초기 히든 스테이트스
        
    - 히든 스테이트스
    
    ----------------------------
1. 초기 인풋 고려
     > 현재 토큰화 되었으니 임배딩 거쳐야해요 [인풋]>[임배딩]
            >> 앤드 투 앤드: 원하는 인풋에서 원하는 결과가 나오게 해서 우리 인풋과 아웃풋만 넣으면 되는것
            >>얘를 통해 색을 반쪽 만들고 앤드투 앤드가 아닌게 중간에 무슨 연산 넣는것
2. 히든 스테이트스(피리비어스 히든 스테이터스)

[input> (EMBEDDING+Prev_hidden)> RNN> encode state] 
    
--------------------



```
# 코드로 형식 지정됨
```
# 어탠션
- 어탠션이 제일 중요하겠죠
- 어탠션(포어드 함수)
    - 프리비어스 히든 스테이터스 줘야해. 이게 쿼리로 들어가니까
    - 인코드 히든 스테이터스
    - 그거에 대한 시퀀스까지 주면 어탠션 계싼해서 weight 나와
        - 웨이트는 배치의 갯수만큼 있어서 B*T만큼 있어 맥스 시퀀스만큼(패드는 0)
    - context= > > b i t인데 b t h를 해야하네요.
        - 이제 우리는 각각 곱해줘서 더해야하는데 가장 쉬은 방식이 포문같죠?
            - 모델 안에서 포문쓰면 속도 느려져서 매트릭스 계싼해야해***
                - 배치 매트리스 멀티 플랫(B,a,b)디맨션과 (B,b,c)있으면 0번째/1번째/2번째에 대해서 매트릭스 ....를 해서 결과적으로 (B,a,c)나오게 한대@@아하 b는 겹치니까 그거 빼고 했네
                - 이렇게 하기 위해서 배ㅣ 매트리스 멀티 플랙션
 - 언스퀴즈
    - 첫 디맨션 생기게 하는것
    - 그러면 b t가 나중에 b , 1, t가 되는거에요. [B, T, H]-> [B, 1 H ]
        - 콘테스트에서 bnn하면 뭐고..  
        
   - 스퀴즈 : 해당 디맨젼 없애기
    - 그래서 [B, H로 줄임]
    - 이 부분까지 하면 context 벡터까지 한거에요 
    
  - 이제 왼쪽의 인풋을 임베딩을 해줘야 해서얻을 수 있고
  - 어텐션으로 얻은걸 추가해서 인풋을 제공합니다. rnn_input(context_vector)언스퀴즈하면돼. 그러면 (B Embedding> 1, b emeddin되고 이 상태에서 앞에 1을 맞춰야 해서 콘캣하면 1,b , embeding> 1,b hiddensize 되어 결국 1,b, hidden이 되는거래요. )

- 콘캣하는 연산
    - torch.cat
    
- 이제 rnn 넣어
- 트랜스폼 하는 이유: 배치 퍼스트
    - (1,b,emb+h)> 1이 앞으로 가고 0번째가 뒤로 간다고 해서 트랜스
        >> transpose(1,0)> (b,1,emb+h)
  - 린리어 레이어 . 
    - 원하는 아웃풋사이즈가 되어야 하니까 똑같이
    - self.output_size
    
 - 아까 아웃풋이 (b,1,hidden)인데 이거 맞춰서 (b,logits)되게 하여 원하는대로 되게 합니다. 
-----------------------
# 어텐션
- 제너럴 닷 프로덕트
    - 제너럴: 바이미니얼. 인풋에 대한 디맨션을 참조로 써줘야해요. 
        - 임베딩 및 디맨션 일치하고 옆에 표기해줘야해요.
        - 라스트 히든을 배치*히든, 아웃은 배치사이즈, 맥스, 히든할거니까  저렇게 줙씀
     - 각각 파라미터 정의 되고 추가된거 필요없으니 두고, 히든 사이즈 투 히든 사이즈. 
     - concat은 2개 파라미터 필요하니까 히든사이즈 2배가도록 하고
     - 마지막으로 va해서 히든사이즈 투 1
- 스커어
    - 주어진 라스트 히든과 배치니까 일단 닷하려면 언스퀴즈해서 배치사이즈, 히든 사이즈1되고,
    - 시쿼늣 연산은 어탠션은 배치사이즈, 맥스, 히든과 쿼리 백터인 배치사이즈 히든딤이랑 연ㅅ나해서 비교해주면 되는거죠
    - 어떤 특정한 결과값으로 딱 맥스 타임 스탭 1의 결과가 나오고결과에 겹치는거 사라져서 나와 
    - 마지막 1 없애면 배치에 그거랑 가탕. 
    - 앞에 있는게 인코더 히든이니까 
    - return encoder_output. 
    - 라스트 히든 스테이터스.. 결론적으로 batchsize, maxtimestep이 됩니다. 
- 제너럴
-콘켓
-----------------------
# 딥러닝 전체적 흐름 (하이레벨) 지금까지 한 거
- 학습목표:
>> 리니어레이어(백프로파게이션이어찌 되는지 보고파)
	- 백프로파? 결과가 얼마나 틀렸는지에 대한 로스 알고파.
		- 해당되는 로스가 얼만큼 틀렸는지 contribution이 있는지 알고파서 수행.
		- 공헌을 해서 결과가 맞다면 그 성과 올려줌
	- 이런 백프로파 알고리즘 통해서 뉴럴 네트워크는 학습이 가능해짐 
		- 리니어기반 레이어 한계: '이미지'
			- 이미지에서는 엠니스트 예제에서 생각하면 얘네를 쭉 폈어요. 
			- 컨벌류션같은 연산이 나온이유:
				- 각각 픽셀은 주변적으로 연결이 되어있어서 디펜던시가 심해요.
				- 인접하니까.공간적으로.
				- 공간적 정보까지 잃었던 거에여(10*10)을 (1*100)으로 늘리면
				- 저런 스페셜한 정보를 이제 알 수 없어. 해결하고자 컨벌류션 생성
			- 컨벌류션: 스페셜해서 중심 픽셀 기반으로 돌아가요
				- 이를 통해 스페셜한 정보 뽑을 수 있고
			- 이를 바탕으로 특정한 피쳐인 '세모' 직선' '사각형' 초록색'을 잡을 수 있어요. 
			>> 레이어가 겹칠 수록 특징을 고려해서 다음 레ㅐ잉어에서는 피쳐 각각 뎁스가됨.
			그 피쳐가 그 공간에 존재하냐 안하냐
				>> 뎁스기반 컨볼루션하면: 하이레벨 잡을 수 있음(별표,코, 눈)
					>> 어떤건 동그라미/ 검은색 등등이 있는데 이게 눈이 될 수있으니.
				>> 즉 컨볼류션은 뎁스와 주변을 고려해서 결과 내리는 것.

- 딥러닝 모델 좋은거?
>> Repre station learning: 모델에게 뭘 배우라고 말하지 않아도 되는 장점
	>> 이미지 분류할때 데이터만 주면 개/고양이 보고 그 피쳐에 대해서 스스로 학습해서 엔지니어틱한 요소가 들어가지않아. 우리가 이거 코라고 학습 안시켜도 돼.
	>> CNN 레이어를 앞에 쌓는데 이 레이어들은 해당되는 피쳐럴 extraction해. 
		>> 이를 기반으로 fc 레이어 거쳐 >> 로짓값 구해. 
				-> 클래시피케이션의 '할당'이 이것. 

- 추가적으로 넌리니어/리니어
>> 리니어: 아무리 쌓아도 의미업다
	> 일직선만 가능
>> 넌리니어: 컴플랙스한거 가능
	> 복잡한거 모델링 가능.


#옵티마이제이션알고리즘
- 어떻게 최적화할 수 있을지 .
- 기존의 sgd방식이 로컬 미니마 빠질 수 있으니/속도 느릴수 있으니, 피하도록 모멘텀을 추가
	- 근데 오버슈팅 일어날 수 있으니 이거 방지코자
		>> rms 나 캐쉬 추가했고 그게 '아담' . 아담이 제일 좋아

# 레귤레이제이션 (성능 향상)
- 드랍아웃
-앙상블
- 배치 노말레이션

#다루려다 못 다뤘던거 생각
- 이니셜레이제이션. ,weight initialization
- 어떻게 하느냐에 따라 결과 달라져. 렐루는 데드로 갈수도, 탄에이ㅣ는 이미 세튜레이트로 0이 될 수 있어 그래서 이거 ㅐ결하고자 웨잇 이니셜라이즈하는데 이거 잘해야함

# 웨잇 이니셜 어떻게 잘하나?
- 처음에는 랜덤 노말을 함. 
- 우리가 해다오디는 애를 배리언스를 0.01로 랜덤 노말함.
	>> 매우 스몰한 랜덤한 넘버를 줌 평균이 0이고 0.01이 되서 거의 0에 몰려있는 식일거야.
	>> 그럼 첫번째 레이어는 적당히 괜찮아요. 레이어가 지나갈수록 -1과 1사이에 있으니까 1보다 작은 값들이니까 곱하면 계쏙 값들이 작아지게 되는거에요. 그러다가 너무 0에 가까워지니까 거의 0에 가까워지는거에요. 그렇게 되면 앧르의 값이 액티베이션이 0이라서 모델이 전부 0만 가지게 되는거에요. 대부분 액티베이션 값이. 이게 다양해야 모델이 좋아. 이제 액티베이션 값을 배리언스 있게 만들고 싶은게 그 방법
		>>배리언스를 조금 커지게 하는거에요. 0보다 멀리 떨어지게끔. 0.05로
		-> 애들이 저누 -1또는 1만 가졌대요. 값이 적당히 크다보니까 다 값이 커져진대요
			>> 노드에 액티베이션 값을 더할건데 그게 w1,2,3,4가 있는데 노드Xn에 대해 웨이트Wn이 계속 곱해서 더할수록 더 커질 확률이 높겠죠. 혹은 마이너스로 빠질 수 있죠. 그래서 w가 조금이라도 크면 saturate되서 1이되고, 엄청 작게되면 -1로 몰릴 수 있어요. 각 배리언스ㅏ 1이라 생각하면 ...

			>> 그러면 그래디언트 vanishing이 일어나서 학습이 안 일어나요. 그래서 웨잇에서 이니셜 크게 주면 배니싱 될 수 이써서 랜덤으로 주는게 애매해짐. 
- 해결 법: Xavier initialization
	- 디맨션 갯수만큼 루트를 씌워주는거에요.
		>> 그럼 값이 평균화되는데, 표본평균의 분산. 엑스바. 배리언스 엑스 바는 엔분에 바엑스. 
		>> 데이터 갯수가 증가하니까 엔 베리언스가 커져. 엔으로 나누면 ㄴ베리언스가 1에가까워져
			.> 평균이 1이고 배리언스가 0인 모델에 가까워지는거야.
			>> 이전 표본평균에서 분산을 1로 맞추기 위해 1/n한 것과 유사 알고리즘
				>> n은 인풋 노드의 갯수
	- 배리언스로 생각하면 4인데 샘플의 갯수 4개면 그대로 나누자는거야. 그래서 하이레벨로 하는거에요. 많은 생략이 있으니 그런거 있다 생각하고.
		>> np.sqrt(Din) 그렇게 되면 랜덤 노말을 스켈링하여 베리언스를 1/n하는것과 같은 셈. 
			>> 평균화 안정화 됩니다.가우시안 분포에 가까워짐. 

- 렐루 문제
	: 절반이 0이 되어 절반의 배리언스가 사라지는 셈
	: 아까는 배리언스를 엔분의 엑스 라면, 이제 렐루는 절반으로 떨어졌다 생각하는거죠.
		>> 배리언스 엑스 분에 이분의일. 이게 바로  weight initialization 40페이지. 
		>> 배리언스 1맞추려고 들어오는 갯수만큼 분모 나눈 셈.

# orthogal initial
- rnn은 정보가 쭉 전달되는게 좋은데 잘못 이니셜 하면 그게 전달이 안돼
- 올소컬리티 하면 최대한 모든걸 다음에 전달하는거라서 벡터를 올소그널하게 변경하게 되면 그 정보를 하나도 잃지 않으면서 전달 할 수 있는거에요. 

# CNN
- 이제 데이터 기반으로 하고
- 리컬시브한거 하려고 생각해냈고, 이거 문제 생겨서 gru, lstm 사용하다가(그래디언트 배니싱+ 익스플로딩_클리핑으로 해결) 얘네가 성능 높일 방법으로는 인풋을 접근 가능할떄 바이디렉션으로 풍부한 피쳐만들게, 깊게 하려고 멀티 rnn 레이어 사용가능하게 할 수 있고. 

# 시퀀스 투 시퀀스
- 시퀀스 투 시퀀스에서는 긴거에서 긴거로 번역 및 생성이 어려워서 이 정보를 다이렉트하게 접근할 수 있는 알고리즘 생각했고 그게 어탠션. 

# 갠
- 한가지 연구방향이라서 딥러닝 중하나. 다음시간에^^;

#워드임베딩
- 그 원리 구조를 이해할 필요 없지만 어떻게 적용되고 학습되는지를 알면 될듯
- 원핫보다는 벡터로 표현하는게 모델 학습에 좋음. 
- 그걸 학습하는 방법은 주변 단어로부터 유추간으. 주변 단어는 비슷하고 비슷한 빈도수.
- 그래ㅓㅅ 중심으로부터 주변을/ 주변에서 중심을


#글로벌 임베딩
- 나오는 빈도수로 코.. 아이스와 스팀이 있는데 둘다 water나오면 이쓸거다. solid는 어디만 많이 나왔다고하면 이 고체쪽으로 인코딩해서 임배딩 할 수도 있음.

# nmt
- 잘 보시면서 라인바이라인 따라하시길 바랍니다.