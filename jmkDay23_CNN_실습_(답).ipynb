{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN 실습 (답)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SH_g6i-jMBh",
        "colab_type": "text"
      },
      "source": [
        "### pyTorch 를 비롯해 오늘 실습에 필요한 파이썬 라이브러리를 읽어들입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEo2sR84NrPx",
        "colab_type": "text"
      },
      "source": [
        "### Copyright (C) 2018  Cheonbok Park <cb_park@korea.ac.kr> and Keetae Park()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-5K8m1hfCRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn #\n",
        "import torch.nn.functional as F #\n",
        "import torchvision # 이미지 관련 처리, Pretrained Model 관련된 Package 입니다. \n",
        "import torchvision.datasets as vision_dsets\n",
        "import torchvision.transforms as transforms # 이미지 처리 (Vison) 관련된 transformation이 정의 되어 있습니다.\n",
        "import torch.optim as optim # pytorch 에서 정의한 수 많은 optimization function 들이 들어 있습니다.\n",
        "from torch.utils import data\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # 시각화를 위한 패키지입니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz8VMAXSjYCe",
        "colab_type": "text"
      },
      "source": [
        "### Hyper-parameter 세팅 및 기타 변수 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-G0yNhJjLtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # pytorch0.4.0 이상 버젼에서 gpu 설정하는 방식, tensor.to(device) 이런식으로 사용\n",
        "lr = 0.001\n",
        "batch_size = 128\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXhH8tYwtQN7",
        "colab_type": "text"
      },
      "source": [
        "### 다양한 함수 연습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfkq3vn1ta4r",
        "colab_type": "code",
        "outputId": "73e23cf3-abbe-403a-ceb5-20ce26f51e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# torch.view 연습\n",
        "\n",
        "sample = torch.randn(2000,64,64,3)\n",
        "# sample => (2000, 64, 64, 3).  \n",
        "sample_1 = sample.view(2000, -1) #위 sample 을 (2000, 64*64*3)으로 바꿔보세요.\n",
        "sample_2 = sample.view(2000*64, -1) #위 sample 을 (2000*64, 64*3)로 바꿔보세요.\n",
        "print(sample_1.size())\n",
        "print(sample_2.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2000, 12288])\n",
            "torch.Size([128000, 192])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iH_HikgtcN_",
        "colab_type": "code",
        "outputId": "037ec698-0bb1-43a6-f868-f5d26c7e4962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# torch.view 다른 예제\n",
        "a = torch.FloatTensor(5,20,100)\n",
        "a1 = a.view(2, 10, -1)\n",
        "print(a1.size())\n",
        "a2 = a.view(-1,10, 200)\n",
        "print(a2.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10, 500])\n",
            "torch.Size([5, 10, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbflffF5jkhF",
        "colab_type": "text"
      },
      "source": [
        "### Convolution layer  가지고 놀기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekBQ5Gv5tdWt",
        "colab_type": "code",
        "outputId": "087ba013-ff2e-493c-aeec-8db0c2721053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# torch.nn.conv 연습\n",
        "# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n",
        "# 아웃풋사이즈가 이와같이 되도록 되도록 해봅니다: (16, 128, 32, 32)\n",
        "input1 = torch.zeros(16, 3, 64, 64)\n",
        "conv1 = nn.Conv2d(3, 512, 3, 1, 1)\n",
        "conv2 = nn.Conv2d(512,128,3,2,1)\n",
        "\n",
        "out = conv1(input1)\n",
        "output = conv2(out)\n",
        "\n",
        "print(output.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4y9j5V1toLX",
        "colab_type": "code",
        "outputId": "94bad342-53eb-4f25-bb0d-d51f92cb1e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# torch.nn.conv 연습\n",
        "# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n",
        "# 아웃풋사이즈가 이와같이 되도록 해봅니다: (16, 512, 16, 16)\n",
        "input = torch.zeros(16, 3, 64, 64)\n",
        "conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "conv2 = nn.Conv2d(64,512,3,4,1)\n",
        "\n",
        "out = conv1(input)\n",
        "output = conv2(out)\n",
        "\n",
        "print(output.size())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512, 16, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z98BxwUEtzMV",
        "colab_type": "code",
        "outputId": "7b7a009b-62cb-481d-b5c0-404dc2acbadb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#quiz 4 (torch.nn.conv 연습)\n",
        "# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n",
        "# 아웃풋사이즈가 이와같이 되도록 해봅니다: (16, 512, 64, 64)\n",
        "input = torch.zeros(16, 3, 64, 64)\n",
        "conv1 = nn.Conv2d(3,64,3,1,1)\n",
        "conv2 = nn.Conv2d(64,512,3,1,1)\n",
        "\n",
        "out = conv1(input)\n",
        "output = conv2(out)\n",
        "\n",
        "print(output.size())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0qEKErJjfFm",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 로딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWG00oKqntRB",
        "colab_type": "text"
      },
      "source": [
        "Data Augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbSxD67XjdzL",
        "colab_type": "code",
        "outputId": "b270ea09-d097-4dfe-9f59-5f0ef0777645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n",
        "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n",
        "\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 데이터 로딩\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXEmr4oVnyRv",
        "colab_type": "code",
        "outputId": "d5014d20-c808-4db6-ba7c-ae6751795dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "def showImages(image, row):\n",
        "  \n",
        "  for _ in range(row):  \n",
        "  \n",
        "    idx = np.random.choice(batch_size, 6)     # 0 ~ 127 의 정수 중 6 개를 임의로 선택\n",
        "    images =image.numpy()[idx].transpose(0,2,3,1).clip(0,1)         # 선택된 index 에 해당하는 이미지를 가져옴\n",
        "    plt.figure(figsize = (15, 90))     # 세로 길이 15, 가로 길이 15 * 6 의 화면 생성\n",
        "    \n",
        "    for i in range(161, 167):    \n",
        "    \n",
        "      plt.subplot(i)\n",
        "      plt.imshow(images[i - 161])\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])    \n",
        "    \n",
        "    plt.show()  \n",
        "\n",
        "for i, (image, labels) in enumerate(trainloader): \n",
        "  \n",
        "  showImages(image.squeeze(), 3)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl/n/uJERam28+MUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x6480 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x6480 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x6480 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGj5qoFcn0FF",
        "colab_type": "code",
        "outputId": "1fe0cfea-de39-4a78-b010-1a37044afe63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('[info] # of train batch : ' ,len(trainloader))\n",
        "print('[info] # of test batch : ', len(testloader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[info] # of train batch :  391\n",
            "[info] # of test batch :  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ9lTPT9n1dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network(net,optimizer,trainloader, epochs=5):\n",
        "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n",
        "      for i, data in enumerate(trainloader): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n",
        "          # get the inputs\n",
        "          inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n",
        "          inputs = inputs.to(device) # Pytorch에서 nn.Module 에 넣어 Backprop을 계산 하기 위해서는 gpu 연동을 이와 같이 해줘야 합니다.\n",
        "          labels = labels.to(device)\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다.\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n",
        "          loss = criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n",
        "          loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n",
        "          optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          if (i+1) % 100 == 0:    # print every 500 mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 100))\n",
        "              running_loss = 0.0\n",
        "\n",
        "  print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F3ZmR6-oIH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model,test_loader):\n",
        "  model.eval() # Eval Mode 왜 해야 할까요?  --> nn.Dropout BatchNorm 등의 Regularization 들이 test 모드로 들어가게 되기 때문입니다. \n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)  # 기존의 train function의 data 처리부분과 같습니다. \n",
        "    output = model(data) \n",
        "    pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
        "    correct += pred.eq(target.view_as(pred)).sum().item() # 정답 데이터의 갯수를 반환합니다. \n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      correct, len(test_loader.dataset),\n",
        "      100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRrx1X1RN-_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model): # 모델 파라미터 개수를 리턴하는 함수를 하나 만들어둡니다\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5gzkWcJoUxC",
        "colab_type": "text"
      },
      "source": [
        "### MNIST에서 사용했던 MLP를 적용해보자!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fwsRmXDoL8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_Net, self).__init__()\n",
        "        \n",
        "        layer_list = [] # 이 리스트에 모든 Layer 를 순차적으로 append 해보겠습니다. \n",
        "        layer_list.append(nn.Linear(3*32*32,256)) #Layer 1 인풋 사이즈가 32*32로 변경되었기 때문에 바꿔줍니다!!\n",
        "        layer_list.append(nn.BatchNorm1d(256))#BatchNorm1\n",
        "        layer_list.append(nn.ReLU()) # Relu \n",
        "        layer_list.append(nn.Linear(256, 64)) # Layer 2\n",
        "        layer_list.append(nn.BatchNorm1d(64)) #BatchNorm1\n",
        "        layer_list.append(nn.ReLU())# Relu \n",
        "        layer_list.append(nn.Linear(64, 10)) # Layer 3\n",
        "        self.net  = nn.Sequential(*layer_list) # nn.Sequential 에 layer list를 넘겨 줍니다.\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1,32*32*3)\n",
        "        x = self.net(x) # 넣은 순서대로 적용이 됩니다. \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXDe9e8goV4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(mnist_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET-9RK75oX3w",
        "colab_type": "code",
        "outputId": "7d519dcf-209c-474c-c939-dad25f3845ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_network(mnist_net,optimizer,trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 2.034\n",
            "[1,   200] loss: 1.835\n",
            "[1,   300] loss: 1.739\n",
            "[2,   100] loss: 1.651\n",
            "[2,   200] loss: 1.617\n",
            "[2,   300] loss: 1.616\n",
            "[3,   100] loss: 1.561\n",
            "[3,   200] loss: 1.555\n",
            "[3,   300] loss: 1.541\n",
            "[4,   100] loss: 1.518\n",
            "[4,   200] loss: 1.507\n",
            "[4,   300] loss: 1.500\n",
            "[5,   100] loss: 1.473\n",
            "[5,   200] loss: 1.470\n",
            "[5,   300] loss: 1.476\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO5Aa_PCoYxL",
        "colab_type": "code",
        "outputId": "02893f2c-30e4-470f-9cd1-f7a277c1383b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(mnist_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 5070/10000 (51%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58fk39tBo91s",
        "colab_type": "text"
      },
      "source": [
        "### 심플한 CNN 모델을 만들어 봅시다.\n",
        "\n",
        "<구성>\n",
        "\n",
        "Layer 1 - input: 3 x 32 x 32, output: 64 x 32 x 32- ReLU + BatchNorm\n",
        "\n",
        "Layer 2 - input: 64 x 32 x 32, output: 128 x 16 x 16- ReLU + BatchNorm (Down Conv라고 부릅니다.)\n",
        "\n",
        "Layer 5 - Global Average Pooling (128 x 16 x 16 => 128 x 1 x 1)\n",
        "\n",
        "Layer 6 - input: 128 x 1 x 1, output 10 x 1 x 1 - ReLU + BatchNorm\n",
        "\n",
        "![대체 텍스트](https://cdn-images-1.medium.com/max/1600/1*D47ER7IArwPv69k3O_1nqQ.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf3CEXKVpi_0",
        "colab_type": "code",
        "outputId": "7715b564-dfba-4322-a806-9829ec2fa663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiyCNN, self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    layers += [nn.Conv2d(in_channels=??, out_channels=??, kernel_size=7, stride=1, padding=3)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
        "    layers += [nn.BatchNorm2d(??)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(??, 128, 5, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(??)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(??, 256, 5, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(256)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(??, ??, 5, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(512)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
        "    \n",
        "    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
        "    \n",
        "    self.main = nn.Sequential(*layers)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.main(x).squeeze(3).squeeze(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-93-c2b1dfeaf243>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    layers += [nn.Conv2d(in_channels=??, out_channels=??, kernel_size=7, stride=1, padding=3)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vorrzAVgq4Dg",
        "colab_type": "text"
      },
      "source": [
        "##### 정답: 자신을 위해 가능한 확인하지 않고 진행해주세요~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J1292kjL1tM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiyCNN, self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
        "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(128)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(256)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(512)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
        "    \n",
        "    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
        "    \n",
        "    self.main = nn.Sequential(*layers)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.main(x).squeeze(3).squeeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZjiCK5vre9t",
        "colab_type": "code",
        "outputId": "9af58806-b4b8-4bd7-a3a2-8e7967341464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n",
        "\n",
        "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[info] number of model parameter - 1558026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE8APJgRrgfS",
        "colab_type": "code",
        "outputId": "835250c9-119b-453c-cf9d-1e4309f811a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_network(cifar_net,optimizer,trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.743\n",
            "[1,   200] loss: 1.491\n",
            "[1,   300] loss: 1.371\n",
            "[2,   100] loss: 1.216\n",
            "[2,   200] loss: 1.172\n",
            "[2,   300] loss: 1.116\n",
            "[3,   100] loss: 1.029\n",
            "[3,   200] loss: 1.017\n",
            "[3,   300] loss: 1.006\n",
            "[4,   100] loss: 0.934\n",
            "[4,   200] loss: 0.919\n",
            "[4,   300] loss: 0.904\n",
            "[5,   100] loss: 0.844\n",
            "[5,   200] loss: 0.843\n",
            "[5,   300] loss: 0.834\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcX_blYBrhef",
        "colab_type": "code",
        "outputId": "ed53d1b6-33b6-41f7-8a20-c98600939071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(cifar_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 7263/10000 (73%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMBJ5Vla_Wkd",
        "colab_type": "text"
      },
      "source": [
        "### Average Pooling 대신 Linear Layer로!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YXvUnMAys_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiyCNN, self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
        "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(128)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(256)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(512)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    classifier = []\n",
        "    classifier += [nn.Linear(512*4,512)]\n",
        "    \n",
        "    classifier += [nn.Linear(512,10)]\n",
        "    \n",
        "    \n",
        "    \n",
        "    self.main = nn.Sequential(*layers)\n",
        "    self.classifier = nn.Sequential(*classifier)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.main(x)\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.classifier(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbVONDRyz1RK",
        "colab_type": "code",
        "outputId": "aa19d4be-b3d8-4db8-88e7-16796ca6a033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n",
        "\n",
        "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[info] number of model parameter - 2607114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0OFFnddz4CS",
        "colab_type": "code",
        "outputId": "361b8713-0914-4443-af35-2a273b09e531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_network(cifar_net,optimizer,trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.771\n",
            "[1,   200] loss: 1.506\n",
            "[1,   300] loss: 1.381\n",
            "[2,   100] loss: 1.238\n",
            "[2,   200] loss: 1.152\n",
            "[2,   300] loss: 1.116\n",
            "[3,   100] loss: 1.016\n",
            "[3,   200] loss: 0.973\n",
            "[3,   300] loss: 0.962\n",
            "[4,   100] loss: 0.882\n",
            "[4,   200] loss: 0.875\n",
            "[4,   300] loss: 0.868\n",
            "[5,   100] loss: 0.803\n",
            "[5,   200] loss: 0.809\n",
            "[5,   300] loss: 0.786\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q27tKqAuz4tM",
        "colab_type": "code",
        "outputId": "9621348d-771a-40b2-ad12-cae212ead3fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(cifar_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 7410/10000 (74%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-UID3Msy1L4",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 intialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyzEg2_y08-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiyCNN, self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
        "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(128)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(256)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(512)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
        "    \n",
        "    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
        "    \n",
        "    self.main = nn.Sequential(*layers)\n",
        "    self._reset_params()\n",
        "  def _reset_params(self):\n",
        "    for i,layer in enumerate(self.main):\n",
        "      if type(layer) == nn.Conv2d:\n",
        "        torch.nn.init.xavier_uniform_(layer.weight.data)\n",
        "  def forward(self, x):\n",
        "    return self.main(x).squeeze(3).squeeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbFjh1PL1cJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqshiap61eT8",
        "colab_type": "code",
        "outputId": "ca87a989-7c63-485c-dc16-21868491a995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_network(cifar_net,optimizer,trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.728\n",
            "[1,   200] loss: 1.484\n",
            "[1,   300] loss: 1.384\n",
            "[2,   100] loss: 1.225\n",
            "[2,   200] loss: 1.168\n",
            "[2,   300] loss: 1.131\n",
            "[3,   100] loss: 1.045\n",
            "[3,   200] loss: 1.022\n",
            "[3,   300] loss: 1.006\n",
            "[4,   100] loss: 0.934\n",
            "[4,   200] loss: 0.920\n",
            "[4,   300] loss: 0.909\n",
            "[5,   100] loss: 0.862\n",
            "[5,   200] loss: 0.851\n",
            "[5,   300] loss: 0.832\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y5LmO0S1hHs",
        "colab_type": "code",
        "outputId": "4330b476-bbbe-4278-efcd-2519dbfc0bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(cifar_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 7350/10000 (74%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACfwmSHo1pUW",
        "colab_type": "text"
      },
      "source": [
        "weight intialization은 효과가 있었나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1gj-ahZvtOK",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 전처리를 한번 없애면 성능은 어떻게 변할까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQqpAoljvf2t",
        "colab_type": "code",
        "outputId": "c642ba16-a2de-44c7-b883-97c280e5908d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_train = transforms.Compose([\n",
        "   \n",
        "    transforms.ToTensor(),\n",
        "     \n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "   # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 데이터 로딩\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_j7qGdvztc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYqBc07Qv2rl",
        "colab_type": "code",
        "outputId": "dca0d705-7e99-40b0-ee19-444404035be9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_network(cifar_net,optimizer,trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.588\n",
            "[1,   200] loss: 1.283\n",
            "[1,   300] loss: 1.159\n",
            "[2,   100] loss: 0.932\n",
            "[2,   200] loss: 0.915\n",
            "[2,   300] loss: 0.868\n",
            "[3,   100] loss: 0.695\n",
            "[3,   200] loss: 0.699\n",
            "[3,   300] loss: 0.710\n",
            "[4,   100] loss: 0.518\n",
            "[4,   200] loss: 0.527\n",
            "[4,   300] loss: 0.561\n",
            "[5,   100] loss: 0.352\n",
            "[5,   200] loss: 0.385\n",
            "[5,   300] loss: 0.422\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRNdaQCHv3mc",
        "colab_type": "code",
        "outputId": "334e32b7-e1cd-49b4-c7c4-9489c475a0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(cifar_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 6834/10000 (68%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Y3AkxQ1xe0",
        "colab_type": "text"
      },
      "source": [
        "Q) 왜 성능이 낮아졌을까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j90-Gd4lwyV2",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 shuffling 의 효과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zcon8zppww3H",
        "colab_type": "code",
        "outputId": "08e12b27-b434-45e7-8f2e-a374ace7c06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n",
        "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n",
        "\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 데이터 로딩\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj8oSDzAw68t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-yaC6mkw9g3",
        "colab_type": "code",
        "outputId": "a3a40899-7941-4156-ed2b-5eed01d04bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_network(cifar_net,optimizer,trainloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.739\n",
            "[1,   200] loss: 1.488\n",
            "[1,   300] loss: 1.375\n",
            "[2,   100] loss: 1.219\n",
            "[2,   200] loss: 1.155\n",
            "[2,   300] loss: 1.113\n",
            "[3,   100] loss: 1.037\n",
            "[3,   200] loss: 1.013\n",
            "[3,   300] loss: 0.986\n",
            "[4,   100] loss: 0.927\n",
            "[4,   200] loss: 0.913\n",
            "[4,   300] loss: 0.895\n",
            "[5,   100] loss: 0.850\n",
            "[5,   200] loss: 0.834\n",
            "[5,   300] loss: 0.831\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xgf-jTdw-NY",
        "colab_type": "code",
        "outputId": "6180ce5f-c6d4-4466-a0e1-de34b95643e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(cifar_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 7224/10000 (72%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbjVKfzg13q6",
        "colab_type": "text"
      },
      "source": [
        "Q) Shuffling 을 제거 했더니 성능이 어떻게 변하나요?  shuffling 은 왜 중요할까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o19_PEjYxeBM",
        "colab_type": "text"
      },
      "source": [
        "### 다시 원래 옵션으로 되돌립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XclAWYKSxdH1",
        "colab_type": "code",
        "outputId": "5b94606a-0389-4f2e-8e2f-3fc5cda20ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n",
        "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n",
        "\n",
        "# 데이터 전처리를 위한 코드\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
        "])\n",
        "\n",
        "# 데이터 로딩\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0lINI_JMdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiyCNN, self).__init__()\n",
        "    layers = []\n",
        "\n",
        "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
        "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(128)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(256)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
        "    layers += [nn.BatchNorm2d(512)]\n",
        "    layers += [nn.ReLU()]\n",
        "    \n",
        "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
        "    \n",
        "    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
        "    \n",
        "    self.main = nn.Sequential(*layers)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.main(x).squeeze(3).squeeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yODwdqQEHIGz",
        "colab_type": "text"
      },
      "source": [
        "### Learning rate scheduler를 도입합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt5HHvczIZIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network2(net,optimizer,trainloader, scheduler, epochs=5):\n",
        "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n",
        "      for i, data in enumerate(trainloader): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n",
        "          # get the inputs\n",
        "          inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n",
        "          inputs = inputs.to(device) # Pytorch에서 nn.Module 에 넣어 Backprop을 계산 하기 위해서는 gpu 연동을 이와 같이 해줘야 합니다.\n",
        "          labels = labels.to(device)\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다.\n",
        "          # forward + backward + optimize\n",
        "          outputs = net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n",
        "          loss = criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n",
        "          loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n",
        "          optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          if (i+1) % 100 == 0:    # print every 500 mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 100))\n",
        "              running_loss = 0.0\n",
        "      scheduler.step() \n",
        "  print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OYIUWkQHHgQ",
        "colab_type": "code",
        "outputId": "4abf5bdb-118e-4f71-e4d8-a8c8c395e83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "scheduler = MultiStepLR(optimizer, milestones=[2,4], gamma=0.5)# learning rate을 0.1에서 시작해서 1에폭마다 1/10로 줄여보겠습니다.\n",
        "cifar_net = DiyCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=0.001) # 초반 learning rate이 0.1입니다\n",
        "\n",
        "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[info] number of model parameter - 1558026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P90jBCr9I1Zx",
        "colab_type": "code",
        "outputId": "220e9ed6-6656-4a50-e5e2-f5eea8756f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "train_network2(cifar_net,optimizer,trainloader, scheduler, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.739\n",
            "[1,   200] loss: 1.464\n",
            "[1,   300] loss: 1.348\n",
            "[2,   100] loss: 1.214\n",
            "[2,   200] loss: 1.144\n",
            "[2,   300] loss: 1.133\n",
            "[3,   100] loss: 1.031\n",
            "[3,   200] loss: 1.030\n",
            "[3,   300] loss: 0.987\n",
            "[4,   100] loss: 0.951\n",
            "[4,   200] loss: 0.918\n",
            "[4,   300] loss: 0.902\n",
            "[5,   100] loss: 0.844\n",
            "[5,   200] loss: 0.835\n",
            "[5,   300] loss: 0.840\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1gRZluHJq8V",
        "colab_type": "code",
        "outputId": "0d60833a-7d1a-4441-fbfa-5dc12a77da4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(cifar_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 7287/10000 (73%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6umQIX-Urwyn",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained 모형 가지고 와서 성능 확인하기 (Transfer Learning 관점)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JecQ-Fkmxjk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "vgg_model = models.vgg19_bn(pretrained=True).to(device) # 기존에 만들어진 vgg network 을 이미지넷 데이터에 트레이닝해둔 파라미터를 그대로 받아옵니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofQJ3YcwFqvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiyCNN(nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(DiyCNN, self).__init__()\n",
        "        self.pre_trained = nn.Sequential(   \n",
        "            *list(vgg_model.features.children())\n",
        "        )\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        out = self.pre_trained(x).squeeze()\n",
        "        out = self.mlp(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6tyTU-3yGHz",
        "colab_type": "code",
        "outputId": "0e2c173a-4a22-4e29-b948-cad99fadc0b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cifar_net = DiyCNN(vgg_model).to(device)\n",
        "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
        "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n",
        "\n",
        "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[info] number of model parameter - 20365002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pro0ncYIyJLg",
        "colab_type": "code",
        "outputId": "f26f55cb-e0ec-4156-c57a-937a40fba0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train_network(cifar_net,optimizer,trainloader, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.405\n",
            "[1,   200] loss: 0.970\n",
            "[1,   300] loss: 0.827\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7hPPEjyLX6",
        "colab_type": "code",
        "outputId": "e2634f69-0347-4b7b-8ce6-dc56c56be9c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test(cifar_net,testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set:  Accuracy: 7699/10000 (77%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4xj3RNZO79a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}