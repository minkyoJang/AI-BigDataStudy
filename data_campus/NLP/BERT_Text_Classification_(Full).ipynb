{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Text Classification (Full).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/getChan/data_campus/blob/master/NLP/BERT_Text_Classification_(Full).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adzlJRbDyc3A",
        "colab_type": "code",
        "outputId": "272fd209-ceb6-4e25-e5bd-dfd062f8453f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "! pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az_pyElrvT6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pickle\n",
        "import bert\n",
        "import os\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "\n",
        "def create_tokenizer_from_hub_module(bert_model_hub):\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    with tf.Graph().as_default():\n",
        "        bert_module = hub.Module(bert_model_hub)\n",
        "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "        with tf.Session() as sess:\n",
        "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                                  tokenization_info[\"do_lower_case\"]])\n",
        "\n",
        "        print(\"Using BERT from %s\" %bert_model_hub)\n",
        "        print(\"with vocab size=%d and do_lower_case=%s.\" %(len(vocab_file), str(do_lower_case)))\n",
        "\n",
        "    return bert.tokenization.FullTokenizer(\n",
        "        vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "\n",
        "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
        "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                             text_a=x[DATA_COLUMN],\n",
        "                                                                             text_b=None,\n",
        "                                                                             label=x[LABEL_COLUMN]), axis=1)\n",
        "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "    return features\n",
        "\n",
        "\n",
        "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "    \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "    bert_module = hub.Module(\n",
        "        bert_model_hub,\n",
        "        trainable=True)\n",
        "    bert_inputs = dict(\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids)\n",
        "    bert_outputs = bert_module(\n",
        "        inputs=bert_inputs,\n",
        "        signature=\"tokens\",\n",
        "        as_dict=True)\n",
        "\n",
        "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "    # Use \"sequence_outputs\" for token-level output.\n",
        "    output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "    with tf.variable_scope(\"output_layer\"):\n",
        "        layer_out = tf.layers.dense(\n",
        "            inputs=output_layer,\n",
        "            units=num_labels,\n",
        "            use_bias=False,\n",
        "            kernel_initializer=tf.initializers.variance_scaling()\n",
        "        )\n",
        "        predicted_labels = tf.squeeze(tf.argmax(layer_out, axis=-1, output_type=tf.int32))\n",
        "\n",
        "        if is_predicting:\n",
        "            return predicted_labels, layer_out\n",
        "        else:\n",
        "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                labels=labels,\n",
        "                logits=layer_out\n",
        "            )\n",
        "            loss = tf.reduce_mean(loss)\n",
        "\n",
        "            return loss, predicted_labels, layer_out\n",
        "\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "\n",
        "        # TRAIN and EVAL\n",
        "        if not is_predicting:\n",
        "\n",
        "            (loss, predicted_labels, log_probs) = create_model(\n",
        "                bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "            train_op = bert.optimization.create_optimizer(\n",
        "                loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "            # Calculate evaluation metrics.\n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                f1_score = tf.contrib.metrics.f1_score(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                auc = tf.metrics.auc(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                recall = tf.metrics.recall(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                precision = tf.metrics.precision(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                true_pos = tf.metrics.true_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                true_neg = tf.metrics.true_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                false_pos = tf.metrics.false_positives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                false_neg = tf.metrics.false_negatives(\n",
        "                    label_ids,\n",
        "                    predicted_labels)\n",
        "                return {\n",
        "                    \"eval_accuracy\": accuracy,\n",
        "                    \"f1_score\": f1_score,\n",
        "                    \"auc\": auc,\n",
        "                    \"precision\": precision,\n",
        "                    \"recall\": recall,\n",
        "                    \"true_positives\": true_pos,\n",
        "                    \"true_negatives\": true_neg,\n",
        "                    \"false_positives\": false_pos,\n",
        "                    \"false_negatives\": false_neg\n",
        "                }\n",
        "\n",
        "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                                  loss=loss,\n",
        "                                                  train_op=train_op)\n",
        "            else:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode,\n",
        "                                                  loss=loss,\n",
        "                                                  eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (predicted_labels, log_probs) = create_model(\n",
        "                bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "            predictions = {\n",
        "                'probabilities': log_probs,\n",
        "                'labels': predicted_labels\n",
        "            }\n",
        "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    # Return the actual model function in the closure\n",
        "    return model_fn\n",
        "\n",
        "\n",
        "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE,\n",
        "                      num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
        "    # Specify outpit directory and number of checkpoint steps to save\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=OUTPUT_DIR,\n",
        "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "        bert_model_hub=bert_model_hub,\n",
        "        num_labels=len(label_list),\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        params={\"batch_size\": BATCH_SIZE})\n",
        "    return estimator, model_fn, run_config\n",
        "\n",
        "\n",
        "def run_on_dfs(train, test, data_column, label_column,\n",
        "               max_seq_length=128,\n",
        "               batch_size=32,\n",
        "               learning_rate=2e-5,\n",
        "               num_train_epochs=3,\n",
        "               warmup_proportion=0.1,\n",
        "               save_summary_steps=100,\n",
        "               save_checkpoint_steps=10000,\n",
        "               bert_model_hub=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
        "               output_dir=\"output\"):\n",
        "    label_list = train[label_column].unique().tolist()\n",
        "\n",
        "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
        "\n",
        "    train_features = make_features(train, label_list, max_seq_length, tokenizer, data_column, label_column)\n",
        "    test_features = make_features(test, label_list, max_seq_length, tokenizer, data_column, label_column)\n",
        "\n",
        "    steps_per_epoch = math.ceil(len(train_features) / batch_size)\n",
        "\n",
        "    num_train_steps = int(len(train_features) / batch_size * num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "    estimator, model_fn, run_config = estimator_builder(\n",
        "        bert_model_hub,\n",
        "        output_dir,\n",
        "        save_summary_steps,\n",
        "        save_checkpoint_steps,\n",
        "        label_list,\n",
        "        learning_rate,\n",
        "        num_train_steps,\n",
        "        num_warmup_steps,\n",
        "        batch_size)\n",
        "\n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=train_features,\n",
        "        seq_length=max_seq_length,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "        features=test_features,\n",
        "        seq_length=max_seq_length,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "\n",
        "    results = []\n",
        "    for epoch in range(num_train_epochs):\n",
        "        estimator.train(input_fn=train_input_fn, steps=steps_per_epoch)\n",
        "\n",
        "        print(\"End of epoch %d.\" %(epoch + 1))\n",
        "\n",
        "        result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "        print(result_dict)\n",
        "        results.append(result_dict)\n",
        "\n",
        "    return results, estimator\n",
        "\n",
        "\n",
        "def pretty_print(result):\n",
        "    df = pd.DataFrame([result]).T\n",
        "    df.columns = [\"values\"]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRVzb1Y2y9_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(data_file):\n",
        "    data = pd.read_csv(data_file)\n",
        "\n",
        "    # Only use the top quartile as polite, and bottom quartile as impolite. Discard the rest.\n",
        "    quantiles = data[\"Normalized Score\"].quantile([0.25, 0.5, 0.75])\n",
        "    # print(quantiles)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        score = data.loc[i, \"Normalized Score\"]\n",
        "        if score <= quantiles[0.25]:\n",
        "            # Bottom quartile (impolite).\n",
        "            data.loc[i, \"Normalized Score\"] = 0\n",
        "        elif score >= quantiles[0.75]:\n",
        "            # Top quartile (polite).\n",
        "            data.loc[i, \"Normalized Score\"] = 1\n",
        "        else:\n",
        "            # Neutral.\n",
        "            data.loc[i, \"Normalized Score\"] = 2\n",
        "\n",
        "    data[\"Normalized Score\"] = data[\"Normalized Score\"].astype(int)\n",
        "\n",
        "    # Discard neutral examples.\n",
        "    data = data[data[\"Normalized Score\"] < 2]\n",
        "    \n",
        "    data.sample(frac=1).reset_index(drop=True)\n",
        "    n_test = len(data) // 10\n",
        "    test_data = data[:n_test]\n",
        "    train_data = data[n_test:]\n",
        "    \n",
        "    print(\"Data loaded successfully. Train=%d, test=%d, total=%d.\" % (len(train_data), len(test_data), len(train_data) + len(test_data)))\n",
        "    print(\"Some train samples:\")\n",
        "    print(train_data.head())\n",
        "    print(\"Some test samples:\")\n",
        "    print(test_data.head())\n",
        "\n",
        "    return train_data, test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BxeqnzOyok3",
        "colab_type": "code",
        "outputId": "a408886d-ce5a-4994-9d5e-2d2b8b3bf218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if not os.path.exists(\"Stanford_politeness_corpus.zip\"):\n",
        "  !wget http://www.cs.cornell.edu/~cristian/Politeness_files/Stanford_politeness_corpus.zip\n",
        "\n",
        "if not os.path.exists(\"Stanford_politeness_corpus/wikipedia.annotated.csv\"):\n",
        "  !unzip Stanford_politeness_corpus.zip\n",
        "\n",
        "train_data, test_data = load_data(\"Stanford_politeness_corpus/wikipedia.annotated.csv\")\n",
        "\n",
        "params = {\n",
        "    \"data_column\": \"Request\",\n",
        "    \"label_column\": \"Normalized Score\",\n",
        "    \"batch_size\": 16,\n",
        "    \"num_train_epochs\": 3,\n",
        "    \"bert_model_hub\": \"https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\"\n",
        "}\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "result, estimator = run_on_dfs(train_data, test_data, **params)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded successfully. Train=1961, test=217, total=2178.\n",
            "Some train samples:\n",
            "     Community      Id  ...         TurkId5  Normalized Score\n",
            "460  Wikipedia  621480  ...  A1Y3Z92RE62NPS                 1\n",
            "462  Wikipedia  146267  ...  A3IHLWMZNBLUR4                 1\n",
            "463  Wikipedia   84242  ...   AIPK94CUWL45W                 1\n",
            "464  Wikipedia  487517  ...  A1F4D2PZ7NNWTL                 1\n",
            "466  Wikipedia  629492  ...  A2WZQ92N4809N1                 1\n",
            "\n",
            "[5 rows x 14 columns]\n",
            "Some test samples:\n",
            "   Community      Id  ...         TurkId5  Normalized Score\n",
            "0  Wikipedia  629705  ...  A15DM9BMKZZJQ6                 0\n",
            "1  Wikipedia  244336  ...  A3TFQK7QK8X6LM                 1\n",
            "5  Wikipedia  214411  ...  A1Y3Z92RE62NPS                 1\n",
            "8  Wikipedia  177439  ...  A29B522D0BX6HN                 0\n",
            "9  Wikipedia  341534  ...  A28TXBSZPWMEU9                 0\n",
            "\n",
            "[5 rows x 14 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0801 08:55:03.547953 140393886611328 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "I0801 08:55:04.198145 140393886611328 run_classifier.py:774] Writing example 0 of 1961\n",
            "I0801 08:55:04.200582 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:04.205874 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:04.210916 140393886611328 run_classifier.py:464] tokens: [CLS] Thanks . As an aside , since this did turn out to be fact ##ual , just very hard to source , do you think the community would count ##enan ##ce an un ##block request from B ##la ##ab ##la if he accepted some strict un ##block conditions ( such as packing in the ' systemic bias ' thing , discussing his edit ##s in a less confrontation ##al manner etc ) ? [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using BERT from https://tfhub.dev/google/bert_cased_L-12_H-768_A-12/1\n",
            "with vocab size=76 and do_lower_case=False.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0801 08:55:04.214390 140393886611328 run_classifier.py:465] input_ids: 101 5749 119 1249 1126 4783 117 1290 1142 1225 1885 1149 1106 1129 1864 4746 117 1198 1304 1662 1106 2674 117 1202 1128 1341 1103 1661 1156 5099 25191 2093 1126 8362 27467 4566 1121 139 1742 6639 1742 1191 1119 3134 1199 9382 8362 27467 2975 113 1216 1112 16360 1107 1103 112 27410 15069 112 1645 117 10751 1117 14609 1116 1107 170 1750 14002 1348 4758 3576 114 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.215842 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.218999 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.220442 140393886611328 run_classifier.py:468] label: 1 (id = 0)\n",
            "I0801 08:55:04.223113 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:04.224514 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:04.226443 140393886611328 run_classifier.py:464] tokens: [CLS] Everything about < u ##rl > looks fantastic , but . . going to | 2 instead of | 30 ##em seems like a major step back . Is there a reason for it ? [SEP]\n",
            "I0801 08:55:04.228824 140393886611328 run_classifier.py:465] input_ids: 101 5268 1164 133 190 17670 135 2736 14820 117 1133 119 119 1280 1106 197 123 1939 1104 197 1476 5521 3093 1176 170 1558 2585 1171 119 2181 1175 170 2255 1111 1122 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.230009 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.231534 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.233461 140393886611328 run_classifier.py:468] label: 1 (id = 0)\n",
            "I0801 08:55:04.236287 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:04.237581 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:04.238702 140393886611328 run_classifier.py:464] tokens: [CLS] I wonder if it would ever be worth doing an article on G & S scholarship ? You know , cover the major discoveries , describe the evolution of the field . . . or is that too likely to hit problems ? [SEP]\n",
            "I0801 08:55:04.240858 140393886611328 run_classifier.py:465] input_ids: 101 146 4608 1191 1122 1156 1518 1129 3869 1833 1126 3342 1113 144 111 156 7084 136 1192 1221 117 2267 1103 1558 17707 117 5594 1103 7243 1104 1103 1768 119 119 119 1137 1110 1115 1315 2620 1106 1855 2645 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.242708 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.244940 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.245961 140393886611328 run_classifier.py:468] label: 1 (id = 0)\n",
            "I0801 08:55:04.248778 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:04.249967 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:04.251146 140393886611328 run_classifier.py:464] tokens: [CLS] Thanks for your help on this , it ' s much appreciated . Should I del ##ete my request for check ##user ? [SEP]\n",
            "I0801 08:55:04.252145 140393886611328 run_classifier.py:465] input_ids: 101 5749 1111 1240 1494 1113 1142 117 1122 112 188 1277 12503 119 9743 146 3687 16618 1139 4566 1111 4031 19399 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.253416 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.254638 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.255618 140393886611328 run_classifier.py:468] label: 1 (id = 0)\n",
            "I0801 08:55:04.258063 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:04.259044 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:04.260300 140393886611328 run_classifier.py:464] tokens: [CLS] Yes please ! B ##uff ##ing up ' ' < u ##rl > ' ' to at least reflect a bit better on current state - of - play - tax ##ono ##mic ##ally would be good : ) Any Re ##lia ##ble Sources call it a < u ##rl > ? [SEP]\n",
            "I0801 08:55:04.261486 140393886611328 run_classifier.py:465] input_ids: 101 2160 4268 106 139 9435 1158 1146 112 112 133 190 17670 135 112 112 1106 1120 1655 7977 170 2113 1618 1113 1954 1352 118 1104 118 1505 118 3641 23038 7257 2716 1156 1129 1363 131 114 6291 11336 4567 2165 22656 1840 1122 170 133 190 17670 135 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.262456 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.263676 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:04.264790 140393886611328 run_classifier.py:468] label: 1 (id = 0)\n",
            "I0801 08:55:05.407844 140393886611328 run_classifier.py:774] Writing example 0 of 217\n",
            "I0801 08:55:05.409238 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:05.410118 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:05.411096 140393886611328 run_classifier.py:464] tokens: [CLS] Where did you learn English ? How come you ' re taking on a third language ? [SEP]\n",
            "I0801 08:55:05.412279 140393886611328 run_classifier.py:465] input_ids: 101 2777 1225 1128 3858 1483 136 1731 1435 1128 112 1231 1781 1113 170 1503 1846 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.413391 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.414389 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.416557 140393886611328 run_classifier.py:468] label: 0 (id = 1)\n",
            "I0801 08:55:05.419002 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:05.421263 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:05.422669 140393886611328 run_classifier.py:464] tokens: [CLS] Thanks very much for your edit to the < u ##rl > article . Would you be interested in ta ##ckling the < u ##rl > of < u ##rl > ? [SEP]\n",
            "I0801 08:55:05.424148 140393886611328 run_classifier.py:465] input_ids: 101 5749 1304 1277 1111 1240 14609 1106 1103 133 190 17670 135 3342 119 5718 1128 1129 3888 1107 27629 27102 1103 133 190 17670 135 1104 133 190 17670 135 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.433102 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.434185 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.435482 140393886611328 run_classifier.py:468] label: 1 (id = 0)\n",
            "I0801 08:55:05.437958 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:05.439000 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:05.440116 140393886611328 run_classifier.py:464] tokens: [CLS] | style = \" vertical - al ##ign : middle ; pad ##ding : 3 ##p ##x ; \" | I ' ve started the Bad ##finger w ##iki am ##d I need help . You seem to know a lot about them , could you please help out ? [SEP]\n",
            "I0801 08:55:05.441390 140393886611328 run_classifier.py:465] input_ids: 101 197 1947 134 107 7391 118 2393 11368 131 2243 132 12921 3408 131 124 1643 1775 132 107 197 146 112 1396 1408 1103 6304 22225 192 12635 1821 1181 146 1444 1494 119 1192 3166 1106 1221 170 1974 1164 1172 117 1180 1128 4268 1494 1149 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.442397 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.443466 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.445579 140393886611328 run_classifier.py:468] label: 1 (id = 0)\n",
            "I0801 08:55:05.447906 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:05.449617 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:05.451832 140393886611328 run_classifier.py:464] tokens: [CLS] These are my numbers : 7 years in Wikipedia , 6 years as an ad ##min , 570 + articles , 4 featured articles , 1 featured list , 21 Good articles , 60 D ##Y ##K ' s - After six years as an ad ##min . I recently made some mistakes and I can understand if I am placed in some type of probation were I am monitored and forbidden to use my tools maybe for a year , but do I really merit the removal of my ad ##mins ##hip ? [SEP]\n",
            "I0801 08:55:05.453756 140393886611328 run_classifier.py:465] input_ids: 101 1636 1132 1139 2849 131 128 1201 1107 18920 117 127 1201 1112 1126 8050 7937 117 28081 116 4237 117 125 2081 4237 117 122 2081 2190 117 1626 2750 4237 117 2539 141 3663 2428 112 188 118 1258 1565 1201 1112 1126 8050 7937 119 146 3055 1189 1199 12572 1105 146 1169 2437 1191 146 1821 1973 1107 1199 2076 1104 23793 1127 146 1821 19232 1105 12031 1106 1329 1139 5537 2654 1111 170 1214 117 1133 1202 146 1541 16008 1103 8116 1104 1139 8050 19296 3157 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.455619 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.458129 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.460309 140393886611328 run_classifier.py:468] label: 0 (id = 1)\n",
            "I0801 08:55:05.462755 140393886611328 run_classifier.py:461] *** Example ***\n",
            "I0801 08:55:05.465117 140393886611328 run_classifier.py:462] guid: None\n",
            "I0801 08:55:05.467108 140393886611328 run_classifier.py:464] tokens: [CLS] I couldn ' t tell you why g ##lam rock was there . Better ? [SEP]\n",
            "I0801 08:55:05.469290 140393886611328 run_classifier.py:465] input_ids: 101 146 1577 112 189 1587 1128 1725 176 7609 2067 1108 1175 119 8529 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.471772 140393886611328 run_classifier.py:466] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.474935 140393886611328 run_classifier.py:467] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0801 08:55:05.477205 140393886611328 run_classifier.py:468] label: 0 (id = 1)\n",
            "I0801 08:55:05.646860 140393886611328 estimator.py:209] Using config: {'_model_dir': 'output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faf3b904128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0801 08:55:06.751308 140393886611328 estimator.py:1145] Calling model_fn.\n",
            "I0801 08:55:09.867592 140393886611328 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0801 08:55:19.285422 140393886611328 estimator.py:1147] Done calling model_fn.\n",
            "I0801 08:55:19.288357 140393886611328 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0801 08:55:21.040728 140393886611328 monitored_session.py:240] Graph was finalized.\n",
            "I0801 08:55:21.057203 140393886611328 saver.py:1280] Restoring parameters from output/model.ckpt-369\n",
            "I0801 08:55:30.439778 140393886611328 session_manager.py:500] Running local_init_op.\n",
            "I0801 08:55:30.718146 140393886611328 session_manager.py:502] Done running local_init_op.\n",
            "I0801 08:55:40.342370 140393886611328 basic_session_run_hooks.py:606] Saving checkpoints for 369 into output/model.ckpt.\n",
            "I0801 08:55:53.575377 140393886611328 basic_session_run_hooks.py:262] loss = 0.0004567166, step = 369\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}