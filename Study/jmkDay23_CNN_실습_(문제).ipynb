{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJKtgmNc774E"
   },
   "source": [
    "링크 주소: tinyurl.com/skt-04-12\n",
    "다운로드 후 google drive 업로드\n",
    "Colaboratory로 열기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9SH_g6i-jMBh"
   },
   "source": [
    "### pyTorch 를 비롯해 오늘 실습에 필요한 파이썬 라이브러리를 읽어들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-5K8m1hfCRC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #\n",
    "import torch.nn.functional as F #\n",
    "import torchvision # 이미지 관련 처리, Pretrained Model 관련된 Package 입니다. \n",
    "import torchvision.datasets as vision_dsets\n",
    "import torchvision.transforms as transforms # 이미지 처리 (Vison) 관련된 transformation이 정의 되어 있습니다.\n",
    "import torch.optim as optim # pytorch 에서 정의한 수 많은 optimization function 들이 들어 있습니다.\n",
    "from torch.utils import data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # 시각화를 위한 패키지입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yz8VMAXSjYCe"
   },
   "source": [
    "### Hyper-parameter 세팅 및 기타 변수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-G0yNhJjLtZ"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # pytorch0.4.0 이상 버젼에서 gpu 설정하는 방식, tensor.to(device) 이런식으로 사용\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXhH8tYwtQN7"
   },
   "source": [
    "### 다양한 함수 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1562083403519,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "gfkq3vn1ta4r",
    "outputId": "f83198d3-9762-43b2-927a-992b4bea7e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 12288])\n"
     ]
    }
   ],
   "source": [
    "# torch.view 연습\n",
    "\n",
    "sample = torch.randn(2000,3,64,64)\n",
    "#기본적으로, 이미지 처리를 할때 파이토치의 텐서 구성은 Batch, Channel, Height, Width로 구성.\n",
    "#코딩 시 B,C,H,W로 변수화하여 사용하면 편리\n",
    "\n",
    "B,C,H,W = sample.size()\n",
    "\n",
    "# sample => (2000, 64, 64, 3).  \n",
    "sample_1 = sample.view(B, -1) #위 sample 을 (2000, 3*64*64)으로 바꿔보세요.\n",
    "\n",
    "print(sample_1.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIEfCDZebJ5f"
   },
   "outputs": [],
   "source": [
    "#위 sample 을 (2000*3, 64*64)로 바꿔보세요.\n",
    "sample_2 = sample.view(B*C, ?)\n",
    "print(sample_2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "0iH_HikgtcN_",
    "outputId": "3e279299-02ed-4f40-d413-200216a983e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 500])\n",
      "torch.Size([5, 10, 200])\n"
     ]
    }
   ],
   "source": [
    "# torch.view 다른 예제\n",
    "a = torch.FloatTensor(5,20,100)\n",
    "a1 = a.view(2, 10, -1)\n",
    "print(a1.size())\n",
    "a2 = a.view(-1,10, 200)\n",
    "print(a2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1504,
     "status": "ok",
     "timestamp": 1562083609033,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "FpJXUhHfZqqk",
    "outputId": "870b4094-2d3d-4c94-e92a-3d5559e0e748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 3, 32, 64])\n",
      "torch.Size([2000, 3, 64, 32])\n"
     ]
    }
   ],
   "source": [
    "# dimension간의 이동을 하고 싶으면? ex) B,C,H,W => B,C,W,H \n",
    "sample = torch.randn(2000,3,32,64)\n",
    "sample_1 = sample.permute(0,1,3,2)\n",
    "print(sample.size())\n",
    "print(sample_1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1562083610890,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "AtmhGsJBbVSu",
    "outputId": "118d7506-2f10-4ab8-8584-54da847d553d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# sample_1 변수의 디멘션을 다시 원래대로 돌리려면?\n",
    "sample_2 = sample_1.??\n",
    "print(torch.equal(sample,sample_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbflffF5jkhF"
   },
   "source": [
    "### Convolution layer  가지고 놀기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2130,
     "status": "ok",
     "timestamp": 1562083896573,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "ekBQ5Gv5tdWt",
    "outputId": "949dc7f8-db5b-473e-84d7-311402dcd935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.conv 연습\n",
    "# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n",
    "# 아웃풋사이즈가 이와같이 되도록 되도록 해봅니다: (16, 128, 32, 32)\n",
    "input1 = torch.zeros(16, 3, 64, 64)\n",
    "conv1 = nn.Conv2d(3, 512, 3, 1, 1)\n",
    "conv2 = nn.Conv2d(512,128,4,2,1)\n",
    "\n",
    "out = conv1(input1)\n",
    "output = conv2(out)\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1562083952486,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "-4y9j5V1toLX",
    "outputId": "fc87f0b3-7126-44ef-a7a1-a4e08ff50206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.nn.conv 연습\n",
    "# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n",
    "# 아웃풋사이즈가 이와같이 되도록 해봅니다: (16, 512, 16, 16)\n",
    "input = torch.zeros(16, 3, 64, 64)\n",
    "conv1 = nn.Conv2d(3,64,3,1,1)\n",
    "conv2 = nn.Conv2d(64,512,3,4,1)\n",
    "\n",
    "out = conv1(input)\n",
    "output = conv2(out)\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "z98BxwUEtzMV",
    "outputId": "01182ee8-5c59-4007-a61c-297eb8c4dfca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#quiz 4 (torch.nn.conv 연습)\n",
    "# 클래스 구성: nn.Conv2d(in, out, filter_size, stride, padding)\n",
    "# 아웃풋사이즈가 이와같이 되도록 해봅니다: (16, 512, 64, 64)\n",
    "input = torch.zeros(16, 3, 64, 64)\n",
    "conv1 = nn.Conv2d(3,64,3,1,1)\n",
    "conv2 = nn.Conv2d(64,512,3,1,1)\n",
    "\n",
    "out = conv1(input)\n",
    "output = conv2(out)\n",
    "\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0qEKErJjfFm"
   },
   "source": [
    "### 데이터 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWG00oKqntRB"
   },
   "source": [
    "Data Augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14618,
     "status": "ok",
     "timestamp": 1562084093179,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "gbSxD67XjdzL",
    "outputId": "413322fd-5b34-4511-b735-f7d8d545f1a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 167911424/170498071 [00:10<00:00, 19807384.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n",
    "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
    "])\n",
    "\n",
    "# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n",
    "\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
    "])\n",
    "\n",
    "# 데이터 로딩\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5930,
     "status": "ok",
     "timestamp": 1562084160153,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "mXEmr4oVnyRv",
    "outputId": "93724c3f-7afe-4559-cde6-b03b0edbfc8d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGy0AAAAASBg3WgAAAACQsP8Pe+outvp5J+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x6480 with 6 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1080x6480 with 6 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAACMCAYAAABlLdgxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1080x6480 with 6 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def showImages(image, row):\n",
    "  \n",
    "  for _ in range(row):  \n",
    "  \n",
    "    idx = np.random.choice(batch_size, 6)     # 0 ~ 127 의 정수 중 6 개를 임의로 선택\n",
    "    images =image.numpy()[idx].transpose(0,2,3,1).clip(0,1)         # 선택된 index 에 해당하는 이미지를 가져옴\n",
    "    plt.figure(figsize = (15, 90))     # 세로 길이 15, 가로 길이 15 * 6 의 화면 생성\n",
    "    \n",
    "    for i in range(161, 167):    \n",
    "    \n",
    "      plt.subplot(i)\n",
    "      plt.imshow(images[i - 161])\n",
    "      plt.xticks([])\n",
    "      plt.yticks([])    \n",
    "    \n",
    "    plt.show()  \n",
    "\n",
    "for i, (image, labels) in enumerate(trainloader): \n",
    "  \n",
    "  showImages(image.squeeze(), 3)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1562084166859,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "QGj5qoFcn0FF",
    "outputId": "f81fbcc0-9cf5-4294-c173-4430c5fc2b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] # of train batch :  391\n",
      "[info] # of test batch :  100\n"
     ]
    }
   ],
   "source": [
    "print('[info] # of train batch : ' ,len(trainloader))\n",
    "print('[info] # of test batch : ', len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJ9lTPT9n1dM"
   },
   "outputs": [],
   "source": [
    "def train_network(net,optimizer,trainloader, epochs=5):\n",
    "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "      running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n",
    "      for i, data in enumerate(trainloader): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n",
    "          # get the inputs\n",
    "          inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n",
    "          inputs = inputs.to(device) # Pytorch에서 nn.Module 에 넣어 Backprop을 계산 하기 위해서는 gpu 연동을 이와 같이 해줘야 합니다.\n",
    "          labels = labels.to(device)\n",
    "          # zero the parameter gradients\n",
    "          optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다.\n",
    "          # forward + backward + optimize\n",
    "          outputs = net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n",
    "          loss = criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n",
    "          loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n",
    "          optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n",
    "\n",
    "          # print statistics\n",
    "          running_loss += loss.item()\n",
    "          if (i+1) % 100 == 0:    # print every 500 mini-batches\n",
    "              print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 100))\n",
    "              running_loss = 0.0\n",
    "\n",
    "  print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3F3ZmR6-oIH3"
   },
   "outputs": [],
   "source": [
    "def test(model,test_loader):\n",
    "  model.eval() # Eval Mode 왜 해야 할까요?  --> nn.Dropout BatchNorm 등의 Regularization 들이 test 모드로 들어가게 되기 때문입니다. \n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)  # 기존의 train function의 data 처리부분과 같습니다. \n",
    "    output = model(data) \n",
    "    pred = output.max(1, keepdim=True)[1] # get the index of the max \n",
    "    correct += pred.eq(target.view_as(pred)).sum().item() # 정답 데이터의 갯수를 반환합니다. \n",
    "\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print('\\nTest set:  Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "      correct, len(test_loader.dataset),\n",
    "      100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRrx1X1RN-_Z"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model): # 모델 파라미터 개수를 리턴하는 함수를 하나 만들어둡니다\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5gzkWcJoUxC"
   },
   "source": [
    "### MNIST에서 사용했던 MLP를 적용해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fwsRmXDoL8d"
   },
   "outputs": [],
   "source": [
    "class MNIST_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_Net, self).__init__()\n",
    "        \n",
    "        layer_list = [] # 이 리스트에 모든 Layer 를 순차적으로 append 해보겠습니다. \n",
    "        layer_list.append(nn.Linear(3*32*32,256)) #Layer 1 인풋 사이즈가 32*32로 변경되었기 때문에 바꿔줍니다!!\n",
    "        layer_list.append(nn.BatchNorm1d(256))#BatchNorm1\n",
    "        layer_list.append(nn.ReLU()) # Relu \n",
    "        layer_list.append(nn.Linear(256, 64)) # Layer 2\n",
    "        layer_list.append(nn.BatchNorm1d(64)) #BatchNorm1\n",
    "        layer_list.append(nn.ReLU())# Relu \n",
    "        layer_list.append(nn.Linear(64, 10)) # Layer 3\n",
    "        self.net  = nn.Sequential(*layer_list) # nn.Sequential 에 layer list를 넘겨 줍니다.\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,32*32*3) # 기존의 (128, 3, 32, 32)를 일자로 쭉 늘립니다.\n",
    "        x = self.net(x) # 넣은 순서대로 적용이 됩니다. \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXDe9e8goV4k"
   },
   "outputs": [],
   "source": [
    "mnist_net = MNIST_Net().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
    "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
    "optimizer = optim.Adam(mnist_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67385,
     "status": "ok",
     "timestamp": 1562084476513,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "ET-9RK75oX3w",
    "outputId": "5273c18f-d059-4826-8b26-d201145f68b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.029\n",
      "[1,   200] loss: 1.828\n",
      "[1,   300] loss: 1.750\n",
      "[2,   100] loss: 1.664\n",
      "[2,   200] loss: 1.638\n",
      "[2,   300] loss: 1.614\n",
      "[3,   100] loss: 1.580\n",
      "[3,   200] loss: 1.560\n",
      "[3,   300] loss: 1.555\n",
      "[4,   100] loss: 1.521\n",
      "[4,   200] loss: 1.503\n",
      "[4,   300] loss: 1.519\n",
      "[5,   100] loss: 1.483\n",
      "[5,   200] loss: 1.479\n",
      "[5,   300] loss: 1.481\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_network(mnist_net,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2964,
     "status": "ok",
     "timestamp": 1562084932438,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "wO5Aa_PCoYxL",
    "outputId": "580ea940-631d-409d-b4ef-a9c2c5286d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 4995/10000 (50%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(mnist_net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "58fk39tBo91s"
   },
   "source": [
    "### 심플한 CNN 모델을 만들어 봅시다.\n",
    "\n",
    "<구성>\n",
    "\n",
    "Layer 1 - input: 3 x 32 x 32, output: 64 x 32 x 32- ReLU + BatchNorm\n",
    "\n",
    "Layer 2 - input: 64 x 32 x 32, output: 128 x 16 x 16- ReLU + BatchNorm (Down Conv라고 부릅니다.)\n",
    "\n",
    "Layer 5 - Global Average Pooling (128 x 16 x 16 => 128 x 1 x 1)\n",
    "\n",
    "Layer 6 - input: 128 x 1 x 1, output 10 x 1 x 1 - ReLU + BatchNorm\n",
    "\n",
    "![대체 텍스트](https://cdn-images-1.medium.com/max/1600/1*D47ER7IArwPv69k3O_1nqQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uf3CEXKVpi_0"
   },
   "outputs": [],
   "source": [
    "class DiyCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DiyCNN, self).__init__()\n",
    "    layers = []\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=1, padding=3)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
    "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(64,?,?,?,?)] # Bx64x32x32 => Bx128x16x16\n",
    "    layers += [nn.BatchNorm2d(128)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(128, ?,?,?,?)] # Bx128x16x16 => Bx256x8x8\n",
    "    layers += [nn.BatchNorm2d(256)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(256, ?,?,?,?)] # Bx256x8x8 => Bx512x4x4\n",
    "    layers += [nn.BatchNorm2d(512)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.AdaptiveAvgPool2d(1)] # 512 x 1 \n",
    "    \n",
    "    layers += [nn.Conv2d(512, 10, 1, 1, 0)] # 128 x 10 x 1 x 1 \n",
    "    \n",
    "    self.main = nn.Sequential(*layers)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.main(x).squeeze(3).squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vorrzAVgq4Dg"
   },
   "source": [
    "##### 정답: 자신을 위해 가능한 확인하지 않고 진행해주세요~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6J1292kjL1tM"
   },
   "outputs": [],
   "source": [
    "class DiyCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DiyCNN, self).__init__()\n",
    "    layers = []\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
    "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(64, 128, 4, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(128)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(128, 256, 4, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(256)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(256, 512, 4, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(512)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
    "    \n",
    "    layers += [nn.Conv2d(512, 10, 1, 1, 0)] \n",
    "    \n",
    "    self.main = nn.Sequential(*layers)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.main(x).squeeze(3).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1562085000050,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "WZjiCK5vre9t",
    "outputId": "944dae20-2239-48ae-a0f2-a5898cc5c38f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] number of model parameter - 2762250\n"
     ]
    }
   ],
   "source": [
    "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
    "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
    "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n",
    "\n",
    "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 33197,
     "status": "error",
     "timestamp": 1562085034763,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "pE8APJgRrgfS",
    "outputId": "a339e363-8375-49ee-9370-1cca1bba8824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.701\n",
      "[1,   200] loss: 1.459\n",
      "[1,   300] loss: 1.347\n",
      "[2,   100] loss: 1.176\n",
      "[2,   200] loss: 1.130\n",
      "[2,   300] loss: 1.071\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-bcd624271182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-d1f2d205b048>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, optimizer, trainloader, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;31m# running loss를 저장하기 위한 변수입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;31m# DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(cifar_net,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3559,
     "status": "ok",
     "timestamp": 1562085042133,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "OcX_blYBrhef",
    "outputId": "b45f64e3-8ddc-4510-d878-b42385e0914d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 6529/10000 (65%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cifar_net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMBJ5Vla_Wkd"
   },
   "source": [
    "### Average Pooling 대신 Linear Layer로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YXvUnMAys_0"
   },
   "outputs": [],
   "source": [
    "class DiyCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DiyCNN, self).__init__()\n",
    "    layers = []\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
    "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(64, 128, 4, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(128)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(128, 256, 4, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(256)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(256, 512, 4, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(512)]\n",
    "    layers += [nn.ReLU()] # 128 x 512*4 -> 128 x 512\n",
    "    \n",
    "    classifier = []\n",
    "    classifier += [nn.Linear(512*4,512)]\n",
    "    \n",
    "    classifier += [nn.Linear(512,10)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    self.main = nn.Sequential(*layers)\n",
    "    self.classifier = nn.Sequential(*classifier)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.main(x) # 128 x 512 x 2 x2\n",
    "    out = out.view(out.size(0),-1)\n",
    "    out = self.classifier(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1562085064259,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "JbVONDRyz1RK",
    "outputId": "afad6533-654f-47b4-e876-4b24f0432eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] number of model parameter - 3811338\n"
     ]
    }
   ],
   "source": [
    "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
    "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
    "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n",
    "\n",
    "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32383,
     "status": "error",
     "timestamp": 1562085098969,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "J0OFFnddz4CS",
    "outputId": "310b43d6-5c43-4a64-9407-e5cf13591c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.782\n",
      "[1,   200] loss: 1.502\n",
      "[1,   300] loss: 1.352\n",
      "[2,   100] loss: 1.184\n",
      "[2,   200] loss: 1.139\n",
      "[2,   300] loss: 1.089\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-bcd624271182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-d1f2d205b048>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, optimizer, trainloader, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m           \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m           \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 500 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m               print('[%d, %5d] loss: %.3f' %\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(cifar_net,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3195,
     "status": "ok",
     "timestamp": 1562085103645,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "Q27tKqAuz4tM",
    "outputId": "5b95f575-e46b-45a2-ec02-63c4d68e0b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 6774/10000 (68%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cifar_net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-UID3Msy1L4"
   },
   "source": [
    "### 데이터 intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyzEg2_y08-C"
   },
   "outputs": [],
   "source": [
    "class DiyCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DiyCNN, self).__init__()\n",
    "    layers = []\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
    "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(128)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(256)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(512)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
    "    \n",
    "    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
    "    \n",
    "    self.main = nn.Sequential(*layers)\n",
    "    self._reset_params() # 실제로 initialize하는 부분\n",
    "  def _reset_params(self): # Initialization 을 정의하는 부분\n",
    "    for i,layer in enumerate(self.main):\n",
    "      if type(layer) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(layer.weight.data)\n",
    "  def forward(self, x):\n",
    "    return self.main(x).squeeze(3).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TbFjh1PL1cJg"
   },
   "outputs": [],
   "source": [
    "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
    "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
    "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "tqshiap61eT8",
    "outputId": "ca87a989-7c63-485c-dc16-21868491a995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.728\n",
      "[1,   200] loss: 1.484\n",
      "[1,   300] loss: 1.384\n",
      "[2,   100] loss: 1.225\n",
      "[2,   200] loss: 1.168\n",
      "[2,   300] loss: 1.131\n",
      "[3,   100] loss: 1.045\n",
      "[3,   200] loss: 1.022\n",
      "[3,   300] loss: 1.006\n",
      "[4,   100] loss: 0.934\n",
      "[4,   200] loss: 0.920\n",
      "[4,   300] loss: 0.909\n",
      "[5,   100] loss: 0.862\n",
      "[5,   200] loss: 0.851\n",
      "[5,   300] loss: 0.832\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_network(cifar_net,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "9y5LmO0S1hHs",
    "outputId": "4330b476-bbbe-4278-efcd-2519dbfc0bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 7350/10000 (74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cifar_net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACfwmSHo1pUW"
   },
   "source": [
    "weight intialization은 효과가 있었나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1gj-ahZvtOK"
   },
   "source": [
    "### 데이터 전처리를 한번 없애면 성능은 어떻게 변할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2608,
     "status": "ok",
     "timestamp": 1562085166062,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "XQqpAoljvf2t",
    "outputId": "77b9d871-6663-4bed-ec03-7cd3f383302f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_train = transforms.Compose([\n",
    "    ????\n",
    "    transforms.ToTensor(),\n",
    "     \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "   # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
    "])\n",
    "\n",
    "# 데이터 로딩\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ha_j7qGdvztc"
   },
   "outputs": [],
   "source": [
    "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
    "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
    "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30964,
     "status": "error",
     "timestamp": 1562085204341,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "PYqBc07Qv2rl",
    "outputId": "6bec49f5-d18c-4bf8-937d-da86aa0539f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.785\n",
      "[1,   200] loss: 1.511\n",
      "[1,   300] loss: 1.397\n",
      "[2,   100] loss: 1.204\n",
      "[2,   200] loss: 1.146\n",
      "[2,   300] loss: 1.090\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-bcd624271182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-d1f2d205b048>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(net, optimizer, trainloader, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;31m# running loss를 저장하기 위한 변수입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m           \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;31m# DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrebuild_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;34m'''Receive a handle over a local connection.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAF_UNIX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mrecvfds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mDupFd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mbytes_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecvmsg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMSG_SPACE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mancdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_network(cifar_net,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2823,
     "status": "ok",
     "timestamp": 1562085208944,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "dRNdaQCHv3mc",
    "outputId": "99baf59b-1f3d-4b6d-d159-c62057ab6d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 2252/10000 (23%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cifar_net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-Y3AkxQ1xe0"
   },
   "source": [
    "Q) 왜 성능이 낮아졌을까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j90-Gd4lwyV2"
   },
   "source": [
    "### 데이터 shuffling 의 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Zcon8zppww3H",
    "outputId": "08e12b27-b434-45e7-8f2e-a374ace7c06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n",
    "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
    "])\n",
    "\n",
    "# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n",
    "\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
    "])\n",
    "\n",
    "# 데이터 로딩\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=????, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pj8oSDzAw68t"
   },
   "outputs": [],
   "source": [
    "cifar_net = DiyCNN().to(device) # 생성한 뉴럴넷 Instance를 생성하고 빠른 학습을 위해 cuda 에 올립니다. \n",
    "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
    "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "J-yaC6mkw9g3",
    "outputId": "a3a40899-7941-4156-ed2b-5eed01d04bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.739\n",
      "[1,   200] loss: 1.488\n",
      "[1,   300] loss: 1.375\n",
      "[2,   100] loss: 1.219\n",
      "[2,   200] loss: 1.155\n",
      "[2,   300] loss: 1.113\n",
      "[3,   100] loss: 1.037\n",
      "[3,   200] loss: 1.013\n",
      "[3,   300] loss: 0.986\n",
      "[4,   100] loss: 0.927\n",
      "[4,   200] loss: 0.913\n",
      "[4,   300] loss: 0.895\n",
      "[5,   100] loss: 0.850\n",
      "[5,   200] loss: 0.834\n",
      "[5,   300] loss: 0.831\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_network(cifar_net,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "4Xgf-jTdw-NY",
    "outputId": "6180ce5f-c6d4-4466-a0e1-de34b95643e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 7224/10000 (72%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cifar_net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbjVKfzg13q6"
   },
   "source": [
    "Q) Shuffling 을 제거 했더니 성능이 어떻게 변하나요?  shuffling 은 왜 중요할까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o19_PEjYxeBM"
   },
   "source": [
    "### 다시 원래 옵션으로 되돌립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2742,
     "status": "ok",
     "timestamp": 1562085980824,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "XclAWYKSxdH1",
    "outputId": "f7ed68cc-7563-4735-dc23-86c6cb33af47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), # 4만큼의 padding을 부여한 후, 32x32로 random cropping\n",
    "    transforms.RandomHorizontalFlip(), # 0.5의 확률로 이미지 좌우 반전하여 넣어줌\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
    "])\n",
    "\n",
    "# 랜덤 cropping을 하고, 이미지 좌우반전을 해주는 이유 : ???\n",
    "\n",
    "# 데이터 전처리를 위한 코드\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), # cifar10(0~1)의 r,g,b 채널 별 평균 및 분산으로 normalization => N(0,1)의 정규분포를 따르도록 만들어준 후 input으로 넣어줍니다.\n",
    "])\n",
    "\n",
    "# 데이터 로딩\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xk0lINI_JMdX"
   },
   "outputs": [],
   "source": [
    "class DiyCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(DiyCNN, self).__init__()\n",
    "    layers = []\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)] # 첫 conv는 보통 receptive field를 최대한 넓혀준 후 feature를 뽑아줍니다.\n",
    "    layers += [nn.BatchNorm2d(64)] # 앞선 MLP 시간과 달리 spatial resolution이 살아있기 때문에, batchnorm 2d를 사용해 줍니다.\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(64, 128, 3, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(128)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(128, 256, 3, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(256)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.Conv2d(256, 512, 3, 2, 1)]\n",
    "    layers += [nn.BatchNorm2d(512)]\n",
    "    layers += [nn.ReLU()]\n",
    "    \n",
    "    layers += [nn.AdaptiveAvgPool2d(1)]\n",
    "    \n",
    "    layers += [nn.Conv2d(512, 10, 1, 1, 0)]\n",
    "    \n",
    "    self.main = nn.Sequential(*layers)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.main(x).squeeze(3).squeeze(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yODwdqQEHIGz"
   },
   "source": [
    "### Learning rate scheduler를 도입합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt5HHvczIZIQ"
   },
   "outputs": [],
   "source": [
    "def train_network2(net,optimizer,trainloader, ??, epochs=5):\n",
    "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "      running_loss = 0.0 # running loss를 저장하기 위한 변수입니다. \n",
    "      for i, data in enumerate(trainloader): # 한 Epoch 만큼 돕니다. 매 iteration 마다 정해진 Batch size 만큼 데이터를 뱉습니다. \n",
    "          # get the inputs\n",
    "          inputs, labels = data # DataLoader iterator의 반환 값은 input_data 와 labels의 튜플 형식입니다. \n",
    "          inputs = inputs.to(device) # Pytorch에서 nn.Module 에 넣어 Backprop을 계산 하기 위해서는 gpu 연동을 이와 같이 해줘야 합니다.\n",
    "          labels = labels.to(device)\n",
    "          # zero the parameter gradients\n",
    "          optimizer.zero_grad()    #  현재 기존의 backprop을 계산하기 위해서 저장했던 activation buffer 를 비웁니다.\n",
    "          # forward + backward + optimize\n",
    "          outputs = net(inputs) # input 을 넣은 위 network 로 부터 output 을 얻어냅니다. \n",
    "          loss = criterion(outputs, labels) # loss fucntion에 주어진 target과 output 의 score를 계산하여 반환합니다. \n",
    "          loss.backward() # * Scalar Loss value를 Backward() 해주게 되면 주어진 loss값을 바탕으로 backpropagation이 진행됩니다. \n",
    "          optimizer.step() # 계산된 Backprop 을 바탕으로 optimizer가 gradient descenting 을 수행합니다. \n",
    "\n",
    "          # print statistics\n",
    "          running_loss += loss.item()\n",
    "          if (i+1) % 100 == 0:    # print every 500 mini-batches\n",
    "              print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 100))\n",
    "              running_loss = 0.0\n",
    "      ??.step() \n",
    "  print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6OYIUWkQHHgQ",
    "outputId": "4abf5bdb-118e-4f71-e4d8-a8c8c395e83f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] number of model parameter - 1558026\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "scheduler = MultiStepLR(optimizer, milestones=[??,??], gamma=??)# mile stone에 해당하는 에폭마다 learning rate을 gamma만큼 줄입니다.\n",
    "cifar_net = DiyCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(cifar_net.parameters(), lr=0.001) # 초반 learning rate이 0.1입니다\n",
    "\n",
    "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "P90jBCr9I1Zx",
    "outputId": "220e9ed6-6656-4a50-e5e2-f5eea8756f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.739\n",
      "[1,   200] loss: 1.464\n",
      "[1,   300] loss: 1.348\n",
      "[2,   100] loss: 1.214\n",
      "[2,   200] loss: 1.144\n",
      "[2,   300] loss: 1.133\n",
      "[3,   100] loss: 1.031\n",
      "[3,   200] loss: 1.030\n",
      "[3,   300] loss: 0.987\n",
      "[4,   100] loss: 0.951\n",
      "[4,   200] loss: 0.918\n",
      "[4,   300] loss: 0.902\n",
      "[5,   100] loss: 0.844\n",
      "[5,   200] loss: 0.835\n",
      "[5,   300] loss: 0.840\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_network2(cifar_net,optimizer,trainloader, ??, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "C1gRZluHJq8V",
    "outputId": "0d60833a-7d1a-4441-fbfa-5dc12a77da4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 7287/10000 (73%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cifar_net,testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6umQIX-Urwyn"
   },
   "source": [
    "### Pre-trained 모형 가지고 와서 성능 확인하기 (Transfer Learning 관점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23920,
     "status": "ok",
     "timestamp": 1562085636277,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "JecQ-Fkmxjk1",
    "outputId": "57d274a9-4d50-4a54-9f73-63c5b241f7e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/checkpoints/vgg19_bn-c79401a0.pth\n",
      "\n",
      "  0%|          | 0/574769405 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 2883584/574769405 [00:00<00:20, 28312455.30it/s]\u001b[A\n",
      "  1%|          | 5963776/574769405 [00:00<00:19, 28896240.99it/s]\u001b[A\n",
      "  2%|▏         | 8978432/574769405 [00:00<00:19, 29252417.97it/s]\u001b[A\n",
      "  2%|▏         | 11927552/574769405 [00:00<00:19, 29288867.80it/s]\u001b[A\n",
      "  3%|▎         | 14901248/574769405 [00:00<00:19, 29420047.26it/s]\u001b[A\n",
      "  3%|▎         | 17825792/574769405 [00:00<00:18, 29341617.88it/s]\u001b[A\n",
      "  4%|▎         | 20774912/574769405 [00:00<00:18, 29289127.71it/s]\u001b[A\n",
      "  4%|▍         | 23814144/574769405 [00:00<00:18, 29609239.51it/s]\u001b[A\n",
      "  5%|▍         | 26738688/574769405 [00:00<00:18, 29472603.45it/s]\u001b[A\n",
      "  5%|▌         | 29605888/574769405 [00:01<00:18, 28891925.13it/s]\u001b[A\n",
      "  6%|▌         | 32833536/574769405 [00:01<00:18, 29785278.51it/s]\u001b[A\n",
      "  6%|▌         | 35913728/574769405 [00:01<00:18, 29932548.74it/s]\u001b[A\n",
      "  7%|▋         | 38928384/574769405 [00:01<00:17, 29920017.13it/s]\u001b[A\n",
      "  7%|▋         | 41902080/574769405 [00:01<00:17, 29831357.68it/s]\u001b[A\n",
      "  8%|▊         | 44875776/574769405 [00:01<00:17, 29578400.89it/s]\u001b[A\n",
      "  8%|▊         | 47824896/574769405 [00:01<00:18, 29074263.00it/s]\u001b[A\n",
      "  9%|▉         | 50790400/574769405 [00:01<00:17, 29234759.57it/s]\u001b[A\n",
      "  9%|▉         | 53870592/574769405 [00:01<00:17, 29590850.91it/s]\u001b[A\n",
      " 10%|▉         | 56885248/574769405 [00:01<00:17, 29701352.31it/s]\u001b[A\n",
      " 10%|█         | 59858944/574769405 [00:02<00:18, 27371352.14it/s]\u001b[A\n",
      " 11%|█         | 62914560/574769405 [00:02<00:18, 28105095.59it/s]\u001b[A\n",
      " 11%|█▏        | 65970176/574769405 [00:02<00:17, 28797009.51it/s]\u001b[A\n",
      " 12%|█▏        | 68878336/574769405 [00:02<00:17, 28517623.23it/s]\u001b[A\n",
      " 13%|█▎        | 71892992/574769405 [00:02<00:17, 28848815.77it/s]\u001b[A\n",
      " 13%|█▎        | 74792960/574769405 [00:02<00:17, 28578685.21it/s]\u001b[A\n",
      " 14%|█▎        | 77791232/574769405 [00:02<00:17, 28964769.77it/s]\u001b[A\n",
      " 14%|█▍        | 80814080/574769405 [00:02<00:16, 29330538.69it/s]\u001b[A\n",
      " 15%|█▍        | 83836928/574769405 [00:02<00:16, 29587689.01it/s]\u001b[A\n",
      " 15%|█▌        | 86835200/574769405 [00:02<00:16, 29650857.51it/s]\u001b[A\n",
      " 16%|█▌        | 89849856/574769405 [00:03<00:16, 29662823.63it/s]\u001b[A\n",
      " 16%|█▌        | 92864512/574769405 [00:03<00:16, 29762115.79it/s]\u001b[A\n",
      " 17%|█▋        | 95944704/574769405 [00:03<00:15, 29945502.23it/s]\u001b[A\n",
      " 17%|█▋        | 98959360/574769405 [00:03<00:15, 29874154.03it/s]\u001b[A\n",
      " 18%|█▊        | 101949440/574769405 [00:03<00:15, 29807641.54it/s]\u001b[A\n",
      " 18%|█▊        | 104931328/574769405 [00:03<00:15, 29569469.85it/s]\u001b[A\n",
      " 19%|█▉        | 107896832/574769405 [00:03<00:16, 28725798.10it/s]\u001b[A\n",
      " 19%|█▉        | 110952448/574769405 [00:03<00:15, 29146156.43it/s]\u001b[A\n",
      " 20%|█▉        | 113967104/574769405 [00:03<00:15, 29317545.99it/s]\u001b[A\n",
      " 20%|██        | 116981760/574769405 [00:03<00:15, 29544998.60it/s]\u001b[A\n",
      " 21%|██        | 120061952/574769405 [00:04<00:15, 29789042.03it/s]\u001b[A\n",
      " 21%|██▏       | 123043840/574769405 [00:04<00:15, 29686196.18it/s]\u001b[A\n",
      " 22%|██▏       | 126091264/574769405 [00:04<00:15, 29775873.80it/s]\u001b[A\n",
      " 22%|██▏       | 129171456/574769405 [00:04<00:14, 29959085.01it/s]\u001b[A\n",
      " 23%|██▎       | 132186112/574769405 [00:04<00:14, 29921165.30it/s]\u001b[A\n",
      " 24%|██▎       | 135200768/574769405 [00:04<00:14, 29952506.65it/s]\u001b[A\n",
      " 24%|██▍       | 138199040/574769405 [00:04<00:14, 29795313.10it/s]\u001b[A\n",
      " 25%|██▍       | 141230080/574769405 [00:04<00:14, 29773464.74it/s]\u001b[A\n",
      " 25%|██▌       | 144310272/574769405 [00:04<00:14, 29982030.58it/s]\u001b[A\n",
      " 26%|██▌       | 147390464/574769405 [00:04<00:14, 30161195.05it/s]\u001b[A\n",
      " 26%|██▌       | 150413312/574769405 [00:05<00:14, 29799469.86it/s]\u001b[A\n",
      " 27%|██▋       | 153485312/574769405 [00:05<00:14, 29929358.13it/s]\u001b[A\n",
      " 27%|██▋       | 156499968/574769405 [00:05<00:13, 29979093.17it/s]\u001b[A\n",
      " 28%|██▊       | 159506432/574769405 [00:05<00:14, 29511864.87it/s]\u001b[A\n",
      " 28%|██▊       | 162463744/574769405 [00:05<00:14, 29331895.45it/s]\u001b[A\n",
      " 29%|██▉       | 165404672/574769405 [00:05<00:13, 29347659.26it/s]\u001b[A\n",
      " 29%|██▉       | 168427520/574769405 [00:05<00:13, 29562964.70it/s]\u001b[A\n",
      " 30%|██▉       | 171507712/574769405 [00:05<00:13, 29762443.98it/s]\u001b[A\n",
      " 30%|███       | 174489600/574769405 [00:05<00:13, 29661326.31it/s]\u001b[A\n",
      " 31%|███       | 177602560/574769405 [00:06<00:13, 29971987.67it/s]\u001b[A\n",
      " 31%|███▏      | 180674560/574769405 [00:06<00:13, 30191358.32it/s]\u001b[A\n",
      " 32%|███▏      | 183697408/574769405 [00:06<00:13, 30027091.39it/s]\u001b[A\n",
      " 32%|███▏      | 186777600/574769405 [00:06<00:12, 30115737.30it/s]\u001b[A\n",
      " 33%|███▎      | 189792256/574769405 [00:06<00:12, 29818553.14it/s]\u001b[A\n",
      " 34%|███▎      | 192782336/574769405 [00:06<00:12, 29576622.80it/s]\u001b[A\n",
      " 34%|███▍      | 195747840/574769405 [00:06<00:12, 29338148.56it/s]\u001b[A\n",
      " 35%|███▍      | 198770688/574769405 [00:06<00:12, 29513462.67it/s]\u001b[A\n",
      " 35%|███▌      | 201728000/574769405 [00:06<00:12, 29261338.84it/s]\u001b[A\n",
      " 36%|███▌      | 204800000/574769405 [00:06<00:12, 29566833.44it/s]\u001b[A\n",
      " 36%|███▌      | 207806464/574769405 [00:07<00:12, 29712511.81it/s]\u001b[A\n",
      " 37%|███▋      | 210780160/574769405 [00:07<00:12, 29631712.00it/s]\u001b[A\n",
      " 37%|███▋      | 213745664/574769405 [00:07<00:12, 29598999.20it/s]\u001b[A\n",
      " 38%|███▊      | 216711168/574769405 [00:07<00:12, 29480205.30it/s]\u001b[A\n",
      " 38%|███▊      | 219742208/574769405 [00:07<00:12, 29574227.72it/s]\u001b[A\n",
      " 39%|███▊      | 222707712/574769405 [00:07<00:11, 29579449.85it/s]\u001b[A\n",
      " 39%|███▉      | 225673216/574769405 [00:07<00:12, 29011955.29it/s]\u001b[A\n",
      " 40%|███▉      | 228720640/574769405 [00:07<00:11, 29360948.76it/s]\u001b[A\n",
      " 40%|████      | 231661568/574769405 [00:08<00:32, 10684173.35it/s]\u001b[A\n",
      " 41%|████      | 233848832/574769405 [00:08<00:35, 9710153.04it/s] \u001b[A\n",
      " 41%|████      | 236847104/574769405 [00:08<00:27, 12154935.18it/s]\u001b[A\n",
      " 42%|████▏     | 239927296/574769405 [00:08<00:22, 14824891.94it/s]\u001b[A\n",
      " 42%|████▏     | 243023872/574769405 [00:09<00:18, 17572114.08it/s]\u001b[A\n",
      " 43%|████▎     | 246087680/574769405 [00:09<00:16, 20077704.84it/s]\u001b[A\n",
      " 43%|████▎     | 249102336/574769405 [00:09<00:14, 22307926.23it/s]\u001b[A\n",
      " 44%|████▍     | 252051456/574769405 [00:09<00:13, 24054769.30it/s]\u001b[A\n",
      " 44%|████▍     | 255000576/574769405 [00:09<00:12, 25427976.85it/s]\u001b[A\n",
      " 45%|████▍     | 257949696/574769405 [00:09<00:11, 26403925.40it/s]\u001b[A\n",
      " 45%|████▌     | 260898816/574769405 [00:09<00:11, 27190868.77it/s]\u001b[A\n",
      " 46%|████▌     | 263847936/574769405 [00:09<00:11, 27798280.65it/s]\u001b[A\n",
      " 46%|████▋     | 266862592/574769405 [00:09<00:10, 28402119.44it/s]\u001b[A\n",
      " 47%|████▋     | 269811712/574769405 [00:09<00:10, 28666238.45it/s]\u001b[A\n",
      " 47%|████▋     | 272744448/574769405 [00:10<00:10, 28391790.03it/s]\u001b[A\n",
      " 48%|████▊     | 275636224/574769405 [00:10<00:10, 28378986.14it/s]\u001b[A\n",
      " 48%|████▊     | 278511616/574769405 [00:10<00:10, 28171322.07it/s]\u001b[A\n",
      " 49%|████▉     | 281477120/574769405 [00:10<00:10, 28525842.92it/s]\u001b[A\n",
      " 50%|████▉     | 284516352/574769405 [00:10<00:09, 29057176.96it/s]\u001b[A\n",
      " 50%|█████     | 287506432/574769405 [00:10<00:09, 29274797.02it/s]\u001b[A\n",
      " 51%|█████     | 290455552/574769405 [00:10<00:09, 29288415.29it/s]\u001b[A\n",
      " 51%|█████     | 293404672/574769405 [00:10<00:09, 29197272.00it/s]\u001b[A\n",
      " 52%|█████▏    | 296484864/574769405 [00:10<00:09, 29531113.55it/s]\u001b[A\n",
      " 52%|█████▏    | 299499520/574769405 [00:10<00:09, 29701417.31it/s]\u001b[A\n",
      " 53%|█████▎    | 302473216/574769405 [00:11<00:09, 29308315.18it/s]\u001b[A\n",
      " 53%|█████▎    | 305528832/574769405 [00:11<00:09, 29564633.21it/s]\u001b[A\n",
      " 54%|█████▎    | 308609024/574769405 [00:11<00:08, 29805919.99it/s]\u001b[A\n",
      " 54%|█████▍    | 311599104/574769405 [00:11<00:09, 28020534.64it/s]\u001b[A\n",
      " 55%|█████▍    | 314638336/574769405 [00:11<00:09, 28657116.85it/s]\u001b[A\n",
      " 55%|█████▌    | 317530112/574769405 [00:11<00:08, 28709113.67it/s]\u001b[A\n",
      " 56%|█████▌    | 320471040/574769405 [00:11<00:08, 28781733.10it/s]\u001b[A\n",
      " 56%|█████▋    | 323362816/574769405 [00:11<00:08, 28719206.16it/s]\u001b[A\n",
      " 57%|█████▋    | 326369280/574769405 [00:11<00:08, 29056882.84it/s]\u001b[A\n",
      " 57%|█████▋    | 329285632/574769405 [00:11<00:08, 28200510.73it/s]\u001b[A\n",
      " 58%|█████▊    | 332120064/574769405 [00:12<00:08, 27465861.97it/s]\u001b[A\n",
      " 58%|█████▊    | 335151104/574769405 [00:12<00:08, 28118951.30it/s]\u001b[A\n",
      " 59%|█████▉    | 338100224/574769405 [00:12<00:08, 28430026.17it/s]\u001b[A\n",
      " 59%|█████▉    | 341049344/574769405 [00:12<00:08, 28699850.00it/s]\u001b[A\n",
      " 60%|█████▉    | 343998464/574769405 [00:12<00:08, 28791365.15it/s]\u001b[A\n",
      " 60%|██████    | 346890240/574769405 [00:12<00:07, 28722041.26it/s]\u001b[A\n",
      " 61%|██████    | 349921280/574769405 [00:12<00:07, 29179914.30it/s]\u001b[A\n",
      " 61%|██████▏   | 352911360/574769405 [00:12<00:07, 29358061.11it/s]\u001b[A\n",
      " 62%|██████▏   | 355926016/574769405 [00:12<00:07, 29415029.95it/s]\u001b[A\n",
      " 62%|██████▏   | 358940672/574769405 [00:12<00:07, 29539472.29it/s]\u001b[A\n",
      " 63%|██████▎   | 361955328/574769405 [00:13<00:07, 29686997.06it/s]\u001b[A\n",
      " 63%|██████▎   | 364969984/574769405 [00:13<00:07, 29768504.04it/s]\u001b[A\n",
      " 64%|██████▍   | 367984640/574769405 [00:13<00:06, 29828253.14it/s]\u001b[A\n",
      " 65%|██████▍   | 370974720/574769405 [00:13<00:06, 29808696.59it/s]\u001b[A\n",
      " 65%|██████▌   | 374013952/574769405 [00:13<00:06, 29890504.56it/s]\u001b[A\n",
      " 66%|██████▌   | 377004032/574769405 [00:13<00:06, 29870895.12it/s]\u001b[A\n",
      " 66%|██████▌   | 380043264/574769405 [00:13<00:06, 29915646.55it/s]\u001b[A\n",
      " 67%|██████▋   | 383057920/574769405 [00:13<00:06, 29892390.82it/s]\u001b[A\n",
      " 67%|██████▋   | 386138112/574769405 [00:13<00:06, 30006496.33it/s]\u001b[A\n",
      " 68%|██████▊   | 389144576/574769405 [00:14<00:06, 29955967.00it/s]\u001b[A\n",
      " 68%|██████▊   | 392167424/574769405 [00:14<00:06, 29919088.41it/s]\u001b[A\n",
      " 69%|██████▉   | 395182080/574769405 [00:14<00:05, 29960715.68it/s]\u001b[A\n",
      " 69%|██████▉   | 398196736/574769405 [00:14<00:05, 29921921.50it/s]\u001b[A\n",
      " 70%|██████▉   | 401276928/574769405 [00:14<00:05, 30088664.98it/s]\u001b[A\n",
      " 70%|███████   | 404291584/574769405 [00:14<00:05, 29988441.28it/s]\u001b[A\n",
      " 71%|███████   | 407306240/574769405 [00:14<00:05, 30030831.65it/s]\u001b[A\n",
      " 71%|███████▏  | 410451968/574769405 [00:14<00:05, 30325075.32it/s]\u001b[A\n",
      " 72%|███████▏  | 413491200/574769405 [00:14<00:05, 30234201.72it/s]\u001b[A\n",
      " 72%|███████▏  | 416546816/574769405 [00:14<00:05, 30287013.29it/s]\u001b[A\n",
      " 73%|███████▎  | 419577856/574769405 [00:15<00:05, 30124381.43it/s]\u001b[A\n",
      " 74%|███████▎  | 422592512/574769405 [00:15<00:05, 29955801.01it/s]\u001b[A\n",
      " 74%|███████▍  | 425656320/574769405 [00:15<00:04, 30071452.85it/s]\u001b[A\n",
      " 75%|███████▍  | 428670976/574769405 [00:15<00:04, 30036071.55it/s]\u001b[A\n",
      " 75%|███████▌  | 431677440/574769405 [00:15<00:05, 27543572.19it/s]\u001b[A\n",
      " 76%|███████▌  | 435355648/574769405 [00:15<00:04, 29782974.37it/s]\u001b[A\n",
      " 76%|███████▋  | 438501376/574769405 [00:15<00:04, 30141138.66it/s]\u001b[A\n",
      " 77%|███████▋  | 441573376/574769405 [00:15<00:04, 30136159.61it/s]\u001b[A\n",
      " 77%|███████▋  | 444628992/574769405 [00:15<00:04, 30000186.10it/s]\u001b[A\n",
      " 78%|███████▊  | 447660032/574769405 [00:15<00:04, 29645016.26it/s]\u001b[A\n",
      " 78%|███████▊  | 450650112/574769405 [00:16<00:04, 29391307.94it/s]\u001b[A\n",
      " 79%|███████▉  | 453607424/574769405 [00:16<00:04, 29194772.88it/s]\u001b[A\n",
      " 79%|███████▉  | 456720384/574769405 [00:16<00:03, 29745876.10it/s]\u001b[A\n",
      " 80%|███████▉  | 459710464/574769405 [00:16<00:03, 29499343.44it/s]\u001b[A\n",
      " 80%|████████  | 462675968/574769405 [00:16<00:03, 29216572.56it/s]\u001b[A\n",
      " 81%|████████  | 465608704/574769405 [00:16<00:03, 29034427.19it/s]\u001b[A\n",
      " 82%|████████▏ | 468516864/574769405 [00:16<00:03, 28140907.07it/s]\u001b[A\n",
      " 82%|████████▏ | 471343104/574769405 [00:16<00:03, 27621021.90it/s]\u001b[A\n",
      " 83%|████████▎ | 474349568/574769405 [00:16<00:03, 28239845.35it/s]\u001b[A\n",
      " 83%|████████▎ | 477495296/574769405 [00:16<00:03, 28997503.94it/s]\u001b[A\n",
      " 84%|████████▎ | 480444416/574769405 [00:17<00:03, 29108775.67it/s]\u001b[A\n",
      " 84%|████████▍ | 483524608/574769405 [00:17<00:03, 29491861.50it/s]\u001b[A\n",
      " 85%|████████▍ | 486637568/574769405 [00:17<00:02, 29953237.86it/s]\u001b[A\n",
      " 85%|████████▌ | 489644032/574769405 [00:17<00:02, 29813938.00it/s]\u001b[A\n",
      " 86%|████████▌ | 492691456/574769405 [00:17<00:02, 30007956.11it/s]\u001b[A\n",
      " 86%|████████▌ | 495697920/574769405 [00:17<00:02, 29820414.60it/s]\u001b[A\n",
      " 87%|████████▋ | 498688000/574769405 [00:17<00:02, 29837208.36it/s]\u001b[A\n",
      " 87%|████████▋ | 501743616/574769405 [00:17<00:02, 30029828.39it/s]\u001b[A\n",
      " 88%|████████▊ | 504758272/574769405 [00:17<00:02, 29964559.31it/s]\u001b[A\n",
      " 88%|████████▊ | 507805696/574769405 [00:18<00:02, 30115460.02it/s]\u001b[A\n",
      " 89%|████████▉ | 510820352/574769405 [00:18<00:02, 29928698.61it/s]\u001b[A\n",
      " 89%|████████▉ | 513867776/574769405 [00:18<00:02, 29969893.77it/s]\u001b[A\n",
      " 90%|████████▉ | 516882432/574769405 [00:18<00:01, 29967163.17it/s]\u001b[A\n",
      " 90%|█████████ | 519897088/574769405 [00:18<00:01, 29922046.17it/s]\u001b[A\n",
      " 91%|█████████ | 522911744/574769405 [00:18<00:01, 29976750.09it/s]\u001b[A\n",
      " 91%|█████████▏| 525910016/574769405 [00:18<00:01, 29947901.05it/s]\u001b[A\n",
      " 92%|█████████▏| 528941056/574769405 [00:18<00:01, 29910346.13it/s]\u001b[A\n",
      " 93%|█████████▎| 532013056/574769405 [00:18<00:01, 30146215.62it/s]\u001b[A\n",
      " 93%|█████████▎| 535035904/574769405 [00:18<00:01, 30010879.50it/s]\u001b[A\n",
      " 94%|█████████▎| 538116096/574769405 [00:19<00:01, 30086106.41it/s]\u001b[A\n",
      " 94%|█████████▍| 541196288/574769405 [00:19<00:01, 30161449.86it/s]\u001b[A\n",
      " 95%|█████████▍| 544219136/574769405 [00:19<00:01, 29880380.06it/s]\u001b[A\n",
      " 95%|█████████▌| 547258368/574769405 [00:19<00:00, 30029730.86it/s]\u001b[A\n",
      " 96%|█████████▌| 550264832/574769405 [00:19<00:00, 29937910.08it/s]\u001b[A\n",
      " 96%|█████████▋| 553320448/574769405 [00:19<00:00, 29973431.19it/s]\u001b[A\n",
      " 97%|█████████▋| 556335104/574769405 [00:19<00:00, 29978762.34it/s]\u001b[A\n",
      " 97%|█████████▋| 559333376/574769405 [00:19<00:00, 29709430.06it/s]\u001b[A\n",
      " 98%|█████████▊| 562307072/574769405 [00:19<00:00, 29578384.90it/s]\u001b[A\n",
      " 98%|█████████▊| 565313536/574769405 [00:19<00:00, 29674998.12it/s]\u001b[A\n",
      " 99%|█████████▉| 568328192/574769405 [00:20<00:00, 29713669.93it/s]\u001b[A\n",
      " 99%|█████████▉| 571301888/574769405 [00:20<00:00, 29456288.07it/s]\u001b[A\n",
      "100%|█████████▉| 574291968/574769405 [00:20<00:00, 29583523.96it/s]\u001b[A\n",
      "100%|██████████| 574769405/574769405 [00:20<00:00, 28390395.99it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "vgg_model = models.vgg19_bn(pretrained=True).to(device) # 기존에 만들어진 vgg network 을 이미지넷 데이터에 트레이닝해둔 파라미터를 그대로 받아옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1307,
     "status": "ok",
     "timestamp": 1562085640589,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "hzItxH6lJRUs",
    "outputId": "81a52882-eeb0-4b80-cbc0-9764ac4a87bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofQJ3YcwFqvi"
   },
   "outputs": [],
   "source": [
    "class DiyCNN(nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        super(DiyCNN, self).__init__()\n",
    "        self.pre_trained = nn.Sequential(   \n",
    "            *list(vgg_model.features.children()) # vgg_model의 features에 있는 모든 레이어 (children)들을 차례로 가져와서 붙여줍니다.\n",
    "        ) # 128 x 512 x 1 x 1\n",
    "        self.mlp = nn.Sequential(  # 기존에는 이미지넷에 학습되어있기 때문에, 이를 cifar-10 데이터셋용으로 바꿔줄 필요가 있습니다. \n",
    "            nn.Linear(512, 512),   # 따라서 1000이 아닌 10가지의 클래스만을 대상으로 하는 linear 레이어를 새로 쌓고 학습시켜주는부분입니다.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.pre_trained(x) # 128x512x1x1\n",
    "        out = out.squeeze()\n",
    "        out = self.mlp(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1562085998736,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "y6tyTU-3yGHz",
    "outputId": "6bb8bcc5-3c26-4113-993e-192d3afb470a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] number of model parameter - 20365002\n"
     ]
    }
   ],
   "source": [
    "cifar_net = DiyCNN(vgg_model).to(device)\n",
    "criterion = nn.CrossEntropyLoss() # Loss Function을 정의 합니다. 여기서는 cross entrophy loss 를 사용합니다. \n",
    "optimizer = optim.Adam(cifar_net.parameters(), lr=lr) # optimizer는 이와 같이 training 할 Parameter와 learning rate를 인자로 줍니다. \n",
    "\n",
    "print('[info] number of model parameter - %d'%(count_parameters(cifar_net))) # 방금 구성한 모형의 파라미터 개수를 프린트 해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35994,
     "status": "ok",
     "timestamp": 1562086034425,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "Pro0ncYIyJLg",
    "outputId": "5add51ec-0588-4493-d3ae-29b08a9684cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.825\n",
      "[1,   200] loss: 0.542\n",
      "[1,   300] loss: 0.541\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_network(cifar_net,optimizer,trainloader, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35702,
     "status": "ok",
     "timestamp": 1562086037163,
     "user": {
      "displayName": "Wonwoong Cho",
      "photoUrl": "",
      "userId": "14212918309461362604"
     },
     "user_tz": -540
    },
    "id": "Cp7hPPEjyLX6",
    "outputId": "67d1a29a-3dc1-4407-c827-332395402684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set:  Accuracy: 8359/10000 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(cifar_net,testloader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_실습_(문제).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
