{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 기존 머신러닝\n",
    "- 학습 데이터 추가하면 성능이 더 올라갈 수 있었는데 어느정도 올라가다가 미미해짐\n",
    "\n",
    "# 딥러닝\n",
    "- 데이터 헝그리함.\n",
    "- 예) 마이클 조던의 등번호, 입력, 출력, 마이클 조던의 위치. 이 입력에 대한 위치가 어디고 저기고.\n",
    "    - 외주를 줄때 이거는 해줘야 합니다. 레이블링. \n",
    "        - 약간의 노가다를 하여 입출력 예제를 만들어 외주 줘야함.\n",
    "        - 학습 데이터 및 예제 데이터를 많이 줄수록 정확도가 올라감. 더 주면 줄수록 성능이 끝 모르고 올라감 \n",
    "\n",
    "# 딥러닝 성공 요인\n",
    "- GPU\n",
    "    - 흔히 그래픽 카드라 부름. \n",
    "    - NVIDIA\n",
    "    - AMD 회사 (ati회사등에서는 소프트 개발에는 소홀해서 지금은 후발주자)\n",
    "    \n",
    "    \n",
    "### classification보는 사이트\n",
    "- playground.tensorflow.org\n",
    "\n",
    "\n",
    "# 오버피팅 방지\n",
    "- drop out\n",
    "- early stop\n",
    "- regularization (l1,l2)\n",
    "\n",
    "# 질문 놓침\n",
    "- 딥러닝 측면에선느 모델이 파워풀해짐. \n",
    "- 입력 데이터의 일부가 타겟 변수를 예측하는데 무관하면 알아서 무시하는 법을 배우게 된대요. ㄷ\n",
    "- 데이터의전처리단에서 하는 테크닉으로서 배우는것?\n",
    "- 피쳐를 줄인다.\n",
    "    - 유의미한 피쳐를 전처리 단에서 찾아서 입력을 선별하여 넣어주자. \n",
    "        - 이렇게 성능을 올릴 수도 있긴 함.\n",
    "- 데이터 어그먼데이션(불리기)\n",
    "    - 학습데이터가 100개이면 마치 분신술로 200개인 것처럼 뻥 튀기 하는 식의 기법 사용.  \n",
    "    \n",
    "    \n",
    "# augmentation dataset \n",
    "- 고양이 사진\n",
    "    - 왼쪽 /오른쪽/ 좌우 반전한 사진 수집\n",
    "    - 그러나 상하 반전은 하지않아요\n",
    "        - 이 세상에서 존재할 법한 고양이 사진이 거꾸로 되있는거면 물구나무라서 안 발견될 거 같아서.\n",
    "        - 즉 실제로 일어날 것 같은 데이터 염두하고 찾는거에요. \n",
    "    - 가로 세로의 비율을 줄여서 진행\n",
    "    - 각도를 회전한다면 어느 정도로 돌릴지. \n",
    "    - 스탠다드한 것을 통해서 \n",
    "    \n",
    "# 오모메틱 머신러닝\n",
    "- 자동화된 머신러닝\n",
    "    - 학습데이터로 자동화된거 할 수 있지만 영역 바깥도 최적의 세팅을 찾을 수 있는 방법론이 등장\n",
    "    - 데이터 어그멘테이션에 적용되어 '오토 어그멘트' . 이거는 그래디언트 디센트 이외에 추가적인 것 갖고 있어 몇 도 돌려야 성능좋은지\n",
    "        - 좌우반전하고 돌릴지 위아래 디스톨션할지 등에 대한 프로세싱 순서도 알아서 자동으로 결정해주는거 발표되었때\n",
    "\n",
    "#### 딥러닝) 레이어 몇 개 쓰고 노드를 몇 개 쓸지에대한 요소. \n",
    "        - CNN을 구성하는 다양한 모듈 및 레이어등이 있는데 컨벌루션/맥스풀리/풀리 커넥티드\n",
    "            - 그리고 여기서 렐루가 사용되곤하죠. 학습이 빠르다는 장점으로.\n",
    "            - 이런 것들 다양하게 변화를 시키면 알고 있는 것도. \n",
    "### NAS\n",
    "    - 자동으로 알고리즘 찾아준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN은\n",
    "1. 정해진 크기의 입력값을 받아 정해진 크기의 출력값을 내보낸다.\n",
    "2. Feed-forward 뉴런 네트워크에 한 종류로, 최소한의 전처리과정을 거치도록 만들어진 MLP(Multi-Layer Perceptrons)의 변형된 형태이다.\n",
    "3. 뉴런 간의 연결패턴을 이용하는데, 이는 동물의 시각피질의 구조에서 따온 것이다. 시각피질의 뉴런들은 각각 시야를 겹치도록 분할한 타일에 대응된다. --> Overlapping reception fields 를 가지고, 합성곱을 수행한다.\n",
    "4. 이미지와 비디오 처리에 적합하다. \n",
    "\n",
    "# RNN은\n",
    "1. 랜덤한 입력값, 출력값 길이를 다룰 수 있다. \n",
    "2. feed-forward 네트워크와 달리 내적 메모리를 이용하여 랜덤 배열의 입력값을 처리할 수 있다.\n",
    "3. 시간순 정보를 사용한다. ex.) 마지막에 말한 것이 다음에 말할 것에 영향을 준다.\n",
    "4. text, speech 분석에 적합하다.\n",
    "\n",
    "** 둘 다 뉴런 네트워크일 뿐이지 사실상 공통점보다 차이점이 더 많다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 강의 해주신 석사?분 이메일\n",
    "- cb-park@korea.ac.kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 수업\n",
    "- convolution: 이미지를 0과1로 구성된 행렬과 맞춰 필터링 하는 부분\n",
    "- RELU를 통해 결과가 -1나온것들을 0~1사이로 변환\n",
    "- Pooling으로 사이즈 줄이기\n",
    "- CHANNEL) 3. RGB 이미지는 이 세개로 구성이 되니까. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam\n",
    "- Adagrad 와 모멘텀의 합친 것\n",
    "- 에이다 그래드: 과거에 발생한 그래디언트를 축적하여 (제곱의합의 루트) 점점 축적될수록 그래디언트 작아져서 가다가 서요. \n",
    "    - 나눠주는 값이 커서 그럼\n",
    "    - 이터레이션 전체 과정에서 나타난 값들의 합을 나눠주는게 아니라 그것의 평균으로 나눠주자하는게 엘엠에스 프라이..?\n",
    "- 평균적인 값으로 나눠주자\n",
    "    - 예) 50개에 대해서 제곱의 평균은 다 더하고 오십으로 나눔. \n",
    "        - 그 전 오십개까지 평균 만들고 하나가 더 나오면 50개에 대한 합에 하나 더 더해서 51로 나눔\n",
    "            - 이 과정에서 50개에 대한 합은 이미 더해져있으니 ...\n",
    "            - 숫자가 늘 수록 비례해서 나누는 평균값 개념이 유지가능하다 \n",
    "            - 단점) 모든 50이든 51개든 지금가지 것들에 대한 제곱의 평균이..\n",
    "                - 평균이 동일한 가중치에 대한 것을 나타내야하는데 가중평균. \n",
    "                - 좀더 직전에 대한건 많은 가중치 내서 . \n",
    "                - 오래전에 한건 적게 가중치. \n",
    "                - 등비수열 형식으로 생긴대\n",
    "                - 가중평균은 가중치가 바뀌잖아요. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch norm\n",
    "- 중요\n",
    "- 이거로 성능이 훅 오르거나 아니면 갑자기 성능이 안 오리기도 해. \n",
    "- 분포 일정하게 만들려면 입력값으로 평균을 빼고 표준편차로 나누는 식으로 유지시켜\n",
    "- 일정한 분포는 평균은 0이고 표준편차가 1인 식으로 유지되게해\n",
    "- 배치놈은 이런 단순한 노말라이제이션을 하는게 아니고 배치노말/레이어라고 불러요\n",
    "    - 렐루나 멕스 뭐시기가 파라미터는 없지만 뉴럴에서 한 단계 차지하니\n",
    "    - 즉 하나의 레이어로서 있는데, 평균으로 빼고 표준편차로 나누는게 트레이너블한게 없어\n",
    "    - 분포 자체도 무조건 평균0 분산1인게 능사 아니야. 분포도 뉴럴이 정하게 하자 해서 find transform이라는게 등장했대\n",
    " - y=2x+3\n",
    "    - 뉴럴넷이 스스로 선택하게 하여 분포에 최적의 평균과 분산 구할 수 있는 능력이 생겨\n",
    "    \n",
    "    \n",
    "    \n",
    "    - 2단계의 배치놈**************************************************\n",
    "    - 1. 평균이 0이고 분산이 1이게 만들어서 트레이너블한거 없음\n",
    "    - 2. 에이엑스플러스 비에서 백프로로 최적의 갑을 가져서 다음에 통과할 레이어에 일정한 분포(평균과 분산)가 도출되게 하는 식 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 노말라이제이션은\n",
    " - 다양한 형태의 노말라이제이션이 연구되고 사용되고 있어요\n",
    "    - 배치외에 다른 노말라이제이션? 버트/프렌스폼/ 이런 것들에서도 기본적으로 들어가 있어요. \n",
    "- 꽤 트랜디하고 많이 쓰인다\n",
    "    - 그룹 놈. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 번역\n",
    "- i go home\n",
    "    - 나는 집에 갑니다. 집에 내가 갑니다 등등 다 맞는 답일 수 있음\n",
    "    - 나는 집에 간다는 단일한 정답만 매칭하는지를 비교한다면 온전하게 맞았음에도 틀렸다고 볼 수 있어\n",
    "    - 백프로 달성하는 것은 따라서 의미 없고 불가능함\n",
    "    \n",
    "- 사람이 단일한 정답만 만든 해답이 있을때 해석가를 불러서 실제로 미리 만들어둔 단일한 정답과 정확도가 몇 프로 나오는지 봄\n",
    "    - 매칭 정도가 80프로가 나온다면 그건 그보다 잘한다는건 사실 말이 안되고 의미가 안돼\n",
    "        - 그 성능이 머신러닝에서보다 더 잘 나온다면 우리는 정복했다고 볼 수 있어요.\n",
    "        - 컴퓨터 비젼 쪽에서도 사람의 퍼포먼스를 올릴 수 있었는지 볼 수 있어요. \n",
    "        - 그래서 이런 비전쪽에서는 예측 혹은 인식의 태스크는 풀린 듯하고 사람들이 입출력을 뒤집는것. \n",
    "        \n",
    "## 생성 테스크\n",
    "- 입출력 변환하여 더 어려운 것을 딥러닝 기반 다양한 기법으로 연구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Applications\n",
    "- 1. 영상 인식\n",
    "- 2. 자연어 처리 (기계 번역, 대화 시스템)\n",
    "    - 파파고, 구글. 7-8년 전까지만 해도 구글 네이버에서 자체적으로 번역 서비스 제공할때 사용되는 알고리즘이 엑스퍼트에 해당되는(언어 학자 데려와서 i go home에 해당하는게 뭐가 목적어 부사인지 태깅하고, 뉴욕타임즈가 고유 명사인거 알게 해야)지 체크. \n",
    "    - 수식어가 많아도 그것들이 형용사라는거임을 인식하게 해야해 chuncking\n",
    "    - 언어 및 자연어 처리에서 서브 테스크 들. 로우레벨 먼저 잘 하고. \n",
    "    - 언어학에서 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공지능 3대 거장\n",
    "- 얀느 쿤\n",
    "- 요슈아 벤지오\n",
    "- 제프리 힌튼\n",
    "    - 컴퓨터가 알아들을 수 있는거 벡터로 변환. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공지능 연구의 최신 동향\n",
    "- 지도 및 비지도 학습\n",
    "- 벡터 표현형을 통한 이종 데이터의 통합 및 변환\n",
    "- 비지도 및 자가지도 학습\n",
    "- 실제 활용될 떄의 이슈들\n",
    "    - 인공지능 모델의 해석 가능성\n",
    "    - 인공지능 모델의 취약점 및 보안\n",
    "    - 사용자 인터페이스\n",
    "\n",
    "### 지도 및 비지도 학습\n",
    "- self-supervised learning: \n",
    "- \n",
    "- BERT GPT2\n",
    "    - 스탠다드한 다음 단어 예측하는 서로다른 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감정분석\n",
    "- 레이블을 달아두고 학습을 하는게 스탠다드한 형태\n",
    "- 우리는 별도의 레이블 없이 문제 항목 full information으로부터 일부 정보  빼서 이가 빠진 정보를 통해 정보를 예측할거에요\n",
    "    - 예 I [] math라고 하면 빈칸에 들어 갈 수 있는 것은?\n",
    "        - 예측시 필요한 지식: 문법적인 지식\n",
    "        - 의미론적으로는 수학과 의미 있는 것이어야 겠쬬. i drink math 같은건 없겠죠 \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "- Generative Adversarial Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 처리\n",
    "### nlu (understand),  nlg (generate)\n",
    "- 인식 및 예측 문제와 연계\n",
    "- 시퀀스 투 시퀀스\n",
    "- Reading Comprehension-based Question Answering.\n",
    "    - 문장 발췌해서 해요. \n",
    "    - 질의 응답을 하기 위해서 상식을 섭렵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JaegulChoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
