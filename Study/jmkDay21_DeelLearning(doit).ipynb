{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jmkDay21_DeelLearning(doit)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaAw5FAGKGeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "27b3993b-11c9-4c7c-f6d6-f828403f7918"
      },
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ifqbI1pKzlQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f750080-7cb5-4b8c-9eb3-ef7788503625"
      },
      "source": [
        "!ls #실제 배쉬에서 사용가능한거 나옴. 이게 매직코드. "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPF1USANK5pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTv8W2GxK_OQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02675bab-7504-4db5-d0f3-3358bdd0d012"
      },
      "source": [
        "torch.cuda.is_available() #cpu 잘 돌아가는지보는코드"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtSI48vLH6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=torch.FloatTensor([[2,3,4,5]]) #토치 생성(어레이와 같은 방식)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y9EPSeeLbfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68ac2f6c-d44b-4ac9-c4c7-d60297ea9365"
      },
      "source": [
        "a"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3., 4., 5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7IAvT0QLb43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# view는 넌파이의 reshape와 같음"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NJnRPCGLgNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_pWQQvQLiq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b=np.array([[3,4,5,6]]) #넌파이와 같이 비교할게요"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxqvxHmWLmSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da58b97a-7003-4752-ffb4-063b91c16e4a"
      },
      "source": [
        "b.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROrGNK9_Lo1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5e434ee5-efd0-4e34-abdf-175f1b0a9028"
      },
      "source": [
        "b.reshape(2,2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 4],\n",
              "       [5, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJuxVVc9Lq60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a9eafdcc-855d-4be2-c8db-a8078baf8033"
      },
      "source": [
        "a.view(2,2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3.],\n",
              "        [4., 5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywmx4Vb-LyOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42f2ed47-5ddc-4837-cfee-df979f67dff0"
      },
      "source": [
        "a.view(2,-1).flatten() #플랫된 벡터로  펼쳐짐"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 3., 4., 5.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X1rcWFeL_C8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 스퀴즈 언스퀴즈"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpfGFw0JMA74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7e10972-d242-4df3-f93c-c0e3f20b852b"
      },
      "source": [
        "a.unsqueeze(1).shape #언스퀴즈. shape은 1,4인데 현재 1,1,4로 뭔가 끼어들어갔음"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHbBRrbOMDWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e751bbec-fead-4617-85f7-c05fc875db94"
      },
      "source": [
        "a.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHdWjpq_MEsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "349fb77d-835a-4011-862f-d67ce401f8a6"
      },
      "source": [
        "a.unsqueeze(1).squeeze(0)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3., 4., 5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atPm_q45MOWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64726867-929d-400e-b838-20e6edc85520"
      },
      "source": [
        "a.unsqueeze(1).squeeze(0).shape #이렇게 다시 없앨 수 있음"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6BijMcRMQyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85824a36-76b7-4648-86e4-26938fc1c85f"
      },
      "source": [
        "#size통해 첫번째 디멘션의 크기가 몇인지 알 수 있음\n",
        "a.size(0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEcssPY9MZsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.cuda _중요한 메소드 잇어서 볼게요"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yirXtGLwMjUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "626817f6-8e08-4bff-a244-0b07bad08439"
      },
      "source": [
        "#cpu 사용 여부 체크\n",
        "print(torch.cuda.is_available())\n",
        "# 만일 사용이 가능하다면, 이 컴퓨터의 지피유 몇개가 가능한지\n",
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd1DHnW8Mq2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.cuda 플롯 팬서\n",
        "# 지피유에 올라간 텐서생성\n",
        "##################실습################3\n",
        "device=torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbVmFr-tNPtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=a.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN6k1ju3NSRm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10eb4fd6-91bd-4e02-b81b-088c3eec3b95"
      },
      "source": [
        "a"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 3., 4., 5.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWGQgPGNWEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !nvidia-smi실제 지피유 얼마나 사용하는지 확인"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q9QRheXNiN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=torch.cuda.FloatTensor(1024,1024,256) #256메가바이트"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os4xgZElNlut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "7229f78c-f5bf-4c87-9919-d43475c9db43"
      },
      "source": [
        "!nvidia-smi  #실제 지피유 얼마나 사용하는지 확인"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 29 05:33:08 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    56W / 149W |   5174MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CigWbdTN3iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 리니어 구현\n",
        "linear=torch.nn.Linear(4,1) #input:4, output:1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFcp8UMnO_jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=torch.FloatTensor([0,1,1,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xLKVh6RPEbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a954b726-1dfb-4b64-8572-021e03232e5e"
      },
      "source": [
        "# 리이어에 함수 형식으로 넣으면, 값이 이렇게 나와요. (tensor([-0.3247], grad_fn=<AddBackward0>))\n",
        "# 리니어 자체가 함수라서 linear. (점) 클릭하면 사용할 수 있는 값들이 나옴\n",
        "linear(x)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3247], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j1Bkt6xPHmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.nn.functional. 시그모이드나 소프트맥스 등. 액티베이션으로 시그모이드 및 소프트맥스 쓸 수 있는데 그게 여기에 있어요. 함수가 워낙 많아서 docs 볼게요\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO8ByncIQq0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F #귀찮으니까 그냥 F로 부르게해"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLN-r-xNQvGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "24bc2818-6dfd-4349-e05a-a6a0475de3c0"
      },
      "source": [
        "F.sigmoid(linear(x))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4195], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKCpKQSvQ4SZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8ad1a873-5303-411a-fe36-25f9d8fe488a"
      },
      "source": [
        "F.tanh(linear(x))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.3137], grad_fn=<TanhBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udqHfho1Q9Us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4fc2b0d0-b6a9-4a7e-a541-0b9bead9752e"
      },
      "source": [
        "F.sigmoid(linear(x))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4195], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX_uMKmlRrcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d5e3605-d851-4cf2-aaaf-f3584f5abd4f"
      },
      "source": [
        "torch.sigmoid(linear(x))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4195], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CAHSC32Rtm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ADAM- 90프로가 사용함. (option)그리고 여기서 옵션 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItUqiZyxXTH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSVbrvHsXlRc",
        "colab_type": "text"
      },
      "source": [
        "####MODEL은 클래스 형식으로 정의\n",
        "- n드. 클래스 정의 할 때 이 함수가 호출 되는 식으로 필수적으로 구현되어야 함. \n",
        "-  self.(점)으로 하고\n",
        "\n",
        "\n",
        "- relu라는 액티베이션을 통해 계산. \n",
        "- forward 함수도 필수적으로 구현이 되어야 하며 이건 내가 사용하는 학습되어야 할 데이터 대한 것\n",
        "- 즉 ** __init__ 및 forward는 모델에서 꼭 구현이 되어야 함\n",
        "\n",
        "\n",
        "#### Training Model\n",
        "- 인풋 디맨젼 8, 히든 디맨전 128 지정하여 모델 생성 (단 초반에는 리니어에 있는 가중치 랜덤 초기화)\n",
        "- model.parameters()\n",
        "- lr: 러닝 메이트 (10의 -3승을 넣게 되어요)\n",
        "- criterion: MSELose를여기에서 하고\n",
        "- model.train() : 학습모드라고 말해주고\n",
        "- epochs : \n",
        "\n",
        "- 포문: 여러번 학습시켜요(매 학습마다 데이터 순서는 랜덤하게 바꿔줘야해요 ** 딥러닝 성능이 좋다보니 저 순서를 고정해버리면 순서 자체를 외울 수 있음. 따라서 랜덤하게 바꾸며 학습하게 됨)\n",
        "\n",
        "- batch: 예,20개씩 한번에 넣어서 학습하는 식. 하나씩 넣게 되면 너무 속도가 느려서.\n",
        "    - 각각에 대해 평균을 내서 그거에 대한 프로포게이션\n",
        "    - gpu 메모리에 복사를 하게 되면 20장에 대해 모델에 넣게 되고, \n",
        "    \n",
        " - 로스 함수 계산; 20개, 타겟 20개에 대한 민ㅅ퀘어 계산을 하래. 그래서 백워드를 쭉 하면 레이어1,2,3별로 계싼이 되어요. 백워드하면 그ㅐ디언튿르이 각각 생김\n",
        " \n",
        " - 옵티마이저.스탭) ㄱㄱ각 레이어 들이 각각 그래디언트를 가지고 업데이트를 하게 됩니다. \n",
        " \n",
        " - 이 과정 반복하면 모델의 성능이 조아져요\n",
        " - 옵티마이점 제로 그래드는\n",
        "    - 백워드 한번하면 그래디언트 계싼되는데 또 백워드를 하면 그래디언트가 플러스가 됨. 이전 계산에 지금 계산 추가되어 누적되니, 이전 계싼은 날려버리곘다는 뜻.\n",
        "    \n",
        "    \n",
        "    \n",
        "    #### Testing Model\n",
        "    - 우선 그래디언트 계산할 필요 없음\n",
        "        - torch.no_grad로 계산 안하겠다 하여 지피유 메모리 적게 쓰게 함\n",
        "        - model. eval() : 평가 모드로 하겠다. \n",
        "            - 나중에 드랍아웃 및 기타 랜더마이즈한 기법 적용시 학습에서 사용하다가 평가할때는 랜덤하게 사용하겠다 그렇게 고정하겠따는건데 일단 무시(''//'')\n",
        "         - 아까는 MSE에러였는데 이제는 loss . \n",
        "           - 즉 |0.8-1| 로 0.2만큼 차이 있는거 직관적으로 알 수 있게끔. \n",
        "           - 다 더하고 평균내서 토탈 로스로 출력한다고 보시면 됩니다.n.Module: 최상위 부모 클래스\n",
        "- __init__ : 스페셜 메소\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### LOAD and Save Mode\n",
        "- torch.save()\n",
        "    - 이 함수로 저장\n",
        "    - 모델 자체를 넣지 않고, 모델의 상태를 불러와서 저장하게 됨\n",
        "    - torh.save(the_model.state_dict(), PATH)\n",
        "        - 상태) 이런 모델의 상태값 저장을 하고 모델 자체를 저장해도 되나 권장하는 것은 상태저장\n",
        "        - 그래야 변형시 유연함\n",
        "- \n",
        "\n",
        "- the_model+THeModelClass(*args, **kwargs)\n",
        "- the_model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "    - 파일에서 모델을 불러오는 경우.\n",
        "    - 클래스로 정의했기에 실제 객체로 만들어줘야해요. \n",
        "    - 만들지 않고 하면 모델이 없는 채에서 함수 사용하는 식이라 에러 생길 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUz9veWgbbB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# california housing 실습 \n",
        "## https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XPqQ3lIcLWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "# sklearn.datasets.fetch_california_housing(data_home=None, download_if_missing=True, return_X_y=False)[source]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LDQSgyUcS0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c57bafe6-1b26-44b0-ec51-4062c8d864f8"
      },
      "source": [
        "data=fetch_california_housing() #datahome은 어느 경로 다운받을지, return X,y는 피쳐만 받을지 아니면 다른 형태로 받을지"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq-nNiW2cdRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "eb7c53a0-7149-4338-96a5-47e00e2ed5ed"
      },
      "source": [
        "data.data #feature_naems, target:집값"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "          37.88      , -122.23      ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "          37.86      , -122.22      ],\n",
              "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "          37.85      , -122.24      ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "          39.43      , -121.22      ],\n",
              "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "          39.43      , -121.32      ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "          39.37      , -121.24      ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyWGTB_wcnsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66efd86b-b945-49ea-c4f7-fe529d2f99fd"
      },
      "source": [
        "data.data.shape #데이터 20640개, 피쳐 8개"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20640, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIuSqwg1cphM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "6fde542f-20ef-46dc-a81c-ebf50b0d2097"
      },
      "source": [
        "data.feature_names"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MedInc',\n",
              " 'HouseAge',\n",
              " 'AveRooms',\n",
              " 'AveBedrms',\n",
              " 'Population',\n",
              " 'AveOccup',\n",
              " 'Latitude',\n",
              " 'Longitude']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br0jlatacufW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9d92151-b564-45bc-b9f0-33ad1ecf17c5"
      },
      "source": [
        "data.target #0.15~5까지 범위가 있는거 알 수 있어요"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqxbbRZFc0Y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 집값 분포를 간단하게 히스토그램으로 시각화\n",
        "## 박사님은 관련 히스토그램 코드 복붙하고 상황에 맞게 교정하셨음"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Nw3FFLc68r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "5a7b2233-a0a9-484d-c33f-98c002a7ff5c"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#xlabel은 아래에 있는 타이틀\n",
        "plt.xlabel('Housing Value')\n",
        "plt.ylabel('Probability')\n",
        "#plt.xlim\n",
        "#plt.ylim\n",
        "#grid:격자 \n",
        "#plt.show()\n",
        "plt.hist(data.target, 50, density=True, )"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.00449531, 0.0069927 , 0.03046819, 0.12736701, 0.26871942,\n",
              "        0.33764745, 0.27271525, 0.40108122, 0.44004054, 0.35263181,\n",
              "        0.40557653, 0.35712711, 0.41756401, 0.40707496, 0.46001968,\n",
              "        0.47949934, 0.39259009, 0.40807392, 0.35113337, 0.25223663,\n",
              "        0.30967666, 0.33015528, 0.28869856, 0.25373507, 0.2157747 ,\n",
              "        0.21927105, 0.23125854, 0.16532738, 0.15983311, 0.10788735,\n",
              "        0.11188318, 0.11587901, 0.12237223, 0.12586858, 0.14285085,\n",
              "        0.09639935, 0.07991656, 0.07442229, 0.05843898, 0.06643064,\n",
              "        0.05194576, 0.04944837, 0.03995828, 0.04495306, 0.05294472,\n",
              "        0.03296558, 0.02447445, 0.0254734 , 0.02347549, 0.51446283]),\n",
              " array([0.14999  , 0.2469904, 0.3439908, 0.4409912, 0.5379916, 0.634992 ,\n",
              "        0.7319924, 0.8289928, 0.9259932, 1.0229936, 1.119994 , 1.2169944,\n",
              "        1.3139948, 1.4109952, 1.5079956, 1.604996 , 1.7019964, 1.7989968,\n",
              "        1.8959972, 1.9929976, 2.089998 , 2.1869984, 2.2839988, 2.3809992,\n",
              "        2.4779996, 2.575    , 2.6720004, 2.7690008, 2.8660012, 2.9630016,\n",
              "        3.060002 , 3.1570024, 3.2540028, 3.3510032, 3.4480036, 3.545004 ,\n",
              "        3.6420044, 3.7390048, 3.8360052, 3.9330056, 4.030006 , 4.1270064,\n",
              "        4.2240068, 4.3210072, 4.4180076, 4.515008 , 4.6120084, 4.7090088,\n",
              "        4.8060092, 4.9030096, 5.00001  ]),\n",
              " <a list of 50 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgC565WSd0iu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data 2만개있지만 이거 다 안 쓰고, 그 중 일부는 검증용으로 쓸거에요. 랜덤하게 스플릿 해봐요"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiwR22TAd5_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "dcefb0b6-aba9-4c60-c966-5e1d2449e773"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# sklearn.model_selection\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "train_test_split(data.data, data.target, test_size=0.2)\n",
        "## 2개 인풋하면 4개 아웃풋(엑스 트레인, 엑스 테스트, 와이 트레인, 와이 테스트)"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[   4.9904    ,   36.        ,    6.00436681, ...,    3.02620087,\n",
              "           33.86      , -118.11      ],\n",
              "        [   1.372     ,   47.        ,    4.03067485, ...,    3.54294479,\n",
              "           36.73      , -119.81      ],\n",
              "        [   4.625     ,   19.        ,    6.15570934, ...,    2.48961938,\n",
              "           33.01      , -117.05      ],\n",
              "        ...,\n",
              "        [   3.1563    ,   29.        ,    3.41614124, ...,    1.56116015,\n",
              "           34.02      , -118.49      ],\n",
              "        [   4.0714    ,   42.        ,    5.84350133, ...,    2.68435013,\n",
              "           34.19      , -118.13      ],\n",
              "        [   1.4828    ,   24.        ,    4.24832215, ...,    3.63422819,\n",
              "           32.67      , -115.49      ]]),\n",
              " array([[   3.5391    ,   27.        ,    5.83526012, ...,    2.97398844,\n",
              "           34.9       , -120.43      ],\n",
              "        [   4.4637    ,   31.        ,    5.88735632, ...,    2.76781609,\n",
              "           34.11      , -117.62      ],\n",
              "        [   8.3275    ,    4.        ,    7.875     , ...,    3.14732143,\n",
              "           33.55      , -117.69      ],\n",
              "        ...,\n",
              "        [   2.1607    ,   48.        ,    4.40116279, ...,    3.93313953,\n",
              "           34.        , -118.28      ],\n",
              "        [   3.0833    ,   24.        ,    6.42      , ...,    7.864     ,\n",
              "           38.34      , -121.41      ],\n",
              "        [   3.5464    ,   15.        ,    5.06509253, ...,    2.80153159,\n",
              "           38.24      , -122.07      ]]),\n",
              " array([2.217, 0.496, 2.111, ..., 3.3  , 2.34 , 0.731]),\n",
              " array([1.447, 1.928, 3.842, ..., 0.961, 1.625, 1.298])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfyB39f2deAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 우리 0~1사이로 변형해보아요"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40iX7a8odp2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPLdxxOzdsdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train.shape #16512는 학습 테스트용, 8개는 검증용"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxMaedNkfQjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_test # 0.15~5까지 집값있었으니 정규화 해볼게요"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGHSPZPufeT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_, max_ =y_train.min(), y_train.max()# 가장 작고 큰 값을 여기에 넣어 민맥스 정규화 할거야\n",
        "# 민맥스- 0~1사이로 만들어준다. \n",
        " # Y_train 실제 집값. 이거 타겟이니까 이거에 대해 해볼게요\n",
        "y_train=(y_train - min_)/ (max_ - min_)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83QL0KlBfiZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 피쳐 별로 정규화 해볼게요. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-I9YkaEgzcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ0Npf-5g25m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#std_scaler= StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZDrq151g8DM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "227a8612-e179-441d-ab55-180a5c604122"
      },
      "source": [
        "#std_scaler.fit(X_train)#이거로 핏하고 "
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q626zp_6g-SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#std_scaler.mean_ #각 피쳐별로 평균 볼 수 있고\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQqUiJEVhEuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iA0oUvdhL-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 근데 이거 말고 그냥 핏 트랜스폼이 있으니 그거로 하면 됨"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW1uh4kqhRO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_scaler=StandardScaler()\n",
        "X_train=std_scaler.fit_transform(X_train)\n",
        "X_test=std_scaler.transform(X_test) #프렌스폼이야 핏프렌스폼 아니고. 뒤에서 에러나길래 추가한 코드"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsW4ch70-15a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c69f1be0-1497-44b7-96f1-a495f0bade77"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.25 , 0.551, 2.171, ..., 1.528, 3.543, 0.946])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYHuFatBhxfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 아까 에러 나서 고친거. \n",
        "### nd array> torch로 바꿨는데 토치가 32라서 float 64로 변환을 해줘야 함. \n",
        "###\n",
        "\n",
        "X_train, y_train=torch.from_numpy(X_train), torch.from_numpy(y_train)#어레이를 텐서로 변경\n",
        "X_test, y_test= torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
        "X_train, y_train=X_train.float(), y_train.float()\n",
        "X_test, y_test= X_test.float(), y_test.float()\n",
        "\n",
        "\n",
        "y_train, y_test= y_train.view(-1,1), y_test.view(-1,1 #reshape와 같은거로 -1은 맞춰주는식"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awk_G27TmSM5",
        "colab_type": "text"
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest 이해\n",
        "- 만일 키를 통해 몸무게를 추측한다고 합시다\n",
        "- 키에 대한 데이터 172, 180cm등은 Xtrain이고, 178일때의 결과를 얻고 싶은 Xtest라하면\n",
        "- 몸무게(결과 예측)에 대한 데이터는 62, 65kg이 ytain이고, 값이 나왔어야 하는 결과값 70은 ytest\n",
        "- 이때 ytest와 ytrain에 대한 차이가 loss\n",
        "- 에폭: 데이터 넣고 돌리는 한 세트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d2uLXwEmTU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tensor 데이터 셋 사용합시다"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeRLnQGKmeoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "train_dataset=TensorDataset(X_train, y_train)\n",
        "test_dataset=TensorDataset(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHyauxWrm4ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 로더를 정의하여 데ㅐ이터 셋들을 포문 돌면서 배치\n",
        "#torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sample=None) # 셔플_ 랜덤"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj-PGPqonLHq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AXgrTydnHQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader= DataLoader(test_dataset, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7vkGtAHtcLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1635c1a-b70d-41d7-9272-497f851ea601"
      },
      "source": [
        "#X_train.float().dtype"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N4j7BLcnSaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xtrain, ytrain 넣었는데 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QPmXUC5nd0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f1b7f7a-670b-401b-b01f-254cab35c657"
      },
      "source": [
        "for batch_X, batch_y in train_loader : #매 배치마다 엑스와 와이 받을 수 있음\n",
        "    print(batch_X)\n",
        "    print(batch_y)\n",
        "    break"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 4.0062e-01, -1.0892e+00,  2.5016e-01, -6.0753e-02,  8.1550e-01,\n",
            "          5.4675e-02,  9.9457e-01, -9.3897e-01],\n",
            "        [ 9.3599e-01,  1.7753e+00,  1.4877e-01, -1.2610e-01, -5.3864e-01,\n",
            "         -1.0961e-01,  9.9926e-01, -1.4384e+00],\n",
            "        [-3.5210e-01,  4.2261e-01,  2.2126e-02, -1.0867e-01,  2.6973e+00,\n",
            "         -3.6911e-02, -5.4813e-01,  1.6984e-01],\n",
            "        [-4.1914e-01,  1.8549e+00, -4.5521e-01, -9.0607e-02,  1.2662e-03,\n",
            "         -9.1524e-02,  1.0039e+00, -1.4334e+00],\n",
            "        [-1.0756e+00, -8.5052e-01, -4.2245e-01, -7.1570e-02,  1.1405e+00,\n",
            "          1.3301e-01,  4.2719e-01,  1.3987e-01],\n",
            "        [-9.4834e-01, -9.3009e-01, -3.5639e-01, -3.3139e-01, -2.6519e-01,\n",
            "         -1.2932e-01, -1.1718e+00,  1.2187e+00],\n",
            "        [ 1.6799e+00, -2.9353e-01,  1.0296e+00, -2.3669e-01, -1.2978e-01,\n",
            "          1.7074e-02, -8.1541e-01,  8.8407e-01],\n",
            "        [-5.9291e-01,  5.0218e-01, -4.7829e-02, -6.3883e-02, -2.0404e-01,\n",
            "         -5.9850e-04, -1.4019e-01,  2.7473e-01],\n",
            "        [ 1.2030e+00, -2.9353e-01,  4.9012e-01, -2.1100e-01,  2.5375e-01,\n",
            "          2.6486e-02, -6.3723e-01,  4.0958e-01],\n",
            "        [-3.7290e-01, -1.4075e+00, -1.0476e-01,  1.1594e-01, -7.1424e-01,\n",
            "         -5.5279e-02,  1.4916e+00, -6.3429e-01],\n",
            "        [-3.5646e-01, -1.8054e+00, -3.3144e-01, -3.0246e-01, -1.0052e+00,\n",
            "         -1.1003e-01,  1.4072e+00, -9.6394e-01],\n",
            "        [-5.9557e-01,  5.0218e-01, -2.1344e-01, -1.8405e-01,  1.5244e-02,\n",
            "          6.9080e-02, -8.0134e-01,  6.4933e-01],\n",
            "        [-5.9962e-01, -1.5667e+00, -3.9326e-01, -5.6537e-02,  1.2235e+00,\n",
            "         -6.4324e-02,  1.1165e+00, -1.1537e+00],\n",
            "        [ 7.7940e-01,  4.2261e-01,  4.5484e-02, -2.6041e-01, -4.5477e-01,\n",
            "          4.9154e-02, -8.0134e-01,  6.3934e-01],\n",
            "        [-1.9386e-01,  1.8390e-01, -9.9956e-02, -1.1639e-01,  1.0601e+00,\n",
            "          1.1815e-01, -7.2163e-01,  7.9417e-01],\n",
            "        [ 3.5954e-01, -5.4815e-02,  4.7096e-02, -2.7313e-01,  3.3587e-01,\n",
            "         -4.8877e-03,  1.1071e+00, -1.2486e+00],\n",
            "        [ 7.3997e-01, -1.2484e+00,  2.5600e-01, -2.1643e-01, -1.2454e-01,\n",
            "          2.6795e-02, -7.4508e-01,  9.4900e-01],\n",
            "        [-2.7697e-01,  5.8175e-01, -3.4679e-01, -2.8187e-02, -6.4348e-01,\n",
            "         -1.0457e-01, -7.3570e-01,  5.9938e-01],\n",
            "        [-3.3241e-01, -1.8849e+00,  1.3374e-01,  1.0954e-01,  1.4288e+00,\n",
            "          1.0508e-01,  8.6796e-01, -7.7414e-01],\n",
            "        [-9.0955e-01, -5.3224e-01, -1.5979e-01, -1.2680e-02,  8.5481e-01,\n",
            "         -2.1518e-02, -8.5292e-01,  1.1538e+00],\n",
            "        [-6.4367e-01,  9.7960e-01, -6.3358e-01, -5.5818e-01, -6.8541e-01,\n",
            "          7.6164e-02, -8.0603e-01,  6.4433e-01],\n",
            "        [-7.4099e-01, -3.7310e-01, -4.1926e-01, -1.6517e-01,  7.7356e-01,\n",
            "         -1.1361e-01, -5.5751e-01, -9.9868e-02],\n",
            "        [-8.9523e-01,  1.3774e+00,  3.4172e-02,  8.5146e-02, -6.2251e-01,\n",
            "         -5.9779e-02, -1.2143e-01,  2.6474e-01],\n",
            "        [-6.4947e-01, -7.7095e-01, -7.5093e-01, -5.8803e-02,  9.2907e-01,\n",
            "         -9.1730e-02, -6.7005e-01,  5.2446e-01],\n",
            "        [-1.0643e+00,  8.2046e-01, -3.4791e-01,  1.0258e-01,  5.2807e-01,\n",
            "          9.1294e-02,  5.2566e-01, -9.4873e-02],\n",
            "        [-2.7589e-02, -7.7095e-01, -2.6561e-01,  1.1720e-01, -3.4469e-01,\n",
            "         -2.2183e-02, -8.3886e-01,  6.5932e-01],\n",
            "        [-1.1455e+00,  1.7753e+00, -8.1892e-01,  2.3391e-02,  1.1659e-01,\n",
            "          8.7634e-02, -7.4976e-01,  6.4933e-01],\n",
            "        [-7.7444e-02, -1.3439e-01, -1.4942e-01, -3.0768e-01, -8.3830e-01,\n",
            "          1.3386e-02, -6.3254e-01,  4.3456e-01],\n",
            "        [ 1.3655e-01, -1.0097e+00, -4.6395e-02, -2.8230e-02,  4.4857e-01,\n",
            "         -7.1331e-03, -1.2515e+00,  1.2687e+00],\n",
            "        [-1.0517e-01, -1.0892e+00,  3.5195e+00,  3.7182e+00, -8.6451e-01,\n",
            "         -8.7953e-02, -8.5761e-01,  1.5434e+00],\n",
            "        [-1.3340e+00,  4.2261e-01,  1.4740e+00,  3.8056e+00, -4.6875e-01,\n",
            "         -8.5942e-02, -6.7005e-01,  1.8580e+00],\n",
            "        [-8.9656e-01,  5.8175e-01, -1.0082e+00, -5.6983e-02,  3.3412e-01,\n",
            "          4.6082e-02, -7.1225e-01,  6.8429e-01]])\n",
            "tensor([[0.3089],\n",
            "        [1.0000],\n",
            "        [0.4384],\n",
            "        [0.8740],\n",
            "        [0.0893],\n",
            "        [0.1340],\n",
            "        [0.7070],\n",
            "        [0.1047],\n",
            "        [0.4330],\n",
            "        [0.2425],\n",
            "        [0.2103],\n",
            "        [0.1893],\n",
            "        [0.2784],\n",
            "        [0.2897],\n",
            "        [0.3017],\n",
            "        [0.3132],\n",
            "        [0.3697],\n",
            "        [1.0000],\n",
            "        [0.2272],\n",
            "        [0.2711],\n",
            "        [0.2981],\n",
            "        [0.5779],\n",
            "        [0.1243],\n",
            "        [0.3711],\n",
            "        [0.0738],\n",
            "        [0.3981],\n",
            "        [0.2268],\n",
            "        [0.4845],\n",
            "        [0.3445],\n",
            "        [0.1546],\n",
            "        [0.0536],\n",
            "        [0.3520]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkpyV0GgnkNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 정의\n",
        "import torch.nn as nn\n",
        "class Model(nn.Module): #괄호안에는 속성으로 nn.Module\n",
        "    def __init__(self, input_dim, hidden_dim): #인풋과 히든 디멘젼을 처음에 만들어 줘야함\n",
        "        super(Model, self).__init__() #파이썬 문법이니 그렇구나\n",
        "        self.input_dim=input_dim\n",
        "        self.hidden_dim=hidden_dim\n",
        "        \n",
        "        self.linear1= nn.Linear(self.input_dim, self.hidden_dim)#첫 인풋 받아서 첫 히든 만드는 벡터\n",
        "        self.linear2= nn.Linear(self.hidden_dim, 1)#아웃풋 레이어 벡터 만들기. 집 하나만 예측하니1\n",
        "        pass\n",
        "    def forward(self,x): #x를 받아 처리해서 예측 값을 반환해야해요\n",
        "        z1=self.linear1(x)\n",
        "        a1=torch.relu(z1)# relu라는 활성화 함수 사용\n",
        "        z2=self.linear2(a1)\n",
        "        a2=torch.sigmoid(z2)# 타겟 0~1이었으니 지금도 0~1로 만드어 보아요. 시그모이드가 아까 0~1이랬으니 한번 써봐요\n",
        "        return a2\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP1iTHfHpKzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 생성\n",
        "device= torch.device('cuda') # gpu 학습이니까\n",
        "model= Model(8, 32)\n",
        "model= model.to(device)# 모델을 지피유로 올려\n",
        "\n",
        "mse_loss=nn.MSELoss()# Torch.nn안에 MSELoss 내용 있으니 참고\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=0.001) # adam이라는 옵티마이저 써볼게요.(첫 인자 파라미터, 두번째는 러닝메이트)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azhbCwnop1kg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "fd30e482-09ef-45ae-e5bb-b72fd1076d37"
      },
      "source": [
        "# 학습 모드 트레인\n",
        "epochs=10 # 10번 학습\n",
        "model.train()\n",
        "for e in range(epochs):\n",
        "    for i, (batch_X, batch_y) in enumerate(train_loader): # 배치 엑스와 와이가 씨피유에 있고 지피유에 없으니 다시 지피유로 올려요\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)#@@@@@이걸 왜 gpuㄹ 올령하나요굳이\n",
        "        # 배치 예측\n",
        "        predict = model(batch_X)\n",
        "        loss=mse_loss(predict, batch_y)\n",
        "        \n",
        "        optimizer.zero_grad() #이전 그래디언트 누적되면 결과에 영향 미치니까 그냥 이전거 날려 0으로\n",
        "        loss.backward() #각 가중치별로 그래디언트 계산\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        #200번째마다 로스출력\n",
        "        # 에프 스트링: \n",
        "        if i % 200 == 0:\n",
        "            loss=loss.cpu() #loss가 어떤 값 하나이면 씨피유 안 하고 바로 loss.item()해도 가능함\n",
        "            print(f\"{e},{i}-{loss}\") #loss는 지피유인데 씨피유에서 출력하려 하면 에러나니까 위에 코드 써줘야함"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0,0-0.07371290028095245\n",
            "0,200-0.014938650652766228\n",
            "0,400-0.025173788890242577\n",
            "1,0-0.01911988854408264\n",
            "1,200-0.02171453833580017\n",
            "1,400-0.010904626920819283\n",
            "2,0-0.014626316726207733\n",
            "2,200-0.015153334476053715\n",
            "2,400-0.04078773409128189\n",
            "3,0-0.01085083931684494\n",
            "3,200-0.004360968247056007\n",
            "3,400-0.006299592554569244\n",
            "4,0-0.020534750074148178\n",
            "4,200-0.009886292740702629\n",
            "4,400-0.018275685608386993\n",
            "5,0-0.017811264842748642\n",
            "5,200-0.009637875482439995\n",
            "5,400-0.013171365484595299\n",
            "6,0-0.022119613364338875\n",
            "6,200-0.020386729389429092\n",
            "6,400-0.015875646844506264\n",
            "7,0-0.014855602756142616\n",
            "7,200-0.018197238445281982\n",
            "7,400-0.010170700028538704\n",
            "8,0-0.013967929407954216\n",
            "8,200-0.014287417754530907\n",
            "8,400-0.019242320209741592\n",
            "9,0-0.011845952831208706\n",
            "9,200-0.011841812171041965\n",
            "9,400-0.010580294765532017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GKaFLgOsjKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7e9df25-096b-42b1-c964-6deb686d78d3"
      },
      "source": [
        "# f string _ 변수의 값 바로 넣게 하는것 파이썬 3.6부터 사용 가능******************************\n",
        "a=32323\n",
        "print(f\"a Value:{a}\")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a Value:32323\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mRAhFmeqwkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "ae4a02ad-b3b7-4bb1-d947-64ffb0b76310"
      },
      "source": [
        "# 마지막 다 한 이후에 성능을 위해 하는 것\n",
        "# L1_Loss 실제 예측과 타겟의 절대적인 차이를 계싼하는 로스. 분석할때 사용\n",
        "## torch.nn.L\n",
        "l1_loss=nn.L1Loss()\n",
        "\n",
        "\n",
        "#전체 테스트 셋이 몇 개인지 체크\n",
        "test_num=0\n",
        "total_lost=[]\n",
        "\n",
        "with torch.no_grad(): #이러면 그라디언트가 안 느니까 무리가 없겠지\n",
        "    model.eval()\n",
        "# 배치 테스트로더에 있는 테스트 데이터 샘플을 다 돌면서 샘플들에 로스들의 총 합을 구할거에요. 그리고 테스트 데이터 셋의 총 갯수로 나누면 전체적인 평균이 되겠죠\n",
        "    \n",
        "    for batch_X, batch_y in test_loader: #얘네 지피유 없으니 지피유로 복사\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        \n",
        "        \n",
        "        #트레이닝데이터에 대해 표준정규분포로 노말라이제이션 했으니 테스트 셋에 대해서도 해줘야해\n",
        "        batch_X=(batch_X - std_scaler.mean_)/std_scaler.var_ #@@@@@@@@@@왜 해주는거\n",
        "        predict= model(batch_X)# 민맥스 스케일로 계산되어서 이것도 다시 변환 해줘야함 #@@@@@@@@@@@@왜해야함\n",
        "        \n",
        "        #역변환\n",
        "        predict= (max_- min_)*predict + min_ # 0.15~5사이로 범위 다시 맞출 수 있어요\n",
        "        \n",
        "        loss= l1_loss(predict, batch_y)\n",
        "        \n",
        "        # 갯수가 딱 안 맞는 경우 대비하여 작성\n",
        "        batch_size=batch_X.size(0)\n",
        "        \n",
        "        \n",
        "        #로스 다시 아이템으로 씨피유 올리고 토탈로 받아\n",
        "        total_loss.append(loss)# loss:해당 이터레이션에 대한 평균 #???????????????????/\n",
        "        total_loss.append(loss*batch_size) #?????????????????????????????????\n",
        "        test_num+=batch_size #그럼 테스트 셋이 98개인거 알 수 있쬬. 그럼 로스에 98개인거 나누면 균등한 평균 알 수 있대 @@\n",
        "total_loss=np.mean(total_loss)/test_num\n",
        "print(total_loss)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-230-ecca50b12291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#트레이닝데이터에 대해 표준정규분포로 노말라이제이션 했으니 테스트 셋에 대해서도 해줘야해\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbatch_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstd_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstd_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_\u001b[0m \u001b[0;31m#@@@@@@@@@@왜 해주는거\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# 민맥스 스케일로 계산되어서 이것도 다시 변환 해줘야함 #@@@@@@@@@@@@왜해야함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sub(): argument 'other' (position 1) must be Tensor, not numpy.ndarray"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFew_Epzvad7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 현재 히든 레이어 1개였는데, 인풋만 받고 예측 하게 해볼게요\n",
        "\n",
        "# 모델 정의\n",
        "import torch.nn as nn\n",
        "class Model(nn.Module): #괄호안에는 속성으로 nn.Module\n",
        "    def __init__(self, input_dim, hidden_dim): #인풋과 히든 디멘젼을 처음에 만들어 줘야함\n",
        "        super(Model, self).__init__() #파이썬 문법이니 그렇구나\n",
        "        self.input_dim=input_dim\n",
        "        self.hidden_dim=hidden_dim\n",
        "        \n",
        "        self.linear1= nn.Linear(self.input_dim, self.hidden_dim)#첫 인풋 받아서 첫 히든 만드는 벡터\n",
        "\n",
        "   \n",
        "    def forward(self,x): #x를 받아 처리해서 예측 값을 반환해야해요\n",
        "        z1=self.linear1(x)\n",
        "        a1=torch.relu(z1)# relu라는 활성화 함수 사용\n",
        "  \n",
        "        return a2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t8zq9vv26-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "3d7ccc00-76ab-400c-91b0-ae0ab5d6666e"
      },
      "source": [
        "# 학습 모드 트레인\n",
        "epochs=10 # 10번 학습\n",
        "model.train()\n",
        "for e in range(epochs):\n",
        "    for i, (batch_X, batch_y) in enumerate(train_loader): # 배치 엑스와 와이가 씨피유에 있고 지피유에 없으니 다시 지피유로 올려요\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        # 배치 예측\n",
        "        predict = model(batch_X)\n",
        "        loss=mse_loss(predict, batch_y)\n",
        "        \n",
        "        optimizer.zero_grad() #이전 그래디언트 누적되면 결과에 영향 미치니까 그냥 이전거 날려 0으로\n",
        "        loss.backward() #각 가중치별로 그래디언트 계산\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        #200번째마다 로스출력\n",
        "        # 에프 스트링: \n",
        "        if i % 200 == 0:\n",
        "            loss=loss.cpu() #loss가 어떤 값 하나이면 씨피유 안 하고 바로 loss.item()해도 가능함\n",
        "            print(f\"{e},{i}-{loss}\") #loss는 지피유인데 씨피유에서 출력하려 하면 에러나니까 위에 코드 써줘야함"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:443: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0,0-2.05976939201355\n",
            "0,200-3.511732578277588\n",
            "0,400-3.1198883056640625\n",
            "1,0-2.738675117492676\n",
            "1,200-1.5061615705490112\n",
            "1,400-2.314528703689575\n",
            "2,0-3.04301381111145\n",
            "2,200-2.121567487716675\n",
            "2,400-1.399751901626587\n",
            "3,0-3.4249320030212402\n",
            "3,200-2.8707096576690674\n",
            "3,400-1.2529720067977905\n",
            "4,0-2.028738498687744\n",
            "4,200-2.499734878540039\n",
            "4,400-1.9956014156341553\n",
            "5,0-2.453291893005371\n",
            "5,200-2.9933032989501953\n",
            "5,400-2.1135921478271484\n",
            "6,0-1.4823060035705566\n",
            "6,200-4.078492164611816\n",
            "6,400-1.882354497909546\n",
            "7,0-2.137181282043457\n",
            "7,200-3.5115861892700195\n",
            "7,400-2.107954263687134\n",
            "8,0-2.9783999919891357\n",
            "8,200-2.7226312160491943\n",
            "8,400-3.515768051147461\n",
            "9,0-2.5658020973205566\n",
            "9,200-1.6819689273834229\n",
            "9,400-2.2110722064971924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB38hyJGCZ5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bab91bd-4864-483a-fc2b-367269f0f586"
      },
      "source": [
        "batch_X.size(0)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sssGYtseCeuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "546d9b7b-7b09-4e2a-e2c5-614a9edea08d"
      },
      "source": [
        "batch_X.size()"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8XSVy6hChBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4784a336-42fa-4de2-907a-72864c4c0e48"
      },
      "source": [
        "batch_X"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8.9220e-01,  1.6162e+00, -3.3857e-01, -1.9496e-01, -1.2341e+00,\n",
              "         -9.5012e-02, -7.4508e-01,  5.6442e-01],\n",
              "        [-1.3010e+00, -1.3279e+00, -7.2584e-01, -1.0394e-01,  1.2078e+00,\n",
              "          1.8844e-01,  2.6307e-01, -2.5970e-01],\n",
              "        [ 7.5508e-01,  3.4304e-01,  1.9917e-01, -2.6430e-01, -7.1246e-02,\n",
              "         -5.8469e-02, -1.3500e+00,  1.2737e+00],\n",
              "        [ 1.2916e-01,  1.8549e+00, -2.9489e-01, -3.0502e-01, -7.8235e-02,\n",
              "          5.5593e-03,  9.8519e-01, -1.4284e+00],\n",
              "        [ 4.7123e-01,  6.6132e-01, -1.0904e-01, -2.3436e-01, -5.7533e-01,\n",
              "          5.5688e-02, -8.1072e-01,  7.3423e-01],\n",
              "        [-9.8457e-01, -9.3009e-01, -7.0677e-01, -3.3772e-02, -5.2903e-01,\n",
              "         -1.0214e-01, -1.3453e+00,  1.2237e+00],\n",
              "        [-3.7237e-01,  6.6132e-01,  3.6476e-01, -3.3772e-02, -7.3434e-01,\n",
              "         -3.0629e-02,  8.8672e-01, -7.8413e-01],\n",
              "        [ 1.3156e+00, -1.9645e+00, -2.2270e-01, -5.0123e-01, -1.6207e-02,\n",
              "         -1.2014e-02, -1.0124e+00,  9.6898e-01],\n",
              "        [ 6.1106e-02, -1.0892e+00, -9.5856e-01, -3.2825e-01, -9.7546e-01,\n",
              "         -7.2098e-02, -7.8259e-01,  5.7940e-01],\n",
              "        [ 6.2829e-01,  9.0003e-01,  2.3980e-03,  1.6923e-01, -6.1290e-01,\n",
              "          7.6216e-04, -8.1072e-01,  6.0437e-01],\n",
              "        [ 1.2947e+00,  1.8549e+00,  8.6349e-01, -1.5936e-01, -2.3462e-01,\n",
              "         -1.6333e-02, -6.7943e-01,  6.4933e-01],\n",
              "        [-1.8875e-01,  1.8390e-01,  8.5216e-02, -1.9496e-01,  1.0121e+00,\n",
              "          4.5854e-02, -1.4156e+00,  1.2587e+00],\n",
              "        [ 1.6778e+00, -9.3009e-01,  3.8850e-01,  2.8887e-02, -4.6788e-01,\n",
              "          7.0868e-03, -1.0968e+00,  1.2587e+00],\n",
              "        [-8.1819e-01,  1.1387e+00, -3.7527e-01,  4.8527e-02,  5.0190e-02,\n",
              "         -1.1717e-01,  1.3838e+00, -9.4895e-01],\n",
              "        [-6.5942e-01,  2.6347e-01, -5.1122e-01, -5.8369e-03,  4.6691e-01,\n",
              "          7.3213e-04, -6.7474e-01,  5.1947e-01],\n",
              "        [ 3.2491e-01,  2.6347e-01, -5.9539e-01, -1.7771e-01, -2.8878e-01,\n",
              "          1.3312e-03,  9.5237e-01, -1.4184e+00],\n",
              "        [ 7.4061e-01, -3.7310e-01,  1.7939e-01, -1.8359e-01,  9.0985e-01,\n",
              "          3.2006e-02, -8.9044e-01,  8.1415e-01],\n",
              "        [-7.0523e-01,  1.4570e+00, -3.1513e-02, -6.5719e-02, -1.0357e-01,\n",
              "         -2.7249e-02,  1.3650e+00, -9.3397e-01],\n",
              "        [-1.1117e+00,  2.4755e-02, -6.3331e-01,  8.7473e-02, -1.5861e-01,\n",
              "          1.2827e-01,  4.1312e-01, -9.3897e-01],\n",
              "        [-2.6292e-01,  1.8549e+00, -3.3646e-01,  3.2278e-03, -5.6136e-01,\n",
              "         -1.1042e-01,  9.9926e-01, -1.4334e+00],\n",
              "        [-7.9626e-02,  2.6347e-01, -7.9064e-01, -2.4485e-01,  3.2232e+00,\n",
              "          2.5298e-01, -8.9044e-01,  8.3413e-01],\n",
              "        [-9.3498e-01,  1.8549e+00, -4.7433e-01, -2.1940e-01, -3.4120e-01,\n",
              "          9.3403e-02, -7.4976e-01,  6.8928e-01],\n",
              "        [ 9.7983e-01,  3.4304e-01,  1.9800e-01, -1.5696e-01, -5.3952e-01,\n",
              "         -5.1963e-03,  8.1170e-01, -1.2037e+00],\n",
              "        [-6.3213e-01, -1.0097e+00, -5.8369e-01,  7.6485e-03,  2.1618e-01,\n",
              "         -5.5060e-02,  7.8356e-01, -1.1537e+00],\n",
              "        [-3.4907e-01,  9.0003e-01, -5.2020e-01,  3.9215e-03,  2.1705e-01,\n",
              "         -9.8981e-02,  9.9926e-01, -1.4484e+00],\n",
              "        [-6.1510e-01, -1.0097e+00,  2.0165e+00,  2.6769e+00, -7.3259e-01,\n",
              "         -6.4675e-03,  2.4857e+00, -1.6182e+00],\n",
              "        [-2.1775e-01, -8.5052e-01,  5.2421e-03, -1.4341e-01, -1.3065e-01,\n",
              "         -1.2240e-02, -1.3687e+00,  1.2936e+00],\n",
              "        [-9.0002e-01, -5.3224e-01,  7.5520e-02, -7.5602e-02, -4.2420e-01,\n",
              "         -1.5369e-02,  1.7730e+00, -1.0688e+00],\n",
              "        [ 3.7513e-01,  1.8390e-01,  2.6928e-01, -2.3406e-01, -1.2279e-01,\n",
              "         -2.9283e-02, -1.1577e+00,  1.1138e+00],\n",
              "        [ 2.2786e-01,  2.6347e-01, -7.3308e-03,  1.3333e-02,  4.1537e-01,\n",
              "          2.4140e-02, -7.4039e-01,  8.1914e-01],\n",
              "        [ 1.6205e+00,  9.0003e-01, -2.0022e-01, -1.3731e-01, -8.9771e-01,\n",
              "         -7.1725e-02, -7.2632e-01,  4.8450e-01],\n",
              "        [-3.8232e-01,  3.4304e-01, -1.9296e-01,  9.4906e-02, -9.3964e-01,\n",
              "         -6.1199e-02,  7.9294e-01, -1.1887e+00]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLh1CBQ2C6l5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a43274dd-6d04-4ae9-e60e-8996139712fa"
      },
      "source": [
        "loss"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32488447427749634"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHZspx0r3AeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77159d08-0481-4c1a-cb1c-c1fa9c1574e0"
      },
      "source": [
        "# L1_Loss 실제 예측과 타겟의 절대적인 차이를 계싼하는 로스. 분석할때 사용\n",
        "## torch.nn.L\n",
        "l1_loss=nn.L1Loss() #L1은 절대적인 차이를 나타냄 |3.7-4.1|\n",
        "\n",
        "\n",
        "#전체 테스트 셋이 몇 개인지 체크\n",
        "test_num=0\n",
        "total_loss=[]\n",
        "\n",
        "with torch.no_grad(): #성능을 평가할거니까 grad는 쓸 필요 없어서 빼고\n",
        "    model.eval() #model은 평가 모드로 쓸거라고 선언\n",
        "# 배치 테스트로더에 있는 테스트 데이터 샘플을 다 돌면서 샘플들에 로스들의 총 합을 구할거에요. 그리고 테스트 데이터 셋의 총 갯수로 나누면 전체적인 평균이 되겠죠\n",
        "    \n",
        "    for batch_X, batch_y in test_loader: #얘네 지피유 없으니 지피유로 복사\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        \n",
        "        \n",
        "        predict= model(batch_X) # 우리 x를 이용해서 batch_X를 예측을 해보면 0~1 사이로 값이 나오겠죠.\n",
        "        \n",
        "        #역변환. 민맥스 스케일로 계산되어서 이것도 다시 변환 해줘야함\n",
        "        predict= (max_- min_)*predict + min_ # 0.15~5사이로 범위 다시 맞출 수 있어요. \n",
        "        \n",
        "        loss= l1_loss(predict, batch_y) #예측한 값과 batchy 에 대한 절대적인 차이를 넣고\n",
        "        loss=loss.item() # 그 넣은 값을 하나씩 너어줍니다. \n",
        "        \n",
        "        # 갯수가 딱 안 맞는 경우 대비하여 작성\n",
        "        batch_size=batch_X.size(0) # 왜 영 넣었지? 이거 토치라. size()하면 (32,8)리스트 나오니, 원하는 32개 나오려면 size(0)\n",
        "        \n",
        "        #로스 다시 아이템으로 씨피유 올리고 토탈로 받아\n",
        "        total_loss.append(loss*batch_size) #토탈 로스는, 로스 몇 개인지 구하고 \n",
        "        test_num+=batch_size #그럼 테스트 셋이 98개인거 알 수 있쬬. 그럼 로스에 98개인거 나누면 균등한 평균 알 수 있대 @@\n",
        "total_loss=np.sum(total_loss)/test_num\n",
        "print(total_loss)"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.41180198529894035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhPOV_1N3DM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "0968a549-99f6-47bb-f39e-0cfb8251b6a2"
      },
      "source": [
        "# 딥러닝 장점 겸 단점\n",
        "model.linear1.weight #각 값에 대한 가중치를 볼 수 있어요"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0601,  0.1990,  0.2708,  0.3641,  0.2026, -0.1196, -0.2511,  0.1315],\n",
              "        [ 0.2844, -0.3171,  0.2034, -0.2983, -0.1259, -0.0321,  0.6199, -0.6288],\n",
              "        [-0.1695,  0.2942,  0.0043, -0.6978, -0.9980, -0.3469,  0.9167, -0.7546],\n",
              "        [-0.4152,  0.4413, -0.3947, -0.4352, -0.3651, -0.1648,  0.4858, -0.1746],\n",
              "        [-0.6103, -0.5530, -0.2142, -0.6517,  0.2048, -0.2471, -0.6672,  0.5346],\n",
              "        [-0.6356, -0.0384, -0.4212,  0.3782, -0.5709,  0.2123, -0.7461,  0.9073],\n",
              "        [ 0.2015,  0.0618, -0.1127,  0.2057, -0.1795,  0.1334, -0.1237,  0.0868],\n",
              "        [ 0.5619, -0.2724,  0.5174,  0.0499, -0.7334, -0.2862, -0.6733,  0.7549],\n",
              "        [-0.7518, -0.7799,  0.3570,  0.2144,  0.5897, -0.1190,  0.5329, -0.7381],\n",
              "        [-0.6441,  0.4198, -0.6093, -0.3952, -0.4990,  0.1785,  0.3007, -0.0634],\n",
              "        [-0.4427,  0.5370, -0.4128, -0.6343, -0.4616, -0.2573, -0.9559,  0.7610],\n",
              "        [ 0.4695, -0.3941,  0.5774, -0.3115, -0.4363, -0.2691,  0.6235, -0.3882],\n",
              "        [-0.0872, -0.1880, -0.2190, -0.2624,  0.2251,  0.2107,  0.0141,  0.0255],\n",
              "        [-0.0458,  0.0990,  0.0387, -0.1613, -0.0700, -0.0063, -0.1746, -0.2078],\n",
              "        [-0.1006, -0.2095, -0.0829, -0.2572, -0.1345,  0.0382,  0.1487, -0.1517],\n",
              "        [-0.6082, -0.2792, -0.4241, -0.2210,  0.3711, -0.2820, -0.5440,  0.7517],\n",
              "        [-0.2652,  0.0987,  0.1690, -0.0353,  0.2622, -0.0093,  0.0194,  0.0096],\n",
              "        [ 0.4370,  0.2758,  0.2500, -0.5251,  0.1141,  0.2098, -0.4596,  0.8822],\n",
              "        [-0.0716, -0.2015,  0.1653,  0.0036,  0.0283, -0.2456, -0.0348,  0.1387],\n",
              "        [ 0.4003, -0.5282,  0.4625, -0.7656,  0.3577,  0.0219, -1.0356,  0.3639],\n",
              "        [-0.2173,  0.6058, -0.1753, -0.2108,  0.0910,  0.0838, -0.7291,  0.4664],\n",
              "        [-0.0473,  0.0405,  0.1983,  0.1304,  0.2335,  0.0729,  0.1659,  0.2275],\n",
              "        [-0.4212,  0.5346, -0.2949, -0.6386, -0.1471, -0.5354,  0.4037, -0.7421],\n",
              "        [ 0.4127, -0.9082,  0.5672,  0.6779, -0.9001, -0.9557,  0.4758, -0.7814],\n",
              "        [-0.5872,  0.5579, -0.3376, -0.2265, -0.5673, -0.3912, -0.7013,  0.4536],\n",
              "        [-0.0256,  0.6838,  0.0761,  0.1072, -0.1309,  0.2405, -0.6805,  0.4533],\n",
              "        [ 0.2707, -0.4828,  0.6474,  0.0350,  0.3581, -0.3092, -0.5672, -0.1129],\n",
              "        [-0.4083, -0.5646, -0.2567,  0.3310,  0.6816,  0.4668, -0.0108,  0.6737],\n",
              "        [-0.5441,  0.7087, -0.3831, -0.4015, -0.2771,  0.2439,  0.2791, -0.5649],\n",
              "        [-0.5465, -0.0156, -0.1039, -0.7817,  0.5113,  0.3751,  0.4038, -0.7621],\n",
              "        [ 0.5210,  0.2908, -0.4026, -0.6689,  0.4431,  0.1477, -0.5303,  0.8816],\n",
              "        [ 0.3992, -0.3444,  0.9168,  0.2421,  0.4047, -0.6271,  0.8252, -0.6434]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySd-ByTQ3J2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}