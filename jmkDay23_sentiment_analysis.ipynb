{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jmkDay23_sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minkyoJang/AI-BigDataStudy/blob/master/jmkDay23_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEK9W8iiQg0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive/')\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdLF_oyMTego",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "okt = Okt()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMbsNc8tQjoI",
        "colab_type": "code",
        "outputId": "b1c68b99-762e-4dd6-9299-819a989c3ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"/drive/My Drive/lectures/deep_learning/2강/data\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_deep.pkl  data_ml.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrC9c3GgSGKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/drive/My Drive/lectures/deep_learning/2강/data/data_deep.pkl', 'rb') as f:\n",
        "    index2voca = pickle.load(f)\n",
        "    voca2index = pickle.load(f)\n",
        "    train_X = pickle.load(f)\n",
        "    train_y = pickle.load(f)\n",
        "    test_X = pickle.load(f)\n",
        "    test_y = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moUI856pSkQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, train_y = torch.LongTensor(train_X), torch.FloatTensor(train_y)\n",
        "test_X, test_y = torch.LongTensor(test_X), torch.FloatTensor(test_y)\n",
        "\n",
        "train_y, test_y = train_y.view(-1, 1), test_y.view(-1, 1)\n",
        "\n",
        "train_dataset = TensorDataset(train_X, train_y)\n",
        "test_dataset = TensorDataset(test_X, test_y)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zERz4SCsSrqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNRegressor(nn.Module):\n",
        "    def __init__(self, voca_num, embedding_dim, filter_lengths, filter_num=20):\n",
        "        super(CNNRegressor, self).__init__()\n",
        "        \n",
        "        self.voca_num = voca_num\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.filter_lengths = filter_lengths\n",
        "        self.filter_num = filter_num\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.voca_num, self.embedding_dim, padding_idx=0)\n",
        "        self.filters = nn.ModuleList([nn.Conv1d(1, self.filter_num, (l, self.embedding_dim)) \\\n",
        "                                      for l in self.filter_lengths])\n",
        "        \n",
        "        self.linear1 = nn.Linear(self.filter_num*len(self.filter_lengths), 10)\n",
        "        self.linear2 = nn.Linear(10, 1)\n",
        "        \n",
        "    def forward(self, words):\n",
        "        embs = self.embedding(words)\n",
        "        embs = embs.unsqueeze(1)\n",
        "        features = [F.relu(conv(embs)) for conv in self.filters]\n",
        "        features = [f.squeeze(3) for f in features]\n",
        "        features = [F.max_pool1d(f, f.size(2)) for f in features]\n",
        "        output = torch.cat(features, dim=1)\n",
        "        output = output.squeeze(2)\n",
        "        output = torch.relu(self.linear1(output))\n",
        "        output = self.linear2(output)\n",
        "        return output\n",
        "    \n",
        "\n",
        "class RNNRegressor(nn.Module):\n",
        "    def __init__(self, voca_num, embedding_dim, hidden_dim, num_layer=2, bidirectional=True):\n",
        "        super(RNNRegressor, self).__init__()\n",
        "        self.voca_num = voca_num\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layer = num_layer\n",
        "        self.bidirectional = bidirectional\n",
        "        \n",
        "        self.embedding = nn.Embedding(voca_num, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=self.num_layer,\n",
        "                          bidirectional=self.bidirectional, batch_first=True)\n",
        "        self.linear1 = nn.Linear(hidden_dim*(self.bidirectional + 1), 10)\n",
        "        self.linear2 = nn.Linear(10, 1)\n",
        "        \n",
        "    def forward(self, words):\n",
        "        embs = self.embedding(words)\n",
        "        output, h_n = self.gru(embs)\n",
        "        output = output[:, -1, :]\n",
        "        output = torch.relu(self.linear1(output))\n",
        "        output = self.linear2(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXPNXECbX0oH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "# reg = CNNRegressor(len(index2voca), 128, [2, 3, 4])\n",
        "reg = RNNRegressor(len(index2voca), 256, 256, num_layer=2, bidirectional=True)\n",
        "reg = reg.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optim = torch.optim.Adam(reg.parameters(), lr=1e-3, weight_decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtnrjUz9YSC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "reg.train()\n",
        "for e in range(epochs):\n",
        "    for i, (batch_X, batch_y) in enumerate(train_loader):\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        \n",
        "        predict = reg(batch_X)\n",
        "        \n",
        "        loss = criterion(predict, batch_y)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(reg.parameters(), 0.5)\n",
        "        optim.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            loss = loss.item()\n",
        "            print(f\"{e}epochs, {i}iters - {loss}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BXZ9CFZe34w",
        "colab_type": "code",
        "outputId": "e435b52f-f56a-409f-a35b-d474c209d65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_loss = []\n",
        "test_num = 0\n",
        "l1_loss = nn.L1Loss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    reg.eval()\n",
        "    for i, (batch_X, batch_y) in enumerate(test_loader):\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        predict = reg(batch_X)\n",
        "        predict = torch.clamp(predict, min=0, max=1)\n",
        "        \n",
        "        loss = l1_loss(predict, batch_y)\n",
        "        loss = loss.item()\n",
        "        batch_size = batch_X.size(0)\n",
        "        test_num += batch_size\n",
        "        total_loss.append(loss*batch_size)\n",
        "        \n",
        "total_loss = np.sum(total_loss)/test_num\n",
        "print(total_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2779954965793842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkijhQENu6U4",
        "colab_type": "code",
        "outputId": "dafb932e-9915-43a8-d784-e7b69d9b3c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = \"이 영화 정말 감동적이다\"\n",
        "parsed = okt.morphs(text)\n",
        "\n",
        "vector = np.zeros((1, train_X.shape[1]))\n",
        "for i, w in enumerate(parsed):\n",
        "    if w in voca2index:\n",
        "        vector[0, i] += voca2index[w]\n",
        "    \n",
        "vector = torch.from_numpy(vector).long().to(device)\n",
        "predict = torch.sigmoid(reg(vector)).item()\n",
        "print(predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6258990168571472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhaWz0W3gyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}